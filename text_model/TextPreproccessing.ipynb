{"cells":[{"cell_type":"markdown","source":["Data Cleaning"],"metadata":{"id":"t5sHEBn0C9ks"},"id":"t5sHEBn0C9ks"},{"cell_type":"code","source":["#Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28r4NN_Q_M90","executionInfo":{"status":"ok","timestamp":1739244624941,"user_tz":-480,"elapsed":11359,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"30359299-2555-4c2a-e5f9-c6f955355e5c"},"id":"28r4NN_Q_M90","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Import necessary libraries\n","import os\n","import pandas as pd\n","import re\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import joblib"],"metadata":{"id":"suWes3jR_niL"},"id":"suWes3jR_niL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the path to the folder containing your text files\n","label_path = '/content/drive/MyDrive/TextClassification/Dataset/EmoEvaluation'\n","\n","# Function to remove unwanted lines from a file\n","def remove_unwanted_lines(file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Filter lines that don't start with \"C-E\" or \"A-E\"\n","    cleaned_lines = [line for line in lines if not (line.startswith(\"C-E\") or line.startswith(\"A-E\"))]\n","\n","    # Write the cleaned lines back to the file\n","    with open(file_path, 'w') as file:\n","        file.writelines(cleaned_lines)\n","\n","# List all .txt files in the folder\n","label_files = [f for f in os.listdir(label_path) if f.endswith('.txt')]\n","\n","if label_files:\n","    for file in label_files:\n","        file_path = os.path.join(label_path, file)\n","\n","        # Remove unwanted lines from the file\n","        remove_unwanted_lines(file_path)\n","        print(f\"Processed {file}\")\n","else:\n","    print(\"No .txt files found in the labels directory.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LzG67kMnVjM-","executionInfo":{"status":"ok","timestamp":1739249919232,"user_tz":-480,"elapsed":567,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"9f3d2d2d-4890-48bc-8f60-4920472b83cd"},"id":"LzG67kMnVjM-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed Ses05F_script01_2.txt\n","Processed Ses05F_impro02.txt\n","Processed Ses05F_impro05.txt\n","Processed Ses05M_impro03.txt\n","Processed Ses05M_script02_1.txt\n","Processed Ses05F_script03_2.txt\n","Processed Ses05M_script01_3.txt\n","Processed Ses05M_impro01.txt\n","Processed Ses05F_impro07.txt\n","Processed Ses05F_impro06.txt\n","Processed Ses05M_script02_2.txt\n","Processed Ses05M_impro05.txt\n","Processed Ses05F_impro08.txt\n","Processed Ses05M_script01_1b.txt\n","Processed Ses05M_impro04.txt\n","Processed Ses05F_script02_1.txt\n","Processed Ses05F_script02_2.txt\n","Processed Ses05M_impro06.txt\n","Processed Ses05M_script03_1.txt\n","Processed Ses05M_impro07.txt\n","Processed Ses05F_script01_3.txt\n","Processed Ses05F_script03_1.txt\n","Processed Ses05M_script01_1.txt\n","Processed Ses05F_impro04.txt\n","Processed Ses05M_script03_2.txt\n","Processed Ses05F_impro03.txt\n","Processed Ses05M_impro08.txt\n","Processed Ses05M_script01_2.txt\n","Processed Ses05M_impro02.txt\n","Processed Ses05F_script01_1.txt\n","Processed Ses05F_impro01.txt\n"]}]},{"cell_type":"code","source":["# Dataset paths\n","label_path = \"/content/drive/MyDrive/TextClassification/Dataset/EmoEvaluation\""],"metadata":{"id":"2gK8bP4sGZ04"},"id":"2gK8bP4sGZ04","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create output directories inside dataset path\n","converted_labels_path = \"/content/drive/MyDrive/TextClassification/Dataset/converted_labels\"\n","\n","# Create the directories if they don't already exist\n","os.makedirs(converted_labels_path, exist_ok=True)"],"metadata":{"id":"MrngoGJgGguT"},"id":"MrngoGJgGguT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create output folder if it doesn't exist\n","if not os.path.exists(converted_labels_path):\n","    os.makedirs(converted_labels_path)\n","\n","# Function to process each text file and convert it to CSV\n","def convert_txt_to_csv(file_path, output_file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Prepare a list to hold the rows of the DataFrame\n","    data = []\n","\n","    # Process the lines to extract meaningful data\n","    for line in lines:\n","        # Skip unwanted lines starting with \"C-E\" or \"A-E\"\n","        if line.startswith(\"C-E\") or line.startswith(\"A-E\"):\n","            continue\n","\n","        # Split by tabs and spaces to separate the columns\n","        split_line = line.strip().split('\\t')\n","\n","        if len(split_line) == 4:\n","            # If there are 4 items, we treat it as a valid row (e.g., [START_TIME - END_TIME], TURN_NAME, EMOTION, [V, A, D])\n","            data.append(split_line)\n","\n","    # Create a DataFrame from the data\n","    df = pd.DataFrame(data, columns=[\"% [START_TIME - END_TIME]\", \"TURN_NAME\", \"EMOTION\", \"[V, A, D]\"])\n","\n","    # Save the DataFrame as a CSV file\n","    df.to_csv(output_file_path, index=False)\n","\n","# List all .txt files in the folder\n","label_files = [f for f in os.listdir(label_path) if f.endswith('.txt')]\n","\n","if label_files:\n","    for file in label_files:\n","        file_path = os.path.join(label_path, file)\n","        output_file_path = os.path.join(converted_labels_path, file.replace('.txt', '.csv'))\n","\n","        # Convert the .txt file to .csv\n","        convert_txt_to_csv(file_path, output_file_path)\n","        print(f\"Converted {file} to CSV.\")\n","else:\n","    print(\"No .txt files found in the labels directory.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"GESbAHn2DM-4","executionInfo":{"status":"ok","timestamp":1739250398991,"user_tz":-480,"elapsed":637,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"07daaeea-c177-4d8f-c316-20d27bb42a73"},"id":"GESbAHn2DM-4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted Ses05F_script01_2.txt to CSV.\n","Converted Ses05F_impro02.txt to CSV.\n","Converted Ses05F_impro05.txt to CSV.\n","Converted Ses05M_impro03.txt to CSV.\n","Converted Ses05M_script02_1.txt to CSV.\n","Converted Ses05F_script03_2.txt to CSV.\n","Converted Ses05M_script01_3.txt to CSV.\n","Converted Ses05M_impro01.txt to CSV.\n","Converted Ses05F_impro07.txt to CSV.\n","Converted Ses05F_impro06.txt to CSV.\n","Converted Ses05M_script02_2.txt to CSV.\n","Converted Ses05M_impro05.txt to CSV.\n","Converted Ses05F_impro08.txt to CSV.\n","Converted Ses05M_script01_1b.txt to CSV.\n","Converted Ses05M_impro04.txt to CSV.\n","Converted Ses05F_script02_1.txt to CSV.\n","Converted Ses05F_script02_2.txt to CSV.\n","Converted Ses05M_impro06.txt to CSV.\n","Converted Ses05M_script03_1.txt to CSV.\n","Converted Ses05M_impro07.txt to CSV.\n","Converted Ses05F_script01_3.txt to CSV.\n","Converted Ses05F_script03_1.txt to CSV.\n","Converted Ses05M_script01_1.txt to CSV.\n","Converted Ses05F_impro04.txt to CSV.\n","Converted Ses05M_script03_2.txt to CSV.\n","Converted Ses05F_impro03.txt to CSV.\n","Converted Ses05M_impro08.txt to CSV.\n","Converted Ses05M_script01_2.txt to CSV.\n","Converted Ses05M_impro02.txt to CSV.\n","Converted Ses05F_script01_1.txt to CSV.\n","Converted Ses05F_impro01.txt to CSV.\n"]}]},{"cell_type":"code","source":["# Specify the folder path where your .txt files are located\n","transcriptions_path = '/content/drive/MyDrive/TextClassification/Dataset/transcriptions'\n","\n","# Specify the path for the new folder where you want to save the .csv files\n","output_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# Ensure the new folder exists\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Column names to add\n","column_names = ['TURN_NAME', '% [START_TIME - END_TIME]', 'TEXT']\n","\n","# Iterate through all files in the folder\n","for filename in os.listdir(transcriptions_path):\n","    file_path = os.path.join(transcriptions_path, filename)\n","\n","    # Only process .txt files\n","    if filename.endswith('.txt'):\n","        try:\n","            # Open the file and process each line\n","            with open(file_path, 'r') as file:\n","                lines = file.readlines()\n","\n","            # Prepare lists to hold data for the DataFrame\n","            turn_names = []\n","            timestamps = []\n","            texts = []\n","\n","            # Process each line in the file\n","            for line in lines:\n","                # Use regex to extract speaker, timestamp, and text\n","                match = re.match(r'([^\\[]+)\\s+\\[([^\\]]+)\\]:\\s*(.*)', line.strip())\n","                if match:\n","                    turn_name = match.group(1).strip()\n","                    timestamp = match.group(2).strip()\n","                    text = match.group(3).strip()\n","\n","                    turn_names.append(turn_name)\n","                    timestamps.append(timestamp)\n","                    texts.append(text)\n","\n","            # Create a DataFrame\n","            df = pd.DataFrame({\n","                'TURN_NAME': turn_names,\n","                '% [START_TIME - END_TIME]': timestamps,\n","                'TEXT': texts\n","            })\n","\n","            # Create new file path for saving as .csv in the new folder\n","            csv_file_path = os.path.join(output_folder, filename.replace('.txt', '.csv'))\n","\n","            # Save the DataFrame as a .csv file in the new folder\n","            df.to_csv(csv_file_path, index=False)\n","\n","            print(f\"File {filename} converted to CSV and saved as {csv_file_path}.\")\n","\n","        except Exception as e:\n","            print(f\"Error processing {filename}: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"498FNgl9It5U","executionInfo":{"status":"ok","timestamp":1739252008990,"user_tz":-480,"elapsed":615,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"4b069e61-4e61-45c7-e2b6-806fe104bb80"},"id":"498FNgl9It5U","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File Ses05F_impro07.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro07.csv.\n","File Ses05M_script03_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_1.csv.\n","File Ses05F_impro03.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro03.csv.\n","File Ses05F_impro08.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro08.csv.\n","File Ses05M_script01_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_2.csv.\n","File Ses05M_impro03.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro03.csv.\n","File Ses05F_impro02.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro02.csv.\n","File Ses05M_script02_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script02_1.csv.\n","File Ses05M_impro04.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro04.csv.\n","File Ses05M_script01_3.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_3.csv.\n","File Ses05F_script01_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_1.csv.\n","File Ses05F_script01_3.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_3.csv.\n","File Ses05M_script02_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script02_2.csv.\n","File Ses05M_script01_1b.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_1b.csv.\n","File Ses05M_script03_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_2.csv.\n","File Ses05F_script03_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script03_2.csv.\n","File Ses05F_script02_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script02_1.csv.\n","File Ses05M_impro01.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro01.csv.\n","File Ses05F_script01_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_2.csv.\n","File Ses05M_impro07.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro07.csv.\n","File Ses05F_script02_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script02_2.csv.\n","File Ses05M_impro06.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro06.csv.\n","File Ses05M_impro05.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro05.csv.\n","File Ses05M_impro08.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro08.csv.\n","File Ses05F_impro06.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro06.csv.\n","File Ses05M_impro02.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro02.csv.\n","File Ses05F_impro04.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro04.csv.\n","File Ses05F_script03_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script03_1.csv.\n","File Ses05F_impro05.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro05.csv.\n","File Ses05M_script01_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_1.csv.\n","File Ses05F_impro01.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro01.csv.\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Path to the folder containing the files\n","folder_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# Loop through all files in the folder\n","for filename in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, filename)\n","\n","    if filename.endswith('.csv'):  # Modify for other file formats like .xlsx if needed\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Find columns with the pattern % [START_TIME - END_TIME]\n","        columns_to_drop = [col for col in df.columns if '%' in col and '[' in col and ']' in col]\n","\n","        # Drop the columns\n","        df.drop(columns=columns_to_drop, inplace=True)\n","\n","        # Save the updated file back\n","        df.to_csv(file_path, index=False)\n","        print(f\"Updated {filename} - Removed columns: {columns_to_drop}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MGtdh8MxZmNF","executionInfo":{"status":"ok","timestamp":1739252382147,"user_tz":-480,"elapsed":629,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"86e19134-e243-4f97-d244-6bd390d9f23e"},"id":"MGtdh8MxZmNF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated Ses05F_impro07.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro03.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script02_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro02.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_3.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro03.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro04.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro08.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script03_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_3.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_1b.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script02_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script02_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script03_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script03_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro01.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script02_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro07.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro06.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro05.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro08.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro06.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro02.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro04.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script03_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro01.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro05.csv - Removed columns: ['% [START_TIME - END_TIME]']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Define the paths to your folders\n","labels_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_labels'\n","transcriptions_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# List all files in the folders (assuming the files have a .csv extension)\n","labels_files = [f for f in os.listdir(labels_folder) if f.endswith('.csv')]\n","transcriptions_files = [f for f in os.listdir(transcriptions_folder) if f.endswith('.csv')]\n","\n","# Check column names for each file in the labels folder\n","for label_file in labels_files:\n","    label_path = os.path.join(labels_folder, label_file)\n","    labels_df = pd.read_csv(label_path, sep=\"\\t\")\n","    print(f\"Columns in label file {label_file}: {labels_df.columns.tolist()}\")\n","\n","# Check column names for each file in the transcriptions folder\n","for transcription_file in transcriptions_files:\n","    transcription_path = os.path.join(transcriptions_folder, transcription_file)\n","    transcriptions_df = pd.read_csv(transcription_path, sep=\",\")\n","    print(f\"Columns in transcription file {transcription_file}: {transcriptions_df.columns.tolist()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UU2YlUgFr3-z","executionInfo":{"status":"ok","timestamp":1739255349033,"user_tz":-480,"elapsed":424,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"2ce4ebdf-4181-4d31-826f-a70b23a3971d"},"id":"UU2YlUgFr3-z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in label file Ses05F_script01_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro03.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script03_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro07.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro01.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script02_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro06.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_3.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro02.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script02_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro05.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro08.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro05.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro01.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script02_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_1b.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro04.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script02_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro06.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro07.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script03_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script01_3.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script03_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro04.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script03_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro03.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro08.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro02.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script01_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in transcription file Ses05F_impro07.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro03.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script02_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro02.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_3.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro03.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro04.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro08.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script03_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_3.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_1b.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script02_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script02_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script03_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script03_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro01.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script02_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro07.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro06.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro05.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro08.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro06.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro02.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro04.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script03_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro01.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro05.csv: ['TURN_NAME', 'TEXT']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Paths to your input files\n","file1_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_labels/Ses05M_script03_2.csv'\n","file2_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_2.csv'\n","\n","# Read the CSV files into pandas DataFrames\n","df1 = pd.read_csv(file1_path)\n","df2 = pd.read_csv(file2_path)\n","\n","# Merge the files based on the \"TURN_NAME\" column\n","merged_df = pd.merge(df1, df2, on=\"TURN_NAME\", how=\"outer\")  # Use 'outer' to keep all rows\n","\n","# Create a new folder to save the merged file\n","output_folder = '/content/drive/MyDrive/TextClassification/Dataset/merged_data'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Get the file name from the original file path (keeping the name of the first file as an example)\n","file_name = os.path.basename(file1_path)\n","\n","# Save the merged file in the new folder with the same name\n","output_path = os.path.join(output_folder, file_name)\n","merged_df.to_csv(output_path, index=False)\n","\n","print(f\"Merged file saved as {output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7cfojvWrb2K","executionInfo":{"status":"ok","timestamp":1739369515095,"user_tz":-480,"elapsed":1121,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"8e165940-8813-490a-dc4e-ded2332ae55a"},"id":"x7cfojvWrb2K","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged file saved as /content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script03_2.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to your CSV file\n","file_path = '/content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script03_2.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path)\n","\n","# 1. Check if there are any missing values in any column\n","missing_values = df[df.isna().any(axis=1)]  # Rows with missing values in any column\n","if not missing_values.empty:\n","    print(\"Rows with missing values:\")\n","    print(missing_values)\n","else:\n","    print(\"No missing values in any column.\")\n","\n","# 2. Check for empty rows (rows where all columns are NaN)\n","empty_rows = df[df.isna().all(axis=1)]\n","if not empty_rows.empty:\n","    print(\"\\nEmpty rows found (rows where all values are NaN):\")\n","    print(empty_rows)\n","else:\n","    print(\"\\nNo empty rows found.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1U6xF5-SYOe","executionInfo":{"status":"ok","timestamp":1739369530354,"user_tz":-480,"elapsed":380,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"7118a020-7975-4472-e710-ed3d5a6bda23"},"id":"X1U6xF5-SYOe","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No missing values in any column.\n","\n","No empty rows found.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to the merged file\n","file_path = '/content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script02_2.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Check if the specific row 'Ses05F_impro01_FXX0' has missing EMOTION and delete it if so\n","df = df[~((df['TURN_NAME'] == 'Ses05M_script02_2_FXX0') & df['EMOTION'].isna())]\n","\n","# Save the modified DataFrame back to the same CSV file\n","df.to_csv(file_path, index=False)\n","\n","print(f\"Updated file saved as {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY1ynamEMa1n","executionInfo":{"status":"ok","timestamp":1739369383580,"user_tz":-480,"elapsed":402,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"896d9456-fba2-4f1a-f781-ddfb8ab70749"},"id":"UY1ynamEMa1n","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated file saved as /content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script02_2.csv\n"]}]},{"cell_type":"markdown","source":["################################################################################"],"metadata":{"id":"WLbnjvKyDFU8"},"id":"WLbnjvKyDFU8"},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","folder = '/content/drive/MyDrive/TextClassification/Dataset/merged_data'\n","\n","# Initialize a counter to keep track of the total number of texts\n","total_text_count = 0\n","\n","# Loop through all files in the folder\n","for file_name in os.listdir(folder):\n","    # Ensure the file is a CSV or Excel file (you can adjust this based on your file types)\n","    if file_name.endswith('.csv'):\n","        file_path = os.path.join(folder, file_name)\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","        # Check if the TEXT column exists and count the non-empty values\n","        if 'TEXT' in df.columns:\n","            total_text_count += df['TEXT'].notna().sum()  # Counting non-null entries in TEXT column\n","\n","    elif file_name.endswith('.xlsx'):\n","        file_path = os.path.join(folder, file_name)\n","        # Read the Excel file into a DataFrame\n","        df = pd.read_excel(file_path)\n","        # Check if the TEXT column exists and count the non-empty values\n","        if 'TEXT' in df.columns:\n","            total_text_count += df['TEXT'].notna().sum()  # Counting non-null entries in TEXT column\n","\n","# Print the total count of texts\n","print(f'Total number of texts in all files: {total_text_count}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlMbD_lRbHDW","executionInfo":{"status":"ok","timestamp":1740039344398,"user_tz":-480,"elapsed":14265,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"bd73b6cc-a198-4313-a98d-5ab6db11d344"},"id":"HlMbD_lRbHDW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of texts in all files: 2170\n"]}]},{"cell_type":"markdown","source":["Start of Data pre-processing"],"metadata":{"id":"KAfg_tXlC2kh"},"id":"KAfg_tXlC2kh"},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import re\n","\n","# Define the contraction-expansion function\n","def expand_contractions(text, contractions):\n","    if not text:\n","        return text\n","\n","    contraction_pattern = r\"\\b(\" + \"|\".join(re.escape(contraction) for contraction in contractions.keys()) + r\")\\b\"\n","    pattern = re.compile(contraction_pattern, re.IGNORECASE)\n","\n","    def replace_contraction(match):\n","        word = match.group(0)\n","        lower_word = word.lower()\n","\n","        if lower_word in contractions:\n","            replacement = contractions[lower_word]\n","\n","            if word[0].isupper():\n","                replacement = replacement.capitalize()\n","\n","            return replacement\n","        else:\n","            return word\n","\n","    return pattern.sub(replace_contraction, text)\n","\n","# Path to the folder containing your original files\n","folder_path = '/content/drive/MyDrive/TextClassification/Dataset/merged_data'\n","\n","# Define the new folder path to save processed files\n","output_folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords'\n","\n","# Ensure the output folder exists\n","if not os.path.exists(output_folder_path):\n","    os.makedirs(output_folder_path)\n","\n","# Define the current list of common contractions\n","contractions = {\n","    \"can't\": \"cannot\",\n","    \"I'm\": \"I am\",\n","    \"don't\": \"do not\",\n","    \"that's\": \"that is\",\n","    \"didn't\": \"did not\",\n","    \"isn't\": \"is not\",\n","    \"they're\": \"they are\",\n","    \"There's\": \"There is\",\n","    \"doesn't\": \"does not\",\n","    \"hadn't\": \"had not\",\n","    \"It's\": \"It is\",\n","    \"woman's\": \"woman is\",  # Assuming possessive \"woman's\" means \"woman is\"\n","    \"won't\": \"will not\",\n","    \"You're\": \"You are\",\n","    \"aren't\": \"are not\",\n","    \"They're\": \"They are\",\n","    \"wasn't\": \"was not\",\n","    \"I'll\": \"I will\",\n","    \"needn't\": \"need not\",\n","    \"wouldn't\": \"would not\",\n","    \"I've\": \"I have\",\n","    \"you've\": \"you have\",\n","    \"we've\": \"we have\",\n","    \"they've\": \"they have\",\n","    \"he's\": \"he is\",\n","    \"she's\": \"she is\",\n","    \"it's\": \"it is\",\n","    \"what's\": \"what is\",\n","    \"where's\": \"where is\",\n","    \"how's\": \"how is\",\n","    \"who's\": \"who is\",\n","    \"mightn't\": \"might not\",  # Added contraction\n","    \"shouldn't\": \"should not\",  # Added contraction\n","    \"mustn't\": \"must not\"  # Added contraction\n","}\n","\n","# Loop through all files in the folder\n","for filename in os.listdir(folder_path):\n","    if filename.endswith(\".csv\"):  # Check for CSV files\n","        file_path = os.path.join(folder_path, filename)\n","\n","        # Read the CSV file into a pandas DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Check if the 'TEXT' column exists\n","        if 'TEXT' in df.columns:\n","            # Fill NaN values with an empty string and ensure all data is in string format\n","            df['TEXT'] = df['TEXT'].fillna('').astype(str)\n","\n","\n","            # Apply contraction expansion to the 'TEXT' column\n","            df['TEXT'] = df['TEXT'].apply(lambda x: expand_contractions(x, contractions))\n","\n","            # Define the output file path (same file name but in the new folder)\n","            output_file_path = os.path.join(output_folder_path, filename)\n","\n","            # Save the updated DataFrame to the new folder\n","            df.to_csv(output_file_path, index=False)\n","\n","            print(f\"Processed and saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QVwTMxd968Wj","executionInfo":{"status":"ok","timestamp":1739518753161,"user_tz":-480,"elapsed":847,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"20a2a91f-846f-4a99-add5-d293e814bb24"},"id":"QVwTMxd968Wj","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro06.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script01_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro08.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro07.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro05.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script01_1b.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script02_2.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script02_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script01_3.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script03_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro04.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro01.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro03.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_impro02.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script03_2.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script01_2.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro07.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro08.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_script01_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro06.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro03.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro01.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro04.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro02.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05F_impro05.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script01_2.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script01_3.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script02_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script02_2.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script03_1.csv\n","Processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords/Ses05M_script03_2.csv\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Define the folder path where your original files are located\n","folder_path = \"/content/drive/MyDrive/TextClassification/Dataset/merged_data\"\n","\n","# List all files in the folder\n","files_in_folder = [filename for filename in os.listdir(folder_path) if filename.endswith('.csv')]\n","\n","# Print the filenames and the total count\n","print(\"Filenames in the original folder:\")\n","for file in files_in_folder:\n","    print(file)\n","\n","print(f\"\\nTotal number of files: {len(files_in_folder)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"D93yjFL9ivJU","executionInfo":{"status":"ok","timestamp":1739521221786,"user_tz":-480,"elapsed":344,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"38af6d93-b42f-4f9a-d4b4-59f13ec18471"},"id":"D93yjFL9ivJU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filenames in the original folder:\n","Ses05M_impro06.csv\n","Ses05M_script01_1.csv\n","Ses05M_impro08.csv\n","Ses05M_impro07.csv\n","Ses05M_impro05.csv\n","Ses05M_script01_1b.csv\n","Ses05F_script02_2.csv\n","Ses05F_script02_1.csv\n","Ses05F_script01_3.csv\n","Ses05F_script03_1.csv\n","Ses05M_impro04.csv\n","Ses05M_impro01.csv\n","Ses05M_impro03.csv\n","Ses05M_impro02.csv\n","Ses05F_script03_2.csv\n","Ses05F_script01_2.csv\n","Ses05F_impro07.csv\n","Ses05F_impro08.csv\n","Ses05F_script01_1.csv\n","Ses05F_impro06.csv\n","Ses05F_impro03.csv\n","Ses05F_impro01.csv\n","Ses05F_impro04.csv\n","Ses05F_impro02.csv\n","Ses05F_impro05.csv\n","Ses05M_script01_2.csv\n","Ses05M_script01_3.csv\n","Ses05M_script02_1.csv\n","Ses05M_script02_2.csv\n","Ses05M_script03_1.csv\n","Ses05M_script03_2.csv\n","\n","Total number of files: 31\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.data.clear_cache()  # Clear the cache to avoid conflicts\n","nltk.download('punkt')   # Redownload the 'punkt' tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbcvKqTJc_1M","executionInfo":{"status":"ok","timestamp":1739604426330,"user_tz":-480,"elapsed":635,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"7ce87658-3c8b-4c1d-f5d0-177f3a3825ad"},"id":"qbcvKqTJc_1M","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["nltk.download('punkt_tab')  # Try downloading the punkt_tab tokenizer just in case"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ycg7jm48dr76","executionInfo":{"status":"ok","timestamp":1739604428680,"user_tz":-480,"elapsed":462,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"633f5595-2ebe-4149-f7ed-aacac3421ab0"},"id":"Ycg7jm48dr76","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import nltk\n","print(nltk.data.path)  # This will show the directories NLTK is checking for resources"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwQVItR2dz06","executionInfo":{"status":"ok","timestamp":1739604431444,"user_tz":-480,"elapsed":299,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"d2743d3f-d361-4ee5-8917-cb87363c75a9"},"id":"iwQVItR2dz06","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['/root/nltk_data', '/usr/nltk_data', '/usr/share/nltk_data', '/usr/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"]}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","import pandas as pd\n","import os\n","\n","folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/contradictionWords\"  # Original folder path with expanded contractions\n","output_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization\"  # New folder for tokenized files\n","\n","# Ensure the output directory exists\n","os.makedirs(output_path, exist_ok=True)\n","\n","def tokenize_text(text):\n","    \"\"\"\n","    Tokenize the text using word_tokenize or other methods.\n","    For example, using NLTK's word_tokenize\n","    \"\"\"\n","    if isinstance(text, str):\n","        return word_tokenize(text)\n","    return []\n","\n","def check_and_tokenize_in_folder(folder_path, output_path):\n","    # Loop over files in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.csv'):  # Adjust if files are in another format (e.g., .json, .xlsx)\n","            file_path = os.path.join(folder_path, filename)\n","            df = pd.read_csv(file_path)  # Read the CSV file\n","\n","            if 'TEXT' in df.columns:\n","                # Check each entry in the TEXT column and tokenize if necessary\n","                for index, text in df['TEXT'].items():\n","                    if isinstance(text, str) and not pd.isna(text) and not isinstance(text, list):\n","                        print(f\"File: {filename}, Row {index} is not tokenized. Tokenizing now...\")\n","                        # Tokenize the text\n","                        df.at[index, 'TEXT'] = tokenize_text(text)\n","                    else:\n","                        print(f\"File: {filename}, Row {index} is already tokenized.\")\n","\n","                # Add print statement here to confirm the file saving path\n","                output_file_path = os.path.join(output_path, filename)\n","                print(f\"Saving file: {output_file_path}\")  # This will print the output file path\n","                df.to_csv(output_file_path, index=False)  # Save to the new folder\n","\n","            else:\n","                print(f\"No 'TEXT' column found in {filename}\")\n","\n","# Usage\n","check_and_tokenize_in_folder(folder_path, output_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"st7QeDF0PkG4","executionInfo":{"status":"ok","timestamp":1739604450820,"user_tz":-480,"elapsed":17371,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"c868b95f-a181-414f-cc5c-2a608ae66702"},"id":"st7QeDF0PkG4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File: expanded_Ses05M_script03_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 35 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 36 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 37 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 38 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 39 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 40 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 41 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 42 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 43 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 44 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 45 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 46 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 47 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 48 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 49 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 50 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 51 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 52 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 53 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 54 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 55 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 56 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 57 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 58 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 59 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 60 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 61 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 62 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 63 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 64 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 65 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 66 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 67 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 68 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 69 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 70 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 71 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 72 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 73 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 74 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 75 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 76 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 77 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 78 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 79 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 80 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 81 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 82 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 83 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 84 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 85 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 86 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 87 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 88 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 89 is not tokenized. Tokenizing now...\n","File: expanded_Ses05M_script03_2.csv, Row 90 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/expanded_Ses05M_script03_2.csv\n","File: Ses05M_impro06.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro06.csv, Row 31 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro06.csv\n","File: Ses05M_script01_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1.csv, Row 79 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script01_1.csv\n","File: Ses05M_impro05.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro05.csv, Row 44 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro05.csv\n","File: Ses05M_script01_1b.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_1b.csv, Row 80 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script01_1b.csv\n","File: Ses05M_impro08.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_impro08.csv, Row 57 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro08.csv\n","File: Ses05F_script02_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_2.csv, Row 80 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script02_2.csv\n","File: Ses05M_impro04.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05M_impro04.csv, Row 80 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro04.csv\n","File: Ses05F_script03_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_1.csv, Row 67 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script03_1.csv\n","File: Ses05F_script01_3.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_3.csv, Row 67 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script01_3.csv\n","File: Ses05F_script02_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script02_1.csv, Row 54 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script02_1.csv\n","File: Ses05M_impro01.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro01.csv, Row 46 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro01.csv\n","File: Ses05F_impro07.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_impro07.csv, Row 76 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro07.csv\n","File: Ses05M_impro03.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_impro03.csv, Row 65 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro03.csv\n","File: Ses05M_impro02.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_impro02.csv, Row 57 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro02.csv\n","File: Ses05F_script01_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_2.csv, Row 35 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script01_2.csv\n","File: Ses05F_script03_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05F_script03_2.csv, Row 85 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script03_2.csv\n","File: Ses05F_impro06.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro06.csv, Row 55 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro06.csv\n","File: Ses05F_script01_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05F_script01_1.csv, Row 82 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_script01_1.csv\n","File: Ses05F_impro08.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro08.csv, Row 66 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro08.csv\n","File: Ses05F_impro03.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 85 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 86 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 87 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 88 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 89 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 90 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 91 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 92 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 93 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 94 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 95 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 96 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 97 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 98 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 99 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 100 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 101 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 102 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 103 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 104 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 105 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 106 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 107 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 108 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 109 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 110 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 111 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 112 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 113 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 114 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 115 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 116 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 117 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 118 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 119 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 120 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 121 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 122 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 123 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 124 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 125 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 126 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 127 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 128 is not tokenized. Tokenizing now...\n","File: Ses05F_impro03.csv, Row 129 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro03.csv\n","File: Ses05F_impro01.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro01.csv, Row 48 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro01.csv\n","File: Ses05F_impro02.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_impro02.csv, Row 80 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro02.csv\n","File: Ses05M_script01_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_2.csv, Row 34 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script01_2.csv\n","File: Ses05F_impro04.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 85 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 86 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 87 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 88 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 89 is not tokenized. Tokenizing now...\n","File: Ses05F_impro04.csv, Row 90 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro04.csv\n","File: Ses05F_impro05.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 85 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 86 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 87 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 88 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 89 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 90 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 91 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 92 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 93 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 94 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 95 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 96 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 97 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 98 is not tokenized. Tokenizing now...\n","File: Ses05F_impro05.csv, Row 99 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05F_impro05.csv\n","File: Ses05M_script01_3.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_script01_3.csv, Row 70 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script01_3.csv\n","File: Ses05M_script02_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_2.csv, Row 79 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script02_2.csv\n","File: Ses05M_script02_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script02_1.csv, Row 54 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script02_1.csv\n","File: Ses05M_impro07.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 85 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 86 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 87 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 88 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 89 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 90 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 91 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 92 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 93 is not tokenized. Tokenizing now...\n","File: Ses05M_impro07.csv, Row 94 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_impro07.csv\n","File: Ses05M_script03_1.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_1.csv, Row 66 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script03_1.csv\n","File: Ses05M_script03_2.csv, Row 0 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 1 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 2 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 3 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 4 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 5 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 6 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 7 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 8 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 9 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 10 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 11 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 12 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 13 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 14 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 15 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 16 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 17 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 18 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 19 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 20 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 21 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 22 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 23 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 24 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 25 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 26 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 27 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 28 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 29 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 30 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 31 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 32 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 33 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 34 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 35 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 36 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 37 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 38 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 39 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 40 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 41 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 42 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 43 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 44 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 45 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 46 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 47 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 48 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 49 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 50 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 51 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 52 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 53 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 54 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 55 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 56 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 57 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 58 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 59 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 60 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 61 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 62 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 63 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 64 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 65 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 66 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 67 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 68 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 69 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 70 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 71 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 72 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 73 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 74 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 75 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 76 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 77 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 78 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 79 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 80 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 81 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 82 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 83 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 84 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 85 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 86 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 87 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 88 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 89 is not tokenized. Tokenizing now...\n","File: Ses05M_script03_2.csv, Row 90 is not tokenized. Tokenizing now...\n","Saving file: /content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script03_2.csv\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Define the folder path where your original files are located\n","folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization\"\n","\n","# List all files in the folder\n","files_in_folder = [filename for filename in os.listdir(folder_path) if filename.endswith('.csv')]\n","\n","# Print the filenames and the total count\n","print(\"Filenames in the original folder:\")\n","for file in files_in_folder:\n","    print(file)\n","\n","print(f\"\\nTotal number of files: {len(files_in_folder)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UG34uWnIjETH","executionInfo":{"status":"ok","timestamp":1739604565840,"user_tz":-480,"elapsed":404,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"8154b162-fb50-4e41-af5f-d084a863377a"},"id":"UG34uWnIjETH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filenames in the original folder:\n","Ses05F_impro01.csv\n","Ses05F_impro05.csv\n","Ses05F_impro06.csv\n","Ses05F_script01_3.csv\n","Ses05F_impro07.csv\n","Ses05F_impro03.csv\n","Ses05F_impro04.csv\n","Ses05F_script01_1.csv\n","Ses05F_impro02.csv\n","Ses05F_script01_2.csv\n","Ses05F_impro08.csv\n","Ses05F_script02_2.csv\n","Ses05F_script03_1.csv\n","Ses05F_script02_1.csv\n","Ses05M_impro02.csv\n","Ses05M_impro01.csv\n","Ses05M_impro03.csv\n","Ses05M_impro06.csv\n","Ses05F_script03_2.csv\n","Ses05M_impro04.csv\n","Ses05M_impro05.csv\n","Ses05M_impro07.csv\n","Ses05M_impro08.csv\n","Ses05M_script01_1b.csv\n","Ses05M_script01_1.csv\n","Ses05M_script01_3.csv\n","Ses05M_script01_2.csv\n","Ses05M_script02_2.csv\n","Ses05M_script02_1.csv\n","Ses05M_script03_2.csv\n","Ses05M_script03_1.csv\n","\n","Total number of files: 31\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# File paths\n","file1_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/Ses05M_script03_2.csv\"\n","file2_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/expanded_Ses05M_script03_2.csv\"\n","\n","# Load the CSV files into pandas DataFrames\n","df1 = pd.read_csv(file1_path)\n","df2 = pd.read_csv(file2_path)\n","\n","# Check if 'TURN_NAME' column exists in both files\n","if 'TURN_NAME' in df1.columns and 'TURN_NAME' in df2.columns:\n","    # Compare the 'TURN_NAME' columns between both DataFrames\n","    if df1['TURN_NAME'].equals(df2['TURN_NAME']):\n","        print(\"The TURN_NAME columns are identical in both files.\")\n","    else:\n","        print(\"The TURN_NAME columns are different in both files.\")\n","else:\n","    print(\"One or both of the files are missing the 'TURN_NAME' column.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V27rojrropXM","executionInfo":{"status":"ok","timestamp":1739604491344,"user_tz":-480,"elapsed":317,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"f336012b-3bb7-4f38-8434-c294ec26337f"},"id":"V27rojrropXM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The TURN_NAME columns are identical in both files.\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Define the file path\n","file_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/expanded_Ses05M_script03_2.csv\"\n","\n","# Check if the file exists before deleting\n","if os.path.exists(file_path):\n","    os.remove(file_path)\n","    print(f\"{file_path} has been deleted.\")\n","else:\n","    print(f\"{file_path} does not exist.\")"],"metadata":{"id":"g6MTtPoWo_A_","executionInfo":{"status":"ok","timestamp":1739604501639,"user_tz":-480,"elapsed":342,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"af22ac70-08ae-4764-983f-b340c21d8db6","colab":{"base_uri":"https://localhost:8080/"}},"id":"g6MTtPoWo_A_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization/expanded_Ses05M_script03_2.csv has been deleted.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import string\n","\n","# Function to remove punctuation and periods from tokenized text\n","def remove_punctuation_and_periods(tokens):\n","    # Remove punctuation and periods\n","    cleaned_tokens = [token for token in tokens if token not in string.punctuation and token != '.']\n","    return cleaned_tokens\n","\n","# Function to check if there are still any punctuation or periods left in the tokenized text\n","def check_for_punctuation(tokens):\n","    # Check if there are any punctuation or period tokens left\n","    remaining_punctuation = [token for token in tokens if token in string.punctuation or token == '.']\n","    return len(remaining_punctuation) > 0\n","\n","def process_files_in_folder(input_folder_path, output_folder_path):\n","    # Ensure the output directory exists\n","    os.makedirs(output_folder_path, exist_ok=True)\n","\n","    # Loop over files in the input folder\n","    for filename in os.listdir(input_folder_path):\n","        if filename.endswith('.csv'):  # Adjust if files are in another format (e.g., .json, .xlsx)\n","            file_path = os.path.join(input_folder_path, filename)\n","            df = pd.read_csv(file_path)  # Read the CSV file\n","\n","            # Assuming the column with tokenized text is called 'TEXT', adjust as needed\n","            if 'TEXT' in df.columns:\n","                # Process each entry in the TEXT column\n","                for index, text in df['TEXT'].items():\n","                    # If the text is in string format (tokenized as a string), convert it to a list\n","                    if isinstance(text, str):\n","                        try:\n","                            tokens = eval(text)  # Converts string representation of list into an actual list\n","                        except Exception as e:\n","                            print(f\"Error evaluating tokens in File: {filename}, Row {index}: {e}\")\n","                            tokens = []\n","                    else:\n","                        tokens = text\n","\n","                    # Remove punctuation and periods from the tokenized text\n","                    updated_tokens = remove_punctuation_and_periods(tokens)\n","\n","                    # Check if any punctuation or period still exists\n","                    if check_for_punctuation(updated_tokens):\n","                        print(f\"File: {filename}, Row {index} still contains punctuation or period.\")\n","                    else:\n","                        print(f\"File: {filename}, Row {index} has no punctuation or period left.\")\n","\n","                    # Update the 'TEXT' column with the cleaned tokens\n","                    df.at[index, 'TEXT'] = updated_tokens\n","\n","                # Save the updated dataframe to the output folder (new path)\n","                output_file_path = os.path.join(output_folder_path, filename)\n","                try:\n","                    df.to_csv(output_file_path, index=False)  # Save to the new folder\n","                    print(f\"File {filename} processed and saved to {output_file_path}.\")\n","                except Exception as e:\n","                    print(f\"Error saving File: {filename}: {e}\")\n","\n","            else:\n","                print(f\"No 'TEXT' column found in {filename}\")\n","\n","# Usage\n","input_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/Tokenization\"\n","output_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations\"\n","process_files_in_folder(input_folder_path, output_folder_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"5-i-H7KkhxlU","executionInfo":{"status":"ok","timestamp":1739604591838,"user_tz":-480,"elapsed":1990,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"c90aab73-388f-46d2-b197-a723ae6cd2af"},"id":"5-i-H7KkhxlU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File: Ses05F_impro01.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro01.csv, Row 48 has no punctuation or period left.\n","File Ses05F_impro01.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro01.csv.\n","File: Ses05F_impro05.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 80 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 81 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 82 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 83 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 84 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 85 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 86 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 87 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 88 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 89 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 90 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 91 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 92 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 93 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 94 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 95 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 96 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 97 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 98 has no punctuation or period left.\n","File: Ses05F_impro05.csv, Row 99 has no punctuation or period left.\n","File Ses05F_impro05.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro05.csv.\n","File: Ses05F_impro06.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro06.csv, Row 55 has no punctuation or period left.\n","File Ses05F_impro06.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro06.csv.\n","File: Ses05F_script01_3.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_script01_3.csv, Row 67 has no punctuation or period left.\n","File Ses05F_script01_3.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script01_3.csv.\n","File: Ses05F_impro07.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_impro07.csv, Row 76 has no punctuation or period left.\n","File Ses05F_impro07.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro07.csv.\n","File: Ses05F_impro03.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 80 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 81 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 82 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 83 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 84 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 85 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 86 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 87 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 88 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 89 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 90 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 91 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 92 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 93 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 94 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 95 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 96 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 97 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 98 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 99 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 100 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 101 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 102 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 103 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 104 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 105 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 106 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 107 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 108 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 109 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 110 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 111 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 112 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 113 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 114 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 115 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 116 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 117 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 118 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 119 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 120 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 121 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 122 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 123 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 124 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 125 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 126 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 127 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 128 has no punctuation or period left.\n","File: Ses05F_impro03.csv, Row 129 has no punctuation or period left.\n","File Ses05F_impro03.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro03.csv.\n","File: Ses05F_impro04.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 80 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 81 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 82 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 83 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 84 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 85 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 86 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 87 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 88 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 89 has no punctuation or period left.\n","File: Ses05F_impro04.csv, Row 90 has no punctuation or period left.\n","File Ses05F_impro04.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro04.csv.\n","File: Ses05F_script01_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 80 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 81 has no punctuation or period left.\n","File: Ses05F_script01_1.csv, Row 82 has no punctuation or period left.\n","File Ses05F_script01_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script01_1.csv.\n","File: Ses05F_impro02.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_impro02.csv, Row 80 has no punctuation or period left.\n","File Ses05F_impro02.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro02.csv.\n","File: Ses05F_script01_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script01_2.csv, Row 35 has no punctuation or period left.\n","File Ses05F_script01_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script01_2.csv.\n","File: Ses05F_impro08.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_impro08.csv, Row 66 has no punctuation or period left.\n","File Ses05F_impro08.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_impro08.csv.\n","File: Ses05F_script02_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_script02_2.csv, Row 80 has no punctuation or period left.\n","File Ses05F_script02_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script02_2.csv.\n","File: Ses05F_script03_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_script03_1.csv, Row 67 has no punctuation or period left.\n","File Ses05F_script03_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script03_1.csv.\n","File: Ses05F_script02_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script02_1.csv, Row 54 has no punctuation or period left.\n","File Ses05F_script02_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script02_1.csv.\n","File: Ses05M_impro02.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_impro02.csv, Row 57 has no punctuation or period left.\n","File Ses05M_impro02.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro02.csv.\n","File: Ses05M_impro01.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro01.csv, Row 46 has no punctuation or period left.\n","File Ses05M_impro01.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro01.csv.\n","File: Ses05M_impro03.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_impro03.csv, Row 65 has no punctuation or period left.\n","File Ses05M_impro03.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro03.csv.\n","File: Ses05M_impro06.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro06.csv, Row 31 has no punctuation or period left.\n","File Ses05M_impro06.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro06.csv.\n","File: Ses05F_script03_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 34 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 35 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 36 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 37 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 38 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 39 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 40 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 41 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 42 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 43 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 44 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 45 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 46 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 47 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 48 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 49 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 50 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 51 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 52 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 53 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 54 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 55 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 56 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 57 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 58 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 59 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 60 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 61 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 62 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 63 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 64 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 65 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 66 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 67 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 68 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 69 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 70 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 71 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 72 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 73 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 74 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 75 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 76 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 77 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 78 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 79 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 80 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 81 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 82 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 83 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 84 has no punctuation or period left.\n","File: Ses05F_script03_2.csv, Row 85 has no punctuation or period left.\n","File Ses05F_script03_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05F_script03_2.csv.\n","File: Ses05M_impro04.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 79 has no punctuation or period left.\n","File: Ses05M_impro04.csv, Row 80 has no punctuation or period left.\n","File Ses05M_impro04.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro04.csv.\n","File: Ses05M_impro05.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro05.csv, Row 44 has no punctuation or period left.\n","File Ses05M_impro05.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro05.csv.\n","File: Ses05M_impro07.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 79 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 80 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 81 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 82 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 83 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 84 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 85 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 86 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 87 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 88 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 89 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 90 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 91 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 92 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 93 has no punctuation or period left.\n","File: Ses05M_impro07.csv, Row 94 has no punctuation or period left.\n","File Ses05M_impro07.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro07.csv.\n","File: Ses05M_impro08.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_impro08.csv, Row 57 has no punctuation or period left.\n","File Ses05M_impro08.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_impro08.csv.\n","File: Ses05M_script01_1b.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 79 has no punctuation or period left.\n","File: Ses05M_script01_1b.csv, Row 80 has no punctuation or period left.\n","File Ses05M_script01_1b.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script01_1b.csv.\n","File: Ses05M_script01_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_script01_1.csv, Row 79 has no punctuation or period left.\n","File Ses05M_script01_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script01_1.csv.\n","File: Ses05M_script01_3.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_script01_3.csv, Row 70 has no punctuation or period left.\n","File Ses05M_script01_3.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script01_3.csv.\n","File: Ses05M_script01_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script01_2.csv, Row 34 has no punctuation or period left.\n","File Ses05M_script01_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script01_2.csv.\n","File: Ses05M_script02_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_script02_2.csv, Row 79 has no punctuation or period left.\n","File Ses05M_script02_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script02_2.csv.\n","File: Ses05M_script02_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script02_1.csv, Row 54 has no punctuation or period left.\n","File Ses05M_script02_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script02_1.csv.\n","File: Ses05M_script03_2.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 66 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 67 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 68 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 69 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 70 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 71 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 72 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 73 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 74 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 75 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 76 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 77 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 78 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 79 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 80 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 81 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 82 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 83 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 84 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 85 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 86 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 87 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 88 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 89 has no punctuation or period left.\n","File: Ses05M_script03_2.csv, Row 90 has no punctuation or period left.\n","File Ses05M_script03_2.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script03_2.csv.\n","File: Ses05M_script03_1.csv, Row 0 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 1 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 2 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 3 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 4 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 5 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 6 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 7 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 8 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 9 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 10 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 11 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 12 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 13 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 14 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 15 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 16 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 17 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 18 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 19 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 20 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 21 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 22 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 23 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 24 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 25 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 26 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 27 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 28 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 29 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 30 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 31 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 32 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 33 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 34 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 35 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 36 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 37 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 38 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 39 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 40 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 41 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 42 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 43 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 44 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 45 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 46 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 47 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 48 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 49 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 50 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 51 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 52 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 53 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 54 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 55 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 56 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 57 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 58 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 59 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 60 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 61 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 62 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 63 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 64 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 65 has no punctuation or period left.\n","File: Ses05M_script03_1.csv, Row 66 has no punctuation or period left.\n","File Ses05M_script03_1.csv processed and saved to /content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations/Ses05M_script03_1.csv.\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Folder paths\n","folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/removingPunctuations\"  # Folder where tokenized files are\n","output_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase\"  # Folder where the lowercase files will be saved\n","\n","# Ensure the output directory exists\n","os.makedirs(output_path, exist_ok=True)\n","\n","def convert_to_lowercase(text):\n","    \"\"\"Converts text to lowercase\"\"\"\n","    if isinstance(text, str):\n","        return text.lower()\n","    return text\n","\n","def process_and_save_in_folder(folder_path, output_path):\n","    # Loop over files in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.csv'):  # Only process CSV files\n","            file_path = os.path.join(folder_path, filename)\n","            df = pd.read_csv(file_path)  # Read the CSV file\n","\n","            if 'TEXT' in df.columns:\n","                # Apply lowercase conversion to the 'TEXT' column\n","                df['TEXT'] = df['TEXT'].apply(convert_to_lowercase)\n","\n","                # Define the output file path (same filename in the new folder)\n","                output_file_path = os.path.join(output_path, filename)\n","                print(f\"Saving to: {output_file_path}\")  # Print where the file will be saved\n","\n","                # Save the updated DataFrame to the new folder\n","                df.to_csv(output_file_path, index=False)\n","\n","            else:\n","                print(f\"No 'TEXT' column found in {filename}\")\n","\n","# Usage\n","process_and_save_in_folder(folder_path, output_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ASlUS2LId6E1","executionInfo":{"status":"ok","timestamp":1739604605010,"user_tz":-480,"elapsed":882,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"5037480b-93a8-4ce8-be19-f7e3ee289121"},"id":"ASlUS2LId6E1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro01.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro05.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro06.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro07.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro02.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro03.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro04.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_impro08.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script01_1.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script01_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script01_3.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script02_1.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script02_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script03_1.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05F_script03_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro01.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro02.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro03.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro04.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro05.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro06.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro07.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_impro08.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script01_1.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script01_1b.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script01_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script01_3.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script02_1.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script02_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script03_2.csv\n","Saving to: /content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase/Ses05M_script03_1.csv\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MpkL4EyuVor","executionInfo":{"status":"ok","timestamp":1739713384705,"user_tz":-480,"elapsed":1566,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"bf1ec1ef-a2ca-4bb0-c2fe-6504967e05c9"},"id":"8MpkL4EyuVor","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import ast\n","\n","# Specify the folder containing the original files\n","folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/ConvertingIntoLowerCase'\n","\n","# Specify the folder where the cleaned files will be saved\n","new_folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords'\n","\n","# Ensure the new folder exists\n","if not os.path.exists(new_folder_path):\n","    os.makedirs(new_folder_path)\n","\n","# List of unwanted words to remove\n","unwanted_words = [\"'s\", \"''\", \"'m\", '--', '``', \"'b\", '...', '..', \"'d\", 'i-', 'is-', \"'ll\", 'c', \"n't\", \"'re\", 'it-','b', 'we-',\"'ve\"]\n","\n","# Function to clean text\n","def clean_text(text):\n","    # Convert string representation of list into a real list if it's in string format\n","    if isinstance(text, str):\n","        text = ast.literal_eval(text)\n","\n","    # Remove unwanted words\n","    cleaned_text = [word for word in text if word not in unwanted_words]\n","\n","    return cleaned_text\n","\n","# Process all CSV files in the folder\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.csv'):  # Adjust if you're working with other file types\n","        file_path = os.path.join(folder_path, filename)\n","        print(f\"Processing file: {filename}\")\n","\n","        # Read the CSV file\n","        try:\n","            df = pd.read_csv(file_path)\n","            print(f\"Read {filename} successfully.\")\n","        except Exception as e:\n","            print(f\"Error reading {filename}: {e}\")\n","            continue\n","\n","        # Check if \"TEXT\" column exists (all uppercase now)\n","        if 'TEXT' in df.columns:\n","            print(f\"Found 'TEXT' column in {filename}. Cleaning...\")\n","\n","            # Apply cleaning function to the \"TEXT\" column\n","            df['TEXT'] = df['TEXT'].apply(clean_text)\n","\n","            # Create the path for the cleaned file in the new folder\n","            new_file_path = os.path.join(new_folder_path, filename)\n","\n","            try:\n","                # Save the cleaned file to the new folder\n","                df.to_csv(new_file_path, index=False)\n","                print(f\"Processed and saved {filename} to {new_folder_path}\")\n","            except Exception as e:\n","                print(f\"Error saving {filename}: {e}\")\n","        else:\n","            print(f\"'TEXT' column not found in {filename}. Skipping...\")\n","\n","print(\"Cleaning complete for all files.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"W0AoxtGb-Bwk","executionInfo":{"status":"ok","timestamp":1739716958737,"user_tz":-480,"elapsed":653,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"176768c6-cf5d-461e-9ffe-2521151c487c"},"id":"W0AoxtGb-Bwk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: Ses05M_script03_1.csv\n","Read Ses05M_script03_1.csv successfully.\n","Found 'TEXT' column in Ses05M_script03_1.csv. Cleaning...\n","Processed and saved Ses05M_script03_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro01.csv\n","Read Ses05F_impro01.csv successfully.\n","Found 'TEXT' column in Ses05F_impro01.csv. Cleaning...\n","Processed and saved Ses05F_impro01.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro02.csv\n","Read Ses05F_impro02.csv successfully.\n","Found 'TEXT' column in Ses05F_impro02.csv. Cleaning...\n","Processed and saved Ses05F_impro02.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro03.csv\n","Read Ses05F_impro03.csv successfully.\n","Found 'TEXT' column in Ses05F_impro03.csv. Cleaning...\n","Processed and saved Ses05F_impro03.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro08.csv\n","Read Ses05F_impro08.csv successfully.\n","Found 'TEXT' column in Ses05F_impro08.csv. Cleaning...\n","Processed and saved Ses05F_impro08.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script01_2.csv\n","Read Ses05F_script01_2.csv successfully.\n","Found 'TEXT' column in Ses05F_script01_2.csv. Cleaning...\n","Processed and saved Ses05F_script01_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro06.csv\n","Read Ses05F_impro06.csv successfully.\n","Found 'TEXT' column in Ses05F_impro06.csv. Cleaning...\n","Processed and saved Ses05F_impro06.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro07.csv\n","Read Ses05F_impro07.csv successfully.\n","Found 'TEXT' column in Ses05F_impro07.csv. Cleaning...\n","Processed and saved Ses05F_impro07.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro04.csv\n","Read Ses05F_impro04.csv successfully.\n","Found 'TEXT' column in Ses05F_impro04.csv. Cleaning...\n","Processed and saved Ses05F_impro04.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_impro05.csv\n","Read Ses05F_impro05.csv successfully.\n","Found 'TEXT' column in Ses05F_impro05.csv. Cleaning...\n","Processed and saved Ses05F_impro05.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script01_1.csv\n","Read Ses05F_script01_1.csv successfully.\n","Found 'TEXT' column in Ses05F_script01_1.csv. Cleaning...\n","Processed and saved Ses05F_script01_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script01_3.csv\n","Read Ses05F_script01_3.csv successfully.\n","Found 'TEXT' column in Ses05F_script01_3.csv. Cleaning...\n","Processed and saved Ses05F_script01_3.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script02_2.csv\n","Read Ses05F_script02_2.csv successfully.\n","Found 'TEXT' column in Ses05F_script02_2.csv. Cleaning...\n","Processed and saved Ses05F_script02_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script02_1.csv\n","Read Ses05F_script02_1.csv successfully.\n","Found 'TEXT' column in Ses05F_script02_1.csv. Cleaning...\n","Processed and saved Ses05F_script02_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro02.csv\n","Read Ses05M_impro02.csv successfully.\n","Found 'TEXT' column in Ses05M_impro02.csv. Cleaning...\n","Processed and saved Ses05M_impro02.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script03_1.csv\n","Read Ses05F_script03_1.csv successfully.\n","Found 'TEXT' column in Ses05F_script03_1.csv. Cleaning...\n","Processed and saved Ses05F_script03_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05F_script03_2.csv\n","Read Ses05F_script03_2.csv successfully.\n","Found 'TEXT' column in Ses05F_script03_2.csv. Cleaning...\n","Processed and saved Ses05F_script03_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro01.csv\n","Read Ses05M_impro01.csv successfully.\n","Found 'TEXT' column in Ses05M_impro01.csv. Cleaning...\n","Processed and saved Ses05M_impro01.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro04.csv\n","Read Ses05M_impro04.csv successfully.\n","Found 'TEXT' column in Ses05M_impro04.csv. Cleaning...\n","Processed and saved Ses05M_impro04.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro03.csv\n","Read Ses05M_impro03.csv successfully.\n","Found 'TEXT' column in Ses05M_impro03.csv. Cleaning...\n","Processed and saved Ses05M_impro03.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro05.csv\n","Read Ses05M_impro05.csv successfully.\n","Found 'TEXT' column in Ses05M_impro05.csv. Cleaning...\n","Processed and saved Ses05M_impro05.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro06.csv\n","Read Ses05M_impro06.csv successfully.\n","Found 'TEXT' column in Ses05M_impro06.csv. Cleaning...\n","Processed and saved Ses05M_impro06.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro07.csv\n","Read Ses05M_impro07.csv successfully.\n","Found 'TEXT' column in Ses05M_impro07.csv. Cleaning...\n","Processed and saved Ses05M_impro07.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_impro08.csv\n","Read Ses05M_impro08.csv successfully.\n","Found 'TEXT' column in Ses05M_impro08.csv. Cleaning...\n","Processed and saved Ses05M_impro08.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script01_1b.csv\n","Read Ses05M_script01_1b.csv successfully.\n","Found 'TEXT' column in Ses05M_script01_1b.csv. Cleaning...\n","Processed and saved Ses05M_script01_1b.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script01_1.csv\n","Read Ses05M_script01_1.csv successfully.\n","Found 'TEXT' column in Ses05M_script01_1.csv. Cleaning...\n","Processed and saved Ses05M_script01_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script01_3.csv\n","Read Ses05M_script01_3.csv successfully.\n","Found 'TEXT' column in Ses05M_script01_3.csv. Cleaning...\n","Processed and saved Ses05M_script01_3.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script01_2.csv\n","Read Ses05M_script01_2.csv successfully.\n","Found 'TEXT' column in Ses05M_script01_2.csv. Cleaning...\n","Processed and saved Ses05M_script01_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script02_1.csv\n","Read Ses05M_script02_1.csv successfully.\n","Found 'TEXT' column in Ses05M_script02_1.csv. Cleaning...\n","Processed and saved Ses05M_script02_1.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script03_2.csv\n","Read Ses05M_script03_2.csv successfully.\n","Found 'TEXT' column in Ses05M_script03_2.csv. Cleaning...\n","Processed and saved Ses05M_script03_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Processing file: Ses05M_script02_2.csv\n","Read Ses05M_script02_2.csv successfully.\n","Found 'TEXT' column in Ses05M_script02_2.csv. Cleaning...\n","Processed and saved Ses05M_script02_2.csv to /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords\n","Cleaning complete for all files.\n"]}]},{"cell_type":"code","source":["import os\n","import csv\n","import ast\n","\n","# Define the folder path where the files are located\n","folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingUnwantedWords'\n","\n","# Define the new folder path where you want to save the cleaned files\n","new_folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEnhypenAtTheEndOfTheword'\n","\n","# Create the new folder if it doesn't exist\n","os.makedirs(new_folder_path, exist_ok=True)\n","\n","# Iterate over all files in the folder\n","for filename in os.listdir(folder_path):\n","    # Only process CSV files\n","    if filename.endswith(\".csv\"):  # Adjust to file types you need\n","        file_path = os.path.join(folder_path, filename)\n","\n","        # Read the content of the CSV file\n","        with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n","            reader = csv.reader(file)\n","            rows = list(reader)  # Read the content into a list of rows\n","\n","        # Print the original content (first few rows for preview)\n","        print(f\"Original content of {filename}:\")\n","        print(rows[:3])  # Print first 3 rows for preview\n","\n","        # Process the content to remove hyphen at the end of words in the TEXT column\n","        cleaned_rows = []\n","        for row in rows:\n","            # Assuming the TEXT column is the last one (you can adjust the index if it's different)\n","            text_column = row[-1]  # or use index if column position is fixed\n","            try:\n","                # Convert string representation of list in TEXT column to an actual list\n","                text_column = ast.literal_eval(text_column)\n","\n","                # Clean up hyphens at the end of words in the list\n","                cleaned_text_column = [word.rstrip('-') if isinstance(word, str) and word.endswith('-') else word for word in text_column]\n","\n","                # Update the row with the cleaned text column\n","                row[-1] = cleaned_text_column  # Update the last column (TEXT column)\n","            except:\n","                pass  # If it's not a valid list string, leave it unchanged\n","\n","            cleaned_rows.append(row)\n","\n","        # Print the cleaned content (first few rows for preview)\n","        print(f\"\\nUpdated content of {filename}:\")\n","        print(cleaned_rows[:3])  # Print first 3 rows for preview\n","\n","        # Define the new file path in the new folder\n","        new_file_path = os.path.join(new_folder_path, filename)\n","\n","        # Write the cleaned content to a new CSV file in the new folder\n","        with open(new_file_path, mode='w', newline='', encoding='utf-8') as new_file:\n","            writer = csv.writer(new_file)\n","            writer.writerows(cleaned_rows)\n","\n","print(\"\\nCleaning complete! Files saved to:\", new_folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"EIoSbW7VJVrr","executionInfo":{"status":"ok","timestamp":1739716969096,"user_tz":-480,"elapsed":888,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"628d2875-97f4-4910-bc95-09aec3803182"},"id":"EIoSbW7VJVrr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original content of Ses05F_impro01.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.6132 - 6.1700]', 'Ses05F_impro01_F000', 'neu', '[4.0000, 2.5000, 3.0000]', \"['hi', 'i', 'need', 'an', 'id']\"], ['[14.1500 - 19.4900]', 'Ses05F_impro01_F001', 'fru', '[2.5000, 3.0000, 3.0000]', \"['okay', 'i', 'sorry', 'but', 'i', 'just', 'stood', 'in', 'this', 'line', 'for', 'an', 'hour', 'can', 'i', 'is', 'there', 'any', 'way', 'i', 'can-']\"]]\n","\n","Updated content of Ses05F_impro01.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.6132 - 6.1700]', 'Ses05F_impro01_F000', 'neu', '[4.0000, 2.5000, 3.0000]', ['hi', 'i', 'need', 'an', 'id']], ['[14.1500 - 19.4900]', 'Ses05F_impro01_F001', 'fru', '[2.5000, 3.0000, 3.0000]', ['okay', 'i', 'sorry', 'but', 'i', 'just', 'stood', 'in', 'this', 'line', 'for', 'an', 'hour', 'can', 'i', 'is', 'there', 'any', 'way', 'i', 'can']]]\n","Original content of Ses05F_impro06.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[10.2102 - 15.6070]', 'Ses05F_impro06_F000', 'sad', '[2.0000, 2.0000, 3.0000]', \"['a', 'good', 'friend', 'of', 'mine', 'passed', 'away', 'the', 'other', 'day']\"], ['[21.2500 - 27.5580]', 'Ses05F_impro06_F001', 'sad', '[2.0000, 2.5000, 3.0000]', \"['oh', 'they', 'had', 'some', 'pretty', 'progressive', 'cancer']\"]]\n","\n","Updated content of Ses05F_impro06.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[10.2102 - 15.6070]', 'Ses05F_impro06_F000', 'sad', '[2.0000, 2.0000, 3.0000]', ['a', 'good', 'friend', 'of', 'mine', 'passed', 'away', 'the', 'other', 'day']], ['[21.2500 - 27.5580]', 'Ses05F_impro06_F001', 'sad', '[2.0000, 2.5000, 3.0000]', ['oh', 'they', 'had', 'some', 'pretty', 'progressive', 'cancer']]]\n","Original content of Ses05F_script01_3.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.4211 - 8.7432]', 'Ses05F_script01_3_F000', 'hap', '[3.5000, 2.0000, 2.5000]', \"['you', 'the', 'only', 'one', 'i', 'know', 'who', 'loves', 'his', 'parents']\"], ['[11.8580 - 13.6306]', 'Ses05F_script01_3_F001', 'hap', '[4.0000, 2.5000, 2.5000]', \"['no', 'it', 'is', 'good']\"]]\n","\n","Updated content of Ses05F_script01_3.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.4211 - 8.7432]', 'Ses05F_script01_3_F000', 'hap', '[3.5000, 2.0000, 2.5000]', ['you', 'the', 'only', 'one', 'i', 'know', 'who', 'loves', 'his', 'parents']], ['[11.8580 - 13.6306]', 'Ses05F_script01_3_F001', 'hap', '[4.0000, 2.5000, 2.5000]', ['no', 'it', 'is', 'good']]]\n","Original content of Ses05F_script01_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.4900 - 7.2200]', 'Ses05F_script01_2_F000', 'xxx', '[2.5000, 2.5000, 2.5000]', \"['why', 'did', 'you', 'invite', 'her', 'here']\"], ['[9.3700 - 13.3300]', 'Ses05F_script01_2_F001', 'neu', '[2.5000, 2.5000, 3.0000]', \"['she', 'is', 'been', 'in', 'new', 'york', 'three', 'and', 'a', 'half', 'years', 'why', 'all', 'of', 'the', 'sudden']\"]]\n","\n","Updated content of Ses05F_script01_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.4900 - 7.2200]', 'Ses05F_script01_2_F000', 'xxx', '[2.5000, 2.5000, 2.5000]', ['why', 'did', 'you', 'invite', 'her', 'here']], ['[9.3700 - 13.3300]', 'Ses05F_script01_2_F001', 'neu', '[2.5000, 2.5000, 3.0000]', ['she', 'is', 'been', 'in', 'new', 'york', 'three', 'and', 'a', 'half', 'years', 'why', 'all', 'of', 'the', 'sudden']]]\n","Original content of Ses05F_impro08.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[1.9734 - 3.7200]', 'Ses05F_impro08_F000', 'neu', '[3.0000, 1.5000, 2.5000]', \"['hi', 'sir', 'how', 'can', 'i', 'help', 'you']\"], ['[17.7300 - 18.8800]', 'Ses05F_impro08_F001', 'neu', '[3.0000, 2.5000, 1.5000]', \"['okay']\"]]\n","\n","Updated content of Ses05F_impro08.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[1.9734 - 3.7200]', 'Ses05F_impro08_F000', 'neu', '[3.0000, 1.5000, 2.5000]', ['hi', 'sir', 'how', 'can', 'i', 'help', 'you']], ['[17.7300 - 18.8800]', 'Ses05F_impro08_F001', 'neu', '[3.0000, 2.5000, 1.5000]', ['okay']]]\n","Original content of Ses05F_script01_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[8.0341 - 13.5000]', 'Ses05F_script01_1_F000', 'sad', '[2.5000, 2.5000, 2.5000]', \"['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'should', 'tell', 'him', 'before', 'he', 'sees', 'it']\"], ['[15.2259 - 19.1000]', 'Ses05F_script01_1_F001', 'xxx', '[2.0000, 3.0000, 3.0000]', \"['how', 'could', 'he', 'see', 'it', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed']\"]]\n","\n","Updated content of Ses05F_script01_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[8.0341 - 13.5000]', 'Ses05F_script01_1_F000', 'sad', '[2.5000, 2.5000, 2.5000]', ['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'should', 'tell', 'him', 'before', 'he', 'sees', 'it']], ['[15.2259 - 19.1000]', 'Ses05F_script01_1_F001', 'xxx', '[2.0000, 3.0000, 3.0000]', ['how', 'could', 'he', 'see', 'it', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed']]]\n","Original content of Ses05F_impro07.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.7258 - 4.6600]', 'Ses05F_impro07_F000', 'exc', '[4.5000, 3.5000, 3.5000]', \"['so', 'guess', 'what']\"], ['[5.0200 - 7.8100]', 'Ses05F_impro07_F001', 'exc', '[4.5000, 3.0000, 4.0000]', \"['i', 'got', 'into', 'college']\"]]\n","\n","Updated content of Ses05F_impro07.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.7258 - 4.6600]', 'Ses05F_impro07_F000', 'exc', '[4.5000, 3.5000, 3.5000]', ['so', 'guess', 'what']], ['[5.0200 - 7.8100]', 'Ses05F_impro07_F001', 'exc', '[4.5000, 3.0000, 4.0000]', ['i', 'got', 'into', 'college']]]\n","Original content of Ses05F_impro04.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1800 - 9.7600]', 'Ses05F_impro04_F000', 'sad', '[2.5000, 2.0000, 3.0000]', \"['brian', 'i', 'need', 'help']\"], ['[15.7900 - 26.2000]', 'Ses05F_impro04_F001', 'xxx', '[2.0000, 3.0000, 3.5000]', \"['i', 'do', 'not', 'i', 'just', 'i', 'thinking', 'maybe', 'i', 'should', 'move', 'back', 'home', 'or', 'something', 'i', 'do', 'not', 'i', 'do', 'not', 'know', 'what', 'to', 'do', 'i', 'can', 'not', 'i', 'cant', 'keep', 'living', 'the', 'way', 'i', 'living']\"]]\n","\n","Updated content of Ses05F_impro04.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1800 - 9.7600]', 'Ses05F_impro04_F000', 'sad', '[2.5000, 2.0000, 3.0000]', ['brian', 'i', 'need', 'help']], ['[15.7900 - 26.2000]', 'Ses05F_impro04_F001', 'xxx', '[2.0000, 3.0000, 3.5000]', ['i', 'do', 'not', 'i', 'just', 'i', 'thinking', 'maybe', 'i', 'should', 'move', 'back', 'home', 'or', 'something', 'i', 'do', 'not', 'i', 'do', 'not', 'know', 'what', 'to', 'do', 'i', 'can', 'not', 'i', 'cant', 'keep', 'living', 'the', 'way', 'i', 'living']]]\n","Original content of Ses05F_impro03.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.8098 - 4.5479]', 'Ses05F_impro03_F000', 'exc', '[4.0000, 3.0000, 3.5000]', \"['okay', 'so', 'big', 'news']\"], ['[7.9600 - 9.8400]', 'Ses05F_impro03_F001', 'exc', '[4.5000, 3.0000, 3.5000]', \"['i', 'getting', 'married']\"]]\n","\n","Updated content of Ses05F_impro03.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.8098 - 4.5479]', 'Ses05F_impro03_F000', 'exc', '[4.0000, 3.0000, 3.5000]', ['okay', 'so', 'big', 'news']], ['[7.9600 - 9.8400]', 'Ses05F_impro03_F001', 'exc', '[4.5000, 3.0000, 3.5000]', ['i', 'getting', 'married']]]\n","Original content of Ses05F_impro05.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.2600 - 11.5600]', 'Ses05F_impro05_F000', 'neu', '[2.5000, 2.5000, 3.0000]', \"['hi', 'um-', 'i', 'think', 'my', 'baggage', 'was', 'lost', 'and', 'i', 'need', 'to', 'i', 'guess', 'file', 'a', 'claim', 'or', 'i', 'do', 'not', 'know', 'what']\"], ['[11.5900 - 15.1665]', 'Ses05F_impro05_F001', 'neu', '[2.5000, 2.5000, 3.0000]', \"['um-seventeen', 'coming', 'from']\"]]\n","\n","Updated content of Ses05F_impro05.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[2.2600 - 11.5600]', 'Ses05F_impro05_F000', 'neu', '[2.5000, 2.5000, 3.0000]', ['hi', 'um', 'i', 'think', 'my', 'baggage', 'was', 'lost', 'and', 'i', 'need', 'to', 'i', 'guess', 'file', 'a', 'claim', 'or', 'i', 'do', 'not', 'know', 'what']], ['[11.5900 - 15.1665]', 'Ses05F_impro05_F001', 'neu', '[2.5000, 2.5000, 3.0000]', ['um-seventeen', 'coming', 'from']]]\n","Original content of Ses05F_impro02.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1700 - 7.6605]', 'Ses05F_impro02_F000', 'xxx', '[2.0000, 2.0000, 2.0000]', \"['baby', 'i', 'need', 'you', 'to', 'sit', 'down']\"], ['[12.3000 - 14.4800]', 'Ses05F_impro02_F001', 'sad', '[2.0000, 1.5000, 1.5000]', \"['um']\"]]\n","\n","Updated content of Ses05F_impro02.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1700 - 7.6605]', 'Ses05F_impro02_F000', 'xxx', '[2.0000, 2.0000, 2.0000]', ['baby', 'i', 'need', 'you', 'to', 'sit', 'down']], ['[12.3000 - 14.4800]', 'Ses05F_impro02_F001', 'sad', '[2.0000, 1.5000, 1.5000]', ['um']]]\n","Original content of Ses05F_script02_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[22.9600 - 24.8051]', 'Ses05F_script02_1_F000', 'neu', '[2.0000, 1.5000, 2.0000]', \"['fine']\"], ['[45.2100 - 47.1300]', 'Ses05F_script02_1_F001', 'neu', '[2.0000, 2.0000, 2.0000]', \"['what', 'flashlight']\"]]\n","\n","Updated content of Ses05F_script02_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[22.9600 - 24.8051]', 'Ses05F_script02_1_F000', 'neu', '[2.0000, 1.5000, 2.0000]', ['fine']], ['[45.2100 - 47.1300]', 'Ses05F_script02_1_F001', 'neu', '[2.0000, 2.0000, 2.0000]', ['what', 'flashlight']]]\n","Original content of Ses05F_script03_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.4800 - 8.7100]', 'Ses05F_script03_1_F000', 'xxx', '[4.0000, 2.5000, 2.5000]', \"['you', 'think', 'it', 'is', 'them']\"], ['[9.9200 - 13.3500]', 'Ses05F_script03_1_F001', 'xxx', '[3.5000, 3.5000, 3.5000]', \"['freda', 'is', 'the', 'only', 'one', 'who', 'knows', 'we', 'up', 'here', 'and', 'she', 'would', 'not', 'call', 'up']\"]]\n","\n","Updated content of Ses05F_script03_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.4800 - 8.7100]', 'Ses05F_script03_1_F000', 'xxx', '[4.0000, 2.5000, 2.5000]', ['you', 'think', 'it', 'is', 'them']], ['[9.9200 - 13.3500]', 'Ses05F_script03_1_F001', 'xxx', '[3.5000, 3.5000, 3.5000]', ['freda', 'is', 'the', 'only', 'one', 'who', 'knows', 'we', 'up', 'here', 'and', 'she', 'would', 'not', 'call', 'up']]]\n","Original content of Ses05F_script03_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[10.0461 - 13.3500]', 'Ses05F_script03_2_F000', 'neu', '[2.5000, 3.0000, 3.0000]', \"['you', 'knew', 'there', 'was', 'nothing', 'in', 'that']\"], ['[15.6000 - 18.0200]', 'Ses05F_script03_2_F001', 'neu', '[2.0000, 3.0000, 3.5000]', \"['only', 'a', 'trivial', 'little', 'broach']\"]]\n","\n","Updated content of Ses05F_script03_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[10.0461 - 13.3500]', 'Ses05F_script03_2_F000', 'neu', '[2.5000, 3.0000, 3.0000]', ['you', 'knew', 'there', 'was', 'nothing', 'in', 'that']], ['[15.6000 - 18.0200]', 'Ses05F_script03_2_F001', 'neu', '[2.0000, 3.0000, 3.5000]', ['only', 'a', 'trivial', 'little', 'broach']]]\n","Original content of Ses05M_impro01.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.9419 - 5.5500]', 'Ses05M_impro01_F000', 'neu', '[3.0000, 2.5000, 2.5000]', \"['can', 'i', 'help', 'you']\"], ['[9.7900 - 19.0800]', 'Ses05M_impro01_F001', 'neu', '[3.0000, 2.5000, 3.0000]', \"['oh', 'this-', 'this', 'form', 'that', 'you', 'have', 'is', 'the', 'wrong', 'form', 'you', 'need', 'to', 'go', 'over', 'to', 'the', 'other', 'line', 'on', 'the', 'other', 'side', 'of', 'the', 'd.m.v']\"]]\n","\n","Updated content of Ses05M_impro01.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.9419 - 5.5500]', 'Ses05M_impro01_F000', 'neu', '[3.0000, 2.5000, 2.5000]', ['can', 'i', 'help', 'you']], ['[9.7900 - 19.0800]', 'Ses05M_impro01_F001', 'neu', '[3.0000, 2.5000, 3.0000]', ['oh', 'this', 'this', 'form', 'that', 'you', 'have', 'is', 'the', 'wrong', 'form', 'you', 'need', 'to', 'go', 'over', 'to', 'the', 'other', 'line', 'on', 'the', 'other', 'side', 'of', 'the', 'd.m.v']]]\n","Original content of Ses05M_impro02.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.0334 - 5.3000]', 'Ses05M_impro02_F000', 'xxx', '[2.3333, 1.6667, 1.6667]', \"['what', 'is', 'it']\"], ['[16.3100 - 18.1100]', 'Ses05M_impro02_F001', 'sur', '[2.0000, 2.6667, 2.0000]', \"['what']\"]]\n","\n","Updated content of Ses05M_impro02.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.0334 - 5.3000]', 'Ses05M_impro02_F000', 'xxx', '[2.3333, 1.6667, 1.6667]', ['what', 'is', 'it']], ['[16.3100 - 18.1100]', 'Ses05M_impro02_F001', 'sur', '[2.0000, 2.6667, 2.0000]', ['what']]]\n","Original content of Ses05M_impro05.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[9.9600 - 11.5200]', 'Ses05M_impro05_F000', 'neu', '[3.0000, 2.3333, 2.0000]', \"['hmm', 'hmm']\"], ['[11.5500 - 13.3300]', 'Ses05M_impro05_F001', 'neu', '[3.0000, 2.6667, 1.6667]', \"['how', 'long', 'ago', 'was', 'that']\"]]\n","\n","Updated content of Ses05M_impro05.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[9.9600 - 11.5200]', 'Ses05M_impro05_F000', 'neu', '[3.0000, 2.3333, 2.0000]', ['hmm', 'hmm']], ['[11.5500 - 13.3300]', 'Ses05M_impro05_F001', 'neu', '[3.0000, 2.6667, 1.6667]', ['how', 'long', 'ago', 'was', 'that']]]\n","Original content of Ses05F_script02_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[9.5800 - 11.9629]', 'Ses05F_script02_2_F000', 'xxx', '[3.0000, 2.0000, 2.5000]', \"['about', 'what']\"], ['[13.4666 - 15.6200]', 'Ses05F_script02_2_F001', 'xxx', '[2.5000, 3.5000, 3.5000]', \"['it', 'is', 'ridiculous']\"]]\n","\n","Updated content of Ses05F_script02_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[9.5800 - 11.9629]', 'Ses05F_script02_2_F000', 'xxx', '[3.0000, 2.0000, 2.5000]', ['about', 'what']], ['[13.4666 - 15.6200]', 'Ses05F_script02_2_F001', 'xxx', '[2.5000, 3.5000, 3.5000]', ['it', 'is', 'ridiculous']]]\n","Original content of Ses05M_impro06.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.6700 - 6.5700]', 'Ses05M_impro06_F000', 'xxx', '[2.0000, 2.0000, 1.5000]', \"['ryan', 'what', 'is', 'wrong']\"], ['[15.2600 - 17.1900]', 'Ses05M_impro06_F001', 'xxx', '[2.0000, 3.0000, 1.5000]', \"['what']\"]]\n","\n","Updated content of Ses05M_impro06.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.6700 - 6.5700]', 'Ses05M_impro06_F000', 'xxx', '[2.0000, 2.0000, 1.5000]', ['ryan', 'what', 'is', 'wrong']], ['[15.2600 - 17.1900]', 'Ses05M_impro06_F001', 'xxx', '[2.0000, 3.0000, 1.5000]', ['what']]]\n","Original content of Ses05M_impro04.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[12.4200 - 14.2700]', 'Ses05M_impro04_F000', 'xxx', '[2.5000, 2.0000, 2.5000]', \"['what', 'do', 'you', 'mean']\"], ['[22.7800 - 25.1300]', 'Ses05M_impro04_F001', 'neu', '[1.5000, 3.0000, 3.5000]', \"['really', 'it', 'is', 'been', 'that', 'long']\"]]\n","\n","Updated content of Ses05M_impro04.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[12.4200 - 14.2700]', 'Ses05M_impro04_F000', 'xxx', '[2.5000, 2.0000, 2.5000]', ['what', 'do', 'you', 'mean']], ['[22.7800 - 25.1300]', 'Ses05M_impro04_F001', 'neu', '[1.5000, 3.0000, 3.5000]', ['really', 'it', 'is', 'been', 'that', 'long']]]\n","Original content of Ses05M_impro03.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.6500 - 8.0900]', 'Ses05M_impro03_F000', 'neu', '[4.0000, 2.6667, 2.0000]', \"['what']\"], ['[10.6700 - 12.8900]', 'Ses05M_impro03_F001', 'sur', '[4.3333, 3.3333, 2.3333]', \"['what', 'you', 'did']\"]]\n","\n","Updated content of Ses05M_impro03.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.6500 - 8.0900]', 'Ses05M_impro03_F000', 'neu', '[4.0000, 2.6667, 2.0000]', ['what']], ['[10.6700 - 12.8900]', 'Ses05M_impro03_F001', 'sur', '[4.3333, 3.3333, 2.3333]', ['what', 'you', 'did']]]\n","Original content of Ses05M_impro08.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.4500 - 31.2000]', 'Ses05M_impro08_F000', 'fru', '[2.0000, 4.0000, 4.0000]', \"['hi', 'i', 'need-', 'i', 'need', 'some', 'help', 'i', 'been', 'transferred', 'to', 'like', 'eight', 'different', 'departments', 'and', 'i', 'told', 'my', 'problem', 'to', 'every', 'single', 'department', 'and', 'then', 'they', 'just', 'send', 'me', 'to', 'another', 'one', 'and', 'say', 'they', 'are', 'going', 'to', 'send', 'all', 'my', 'information', 'so', 'i', 'will', 'not', 'have', 'to', 'repeat', 'it', 'and', 'then', 'that', 'person', 'does', 'not', 'know', 'what', 'is', 'going', 'on', 'and', 'i', 'restated', 'my', 'story', 'about', 'eight', 'different', 'times', 'and', 'i', 'just', 'want', 'somebody', 'to', 'help', 'me', 'get', 'my', 'connection', 'back', 'because', 'this', 'happens', 'every', 'two', 'weeks', 'and', 'i', 'want', 'to', 'know', 'what', 'to', 'do', 'to', 'stop', 'it', 'from', 'happening', 'again']\"], ['[31.8600 - 34.8400]', 'Ses05M_impro08_F001', 'fru', '[2.0000, 3.0000, 3.0000]', \"['yeah', 'that', 'my', 'service', 'just', 'goes', 'out']\"]]\n","\n","Updated content of Ses05M_impro08.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.4500 - 31.2000]', 'Ses05M_impro08_F000', 'fru', '[2.0000, 4.0000, 4.0000]', ['hi', 'i', 'need', 'i', 'need', 'some', 'help', 'i', 'been', 'transferred', 'to', 'like', 'eight', 'different', 'departments', 'and', 'i', 'told', 'my', 'problem', 'to', 'every', 'single', 'department', 'and', 'then', 'they', 'just', 'send', 'me', 'to', 'another', 'one', 'and', 'say', 'they', 'are', 'going', 'to', 'send', 'all', 'my', 'information', 'so', 'i', 'will', 'not', 'have', 'to', 'repeat', 'it', 'and', 'then', 'that', 'person', 'does', 'not', 'know', 'what', 'is', 'going', 'on', 'and', 'i', 'restated', 'my', 'story', 'about', 'eight', 'different', 'times', 'and', 'i', 'just', 'want', 'somebody', 'to', 'help', 'me', 'get', 'my', 'connection', 'back', 'because', 'this', 'happens', 'every', 'two', 'weeks', 'and', 'i', 'want', 'to', 'know', 'what', 'to', 'do', 'to', 'stop', 'it', 'from', 'happening', 'again']], ['[31.8600 - 34.8400]', 'Ses05M_impro08_F001', 'fru', '[2.0000, 3.0000, 3.0000]', ['yeah', 'that', 'my', 'service', 'just', 'goes', 'out']]]\n","Original content of Ses05M_impro07.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.4800 - 6.7000]', 'Ses05M_impro07_F000', 'exc', '[4.0000, 3.0000, 2.0000]', \"['what']\"], ['[8.3300 - 9.6900]', 'Ses05M_impro07_F001', 'exc', '[4.0000, 3.5000, 2.0000]', \"['oh', 'for', 'real']\"]]\n","\n","Updated content of Ses05M_impro07.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.4800 - 6.7000]', 'Ses05M_impro07_F000', 'exc', '[4.0000, 3.0000, 2.0000]', ['what']], ['[8.3300 - 9.6900]', 'Ses05M_impro07_F001', 'exc', '[4.0000, 3.5000, 2.0000]', ['oh', 'for', 'real']]]\n","Original content of Ses05M_script01_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.0700 - 10.2900]', 'Ses05M_script01_1_F000', 'sad', '[2.5000, 2.5000, 3.0000]', \"['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'should', 'tell', 'him', 'before', 'he', 'sees', 'it']\"], ['[10.9500 - 16.9600]', 'Ses05M_script01_1_F001', 'sad', '[2.0000, 2.5000, 3.0000]', \"['when', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed', 'how', 'could', 'he', 'have', 'seen', 'it']\"]]\n","\n","Updated content of Ses05M_script01_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[6.0700 - 10.2900]', 'Ses05M_script01_1_F000', 'sad', '[2.5000, 2.5000, 3.0000]', ['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'should', 'tell', 'him', 'before', 'he', 'sees', 'it']], ['[10.9500 - 16.9600]', 'Ses05M_script01_1_F001', 'sad', '[2.0000, 2.5000, 3.0000]', ['when', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed', 'how', 'could', 'he', 'have', 'seen', 'it']]]\n","Original content of Ses05M_script01_1b.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.1063 - 8.8600]', 'Ses05M_script01_1b_F000', 'sad', '[2.5000, 2.5000, 2.5000]', \"['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'ought', 'to', 'tell', 'him', 'before', 'he', 'sees', 'it']\"], ['[10.6000 - 13.7700]', 'Ses05M_script01_1b_F001', 'sur', '[2.0000, 3.0000, 3.0000]', \"['what', 'do', 'you', 'mean', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed']\"]]\n","\n","Updated content of Ses05M_script01_1b.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.1063 - 8.8600]', 'Ses05M_script01_1b_F000', 'sad', '[2.5000, 2.5000, 2.5000]', ['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'ought', 'to', 'tell', 'him', 'before', 'he', 'sees', 'it']], ['[10.6000 - 13.7700]', 'Ses05M_script01_1b_F001', 'sur', '[2.0000, 3.0000, 3.0000]', ['what', 'do', 'you', 'mean', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed']]]\n","Original content of Ses05M_script01_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.9869 - 8.2400]', 'Ses05M_script01_2_F000', 'xxx', '[2.3333, 2.3333, 2.6667]', \"['why', 'did', 'you', 'invite', 'her', 'here']\"], ['[10.2600 - 14.0100]', 'Ses05M_script01_2_F001', 'xxx', '[2.3333, 2.6667, 3.3333]', \"['she', 'is', 'been', 'in', 'new', 'york', 'three', 'and', 'a', 'half', 'years', 'why', 'all', 'of', 'a', 'sudden']\"]]\n","\n","Updated content of Ses05M_script01_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[4.9869 - 8.2400]', 'Ses05M_script01_2_F000', 'xxx', '[2.3333, 2.3333, 2.6667]', ['why', 'did', 'you', 'invite', 'her', 'here']], ['[10.2600 - 14.0100]', 'Ses05M_script01_2_F001', 'xxx', '[2.3333, 2.6667, 3.3333]', ['she', 'is', 'been', 'in', 'new', 'york', 'three', 'and', 'a', 'half', 'years', 'why', 'all', 'of', 'a', 'sudden']]]\n","Original content of Ses05M_script01_3.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.3400 - 6.2900]', 'Ses05M_script01_3_F000', 'neu', '[3.5000, 2.0000, 2.5000]', \"['you', 'the', 'only', 'one', 'i', 'know', 'who', 'loves', 'his', 'parents']\"], ['[10.1700 - 17.4600]', 'Ses05M_script01_3_F001', 'hap', '[4.0000, 2.5000, 2.5000]', \"['it', 'is', 'all', 'right', 'it', 'is', 'a', 'good', 'thing', 'it', 'is', 'lovely', 'here', 'the', 'air', 'is', 'sweet']\"]]\n","\n","Updated content of Ses05M_script01_3.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[3.3400 - 6.2900]', 'Ses05M_script01_3_F000', 'neu', '[3.5000, 2.0000, 2.5000]', ['you', 'the', 'only', 'one', 'i', 'know', 'who', 'loves', 'his', 'parents']], ['[10.1700 - 17.4600]', 'Ses05M_script01_3_F001', 'hap', '[4.0000, 2.5000, 2.5000]', ['it', 'is', 'all', 'right', 'it', 'is', 'a', 'good', 'thing', 'it', 'is', 'lovely', 'here', 'the', 'air', 'is', 'sweet']]]\n","Original content of Ses05M_script03_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[8.8100 - 10.9600]', 'Ses05M_script03_2_F000', 'xxx', '[2.5000, 3.0000, 3.0000]', \"['oh', 'you', 'knew', 'there', 'was', 'nothing', 'in', 'that']\"], ['[13.1300 - 15.5200]', 'Ses05M_script03_2_F001', 'neu', '[2.0000, 3.0000, 3.5000]', \"['only', 'a', 'trivial', 'little', 'broach']\"]]\n","\n","Updated content of Ses05M_script03_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[8.8100 - 10.9600]', 'Ses05M_script03_2_F000', 'xxx', '[2.5000, 3.0000, 3.0000]', ['oh', 'you', 'knew', 'there', 'was', 'nothing', 'in', 'that']], ['[13.1300 - 15.5200]', 'Ses05M_script03_2_F001', 'neu', '[2.0000, 3.0000, 3.5000]', ['only', 'a', 'trivial', 'little', 'broach']]]\n","Original content of Ses05M_script02_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[7.8200 - 9.4300]', 'Ses05M_script02_2_F000', 'neu', '[3.0000, 2.0000, 2.0000]', \"['about', 'what']\"], ['[11.2000 - 12.6600]', 'Ses05M_script02_2_F001', 'neu', '[2.6667, 2.0000, 2.0000]', \"['it', 'is', 'ridiculous']\"]]\n","\n","Updated content of Ses05M_script02_2.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[7.8200 - 9.4300]', 'Ses05M_script02_2_F000', 'neu', '[3.0000, 2.0000, 2.0000]', ['about', 'what']], ['[11.2000 - 12.6600]', 'Ses05M_script02_2_F001', 'neu', '[2.6667, 2.0000, 2.0000]', ['it', 'is', 'ridiculous']]]\n","Original content of Ses05M_script03_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1500 - 6.5000]', 'Ses05M_script03_1_F000', 'fea', '[3.5000, 3.0000, 3.0000]', \"['do', 'you', 'think', 'it', 'is', 'them']\"], ['[7.7000 - 11.1200]', 'Ses05M_script03_1_F001', 'exc', '[2.5000, 4.0000, 3.0000]', \"['what', 'nobody', 'knows', 'we', 'are', 'here', 'except', 'freda', 'and', 'she', 'would', 'not', 'ring', 'up']\"]]\n","\n","Updated content of Ses05M_script03_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[5.1500 - 6.5000]', 'Ses05M_script03_1_F000', 'fea', '[3.5000, 3.0000, 3.0000]', ['do', 'you', 'think', 'it', 'is', 'them']], ['[7.7000 - 11.1200]', 'Ses05M_script03_1_F001', 'exc', '[2.5000, 4.0000, 3.0000]', ['what', 'nobody', 'knows', 'we', 'are', 'here', 'except', 'freda', 'and', 'she', 'would', 'not', 'ring', 'up']]]\n","Original content of Ses05M_script02_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[24.6765 - 25.8200]', 'Ses05M_script02_1_F000', 'sad', '[3.0000, 2.0000, 2.5000]', \"['fine']\"], ['[56.2900 - 58.1700]', 'Ses05M_script02_1_F001', 'neu', '[3.0000, 3.0000, 2.5000]', \"['what', 'flashlight']\"]]\n","\n","Updated content of Ses05M_script02_1.csv:\n","[['% [START_TIME - END_TIME]', 'TURN_NAME', 'EMOTION', '[V, A, D]', 'TEXT'], ['[24.6765 - 25.8200]', 'Ses05M_script02_1_F000', 'sad', '[3.0000, 2.0000, 2.5000]', ['fine']], ['[56.2900 - 58.1700]', 'Ses05M_script02_1_F001', 'neu', '[3.0000, 3.0000, 2.5000]', ['what', 'flashlight']]]\n","\n","Cleaning complete! Files saved to: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEnhypenAtTheEndOfTheword\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from nltk.corpus import stopwords\n","import ast  # Safer alternative to eval\n","\n","# Initialize the stopwords set\n","stop_words = set(stopwords.words('english'))\n","\n","# Function to remove stopwords from tokenized text\n","def remove_stopwords(tokens):\n","    # Remove stopwords from the token list\n","    cleaned_tokens = [token for token in tokens if token.lower() not in stop_words]\n","    removed_stopwords = [token for token in tokens if token.lower() in stop_words]\n","    return cleaned_tokens, removed_stopwords\n","\n","def remove_stopwords_in_folder(input_folder_path, output_folder_path):\n","    # Ensure the output folder exists\n","    os.makedirs(output_folder_path, exist_ok=True)\n","\n","    # Loop over files in the input folder\n","    for filename in os.listdir(input_folder_path):\n","        if filename.endswith('.csv'):  # Adjust if files are in another format (e.g., .json, .xlsx)\n","            file_path = os.path.join(input_folder_path, filename)\n","            df = pd.read_csv(file_path)  # Read the CSV file\n","\n","            # Check if the 'TEXT' column exists\n","            if 'TEXT' in df.columns:\n","                print(f\"\\nProcessing File: {filename}\")\n","                stopwords_removed_in_file = False  # Track if stopwords are removed in the file\n","\n","                # Process each entry in the TEXT column\n","                for index, text in df['TEXT'].items():\n","                    # If the text is in string format (tokenized as a string), convert it to a list\n","                    if isinstance(text, str):\n","                        try:\n","                            tokens = ast.literal_eval(text)  # Converts string representation of list into an actual list safely\n","                        except (ValueError, SyntaxError):\n","                            tokens = text.split()  # Split text into words if it's not a proper list format\n","                    else:\n","                        tokens = text if isinstance(text, list) else text.split()  # If it's already a list, keep it; else split the string\n","\n","                    # Show the original tokens before removing stopwords\n","                    print(f\"Original Tokens (Row {index}): {tokens}\")\n","\n","                    # Remove stopwords\n","                    updated_tokens, removed_stopwords = remove_stopwords(tokens)\n","\n","                    # Show the updated tokens and which stopwords were removed\n","                    print(f\"Updated Tokens (Row {index}): {updated_tokens}\")\n","                    print(f\"Stopwords Removed (Row {index}): {removed_stopwords}\")\n","\n","                    # If stopwords were removed, update the flag\n","                    if removed_stopwords:\n","                        stopwords_removed_in_file = True\n","                        print(f\"Stopwords were removed for Row {index} in file {filename}.\")\n","                    else:\n","                        print(f\"No stopwords removed for Row {index} in file {filename}.\")\n","\n","                    # Update the 'TEXT' column with the cleaned tokens\n","                    df.at[index, 'TEXT'] = updated_tokens\n","\n","                # Define the path for saving the updated file to the output folder\n","                output_file_path = os.path.join(output_folder_path, filename)\n","\n","                # After processing all rows, save the updated dataframe back to the output file\n","                df.to_csv(output_file_path, index=False)  # Save to the new folder\n","\n","                # If stopwords were removed from any row in the file, display the message\n","                if stopwords_removed_in_file:\n","                    print(f\"Stopwords were removed in at least one row in the file: {filename}\")\n","                else:\n","                    print(f\"No stopwords removed in the file: {filename}\")\n","\n","                print(f\"Updated file saved: {output_file_path}\")\n","\n","            else:\n","                print(f\"No 'TEXT' column found in {filename}\")\n","\n","# Usage\n","input_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEnhypenAtTheEndOfTheword\"\n","output_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords\"\n","remove_stopwords_in_folder(input_folder_path, output_folder_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"NvTfv52VtKGL","executionInfo":{"status":"ok","timestamp":1739717065101,"user_tz":-480,"elapsed":4408,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"a131488b-c24e-4066-d562-c6afe73bc470"},"id":"NvTfv52VtKGL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Stopwords Removed (Row 50): ['no', 'that', 'will', 'with', 'our']\n","Stopwords were removed for Row 50 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 51): ['it', 'all', 'depends', 'on', 'how', 'well', 'we', 'played']\n","Updated Tokens (Row 51): ['depends', 'well', 'played']\n","Stopwords Removed (Row 51): ['it', 'all', 'on', 'how', 'we']\n","Stopwords were removed for Row 51 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 52): ['yes', 'yes', 'with', 'all', 'his', 'might']\n","Updated Tokens (Row 52): ['yes', 'yes', 'might']\n","Stopwords Removed (Row 52): ['with', 'all', 'his']\n","Stopwords were removed for Row 52 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 53): ['no', 'no', 'it', 'is', 'not', 'death', 'is', 'very', 'laughable', 'come', 'such', 'a', 'cunning', 'little', 'mystery', 'all', 'done', 'with', 'mirrors']\n","Updated Tokens (Row 53): ['death', 'laughable', 'come', 'cunning', 'little', 'mystery', 'done', 'mirrors']\n","Stopwords Removed (Row 53): ['no', 'no', 'it', 'is', 'not', 'is', 'very', 'such', 'a', 'all', 'with']\n","Stopwords were removed for Row 53 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 54): ['no', 'so', 'is', 'everyone', 'else', 'in', 'the', 'long', 'run', 'let', 'be', 'superficial', 'and', 'pity', 'the', 'poor', 'philosophers', 'let', 'blow', 'trumpets', 'and', 'squeakers', 'and']\n","Updated Tokens (Row 54): ['everyone', 'else', 'long', 'run', 'let', 'superficial', 'pity', 'poor', 'philosophers', 'let', 'blow', 'trumpets', 'squeakers']\n","Stopwords Removed (Row 54): ['no', 'so', 'is', 'in', 'the', 'be', 'and', 'the', 'and', 'and']\n","Stopwords were removed for Row 54 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 55): ['enjoy', 'the', 'party', 'as', 'long', 'as', 'we', 'can', 'like', 'very', 'little', 'quite', 'idiotic', 'schoolchildren', 'garbage', 'let', 'savor', 'the', 'delight', 'of', 'the', 'moment']\n","Updated Tokens (Row 55): ['enjoy', 'party', 'long', 'like', 'little', 'quite', 'idiotic', 'schoolchildren', 'garbage', 'let', 'savor', 'delight', 'moment']\n","Stopwords Removed (Row 55): ['the', 'as', 'as', 'we', 'can', 'very', 'the', 'of', 'the']\n","Stopwords were removed for Row 55 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 56): ['darling', 'come', 'here', 'and', 'kiss', 'me', 'before', 'your', 'body', 'rots', 'and', 'worms', 'pop', 'in', 'and', 'out', 'of', 'your', 'eye', 'sockets']\n","Updated Tokens (Row 56): ['darling', 'come', 'kiss', 'body', 'rots', 'worms', 'pop', 'eye', 'sockets']\n","Stopwords Removed (Row 56): ['here', 'and', 'me', 'before', 'your', 'and', 'in', 'and', 'out', 'of', 'your']\n","Stopwords were removed for Row 56 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 57): ['i', 'do', 'not', 'mind', 'what', 'you', 'do', 'see', 'you', 'could', 'paint', 'your', 'body', 'green', 'all', 'over', 'and', 'dance', 'naked', 'through', 'the', 'place', 'vendome', 'and', 'run', 'off', 'with', 'every', 'man', 'in', 'the', 'world', 'and', 'i', 'sha', 'say', 'a', 'word', 'as', 'long', 'as', 'i', 'know', 'that', 'you', 'love', 'me', 'best']\n","Updated Tokens (Row 57): ['mind', 'see', 'could', 'paint', 'body', 'green', 'dance', 'naked', 'place', 'vendome', 'run', 'every', 'man', 'world', 'sha', 'say', 'word', 'long', 'know', 'love', 'best']\n","Stopwords Removed (Row 57): ['i', 'do', 'not', 'what', 'you', 'do', 'you', 'your', 'all', 'over', 'and', 'through', 'the', 'and', 'off', 'with', 'in', 'the', 'and', 'i', 'a', 'as', 'as', 'i', 'that', 'you', 'me']\n","Stopwords were removed for Row 57 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 58): ['do', 'you', 'remember', 'that', 'awful', 'scene', 'we', 'had', 'in', 'venice']\n","Updated Tokens (Row 58): ['remember', 'awful', 'scene', 'venice']\n","Stopwords Removed (Row 58): ['do', 'you', 'that', 'we', 'had', 'in']\n","Stopwords were removed for Row 58 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 59): ['the', 'one', 'where', 'you', 'bought', 'that', 'little', 'painted', 'wooden', 'snake', 'and', 'put', 'it', 'on', 'my', 'bed']\n","Updated Tokens (Row 59): ['one', 'bought', 'little', 'painted', 'wooden', 'snake', 'put', 'bed']\n","Stopwords Removed (Row 59): ['the', 'where', 'you', 'that', 'and', 'it', 'on', 'my']\n","Stopwords were removed for Row 59 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 60): ['horrible', 'thing', 'i', 'hate', 'it']\n","Updated Tokens (Row 60): ['horrible', 'thing', 'hate']\n","Stopwords Removed (Row 60): ['i', 'it']\n","Stopwords were removed for Row 60 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 61): ['how', 'long', 'did', 'that', 'row', 'last']\n","Updated Tokens (Row 61): ['long', 'row', 'last']\n","Stopwords Removed (Row 61): ['how', 'did', 'that']\n","Stopwords were removed for Row 61 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 62): ['the', 'worst', 'one', 'was', 'in', 'cannes', 'when', 'your', 'curling', 'irons', 'burnt', 'a', 'hole', 'in', 'my', 'new', 'dressing', 'gown']\n","Updated Tokens (Row 62): ['worst', 'one', 'cannes', 'curling', 'irons', 'burnt', 'hole', 'new', 'dressing', 'gown']\n","Stopwords Removed (Row 62): ['the', 'was', 'in', 'when', 'your', 'a', 'in', 'my']\n","Stopwords were removed for Row 62 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 63): ['oh', 'that', 'was', 'quite', 'a', 'rouser', 'was', 'not', 'it']\n","Updated Tokens (Row 63): ['oh', 'quite', 'rouser']\n","Stopwords Removed (Row 63): ['that', 'was', 'a', 'was', 'not', 'it']\n","Stopwords were removed for Row 63 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 64): ['oh', 'i', 'did', 'not', 'hit', 'you', 'very', 'hard']\n","Updated Tokens (Row 64): ['oh', 'hit', 'hard']\n","Stopwords Removed (Row 64): ['i', 'did', 'not', 'you', 'very']\n","Stopwords were removed for Row 64 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 65): ['laughter', 'i', 'shall', 'never', 'forget', 'his', 'face']\n","Updated Tokens (Row 65): ['laughter', 'shall', 'never', 'forget', 'face']\n","Stopwords Removed (Row 65): ['i', 'his']\n","Stopwords were removed for Row 65 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 66): ['oh', 'we', 'were', 'very', 'much', 'younger', 'then']\n","Updated Tokens (Row 66): ['oh', 'much', 'younger']\n","Stopwords Removed (Row 66): ['we', 'were', 'very', 'then']\n","Stopwords were removed for Row 66 in file Ses05F_script03_1.csv.\n","Original Tokens (Row 67): ['oh', 'as', 'a', 'matter', 'of', 'fact', 'the', 'real', 'cause', 'of', 'that', 'row', 'was', 'peter', 'burden']\n","Updated Tokens (Row 67): ['oh', 'matter', 'fact', 'real', 'cause', 'row', 'peter', 'burden']\n","Stopwords Removed (Row 67): ['as', 'a', 'of', 'the', 'of', 'that', 'was']\n","Stopwords were removed for Row 67 in file Ses05F_script03_1.csv.\n","Stopwords were removed in at least one row in the file: Ses05F_script03_1.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05F_script03_1.csv\n","\n","Processing File: Ses05M_impro03.csv\n","Original Tokens (Row 0): ['what']\n","Updated Tokens (Row 0): []\n","Stopwords Removed (Row 0): ['what']\n","Stopwords were removed for Row 0 in file Ses05M_impro03.csv.\n","Original Tokens (Row 1): ['what', 'you', 'did']\n","Updated Tokens (Row 1): []\n","Stopwords Removed (Row 1): ['what', 'you', 'did']\n","Stopwords were removed for Row 1 in file Ses05M_impro03.csv.\n","Original Tokens (Row 2): ['when']\n","Updated Tokens (Row 2): []\n","Stopwords Removed (Row 2): ['when']\n","Stopwords were removed for Row 2 in file Ses05M_impro03.csv.\n","Original Tokens (Row 3): ['oh', 'what', 'how', 'where', 'how', 'did', 'you', 'do', 'it']\n","Updated Tokens (Row 3): ['oh']\n","Stopwords Removed (Row 3): ['what', 'how', 'where', 'how', 'did', 'you', 'do', 'it']\n","Stopwords were removed for Row 3 in file Ses05M_impro03.csv.\n","Original Tokens (Row 4): ['okay', 'good', 'i', 'i', 'assumed']\n","Updated Tokens (Row 4): ['okay', 'good', 'assumed']\n","Stopwords Removed (Row 4): ['i', 'i']\n","Stopwords were removed for Row 4 in file Ses05M_impro03.csv.\n","Original Tokens (Row 5): ['oh']\n","Updated Tokens (Row 5): ['oh']\n","Stopwords Removed (Row 5): []\n","No stopwords removed for Row 5 in file Ses05M_impro03.csv.\n","Original Tokens (Row 6): ['uh-huh']\n","Updated Tokens (Row 6): ['uh-huh']\n","Stopwords Removed (Row 6): []\n","No stopwords removed for Row 6 in file Ses05M_impro03.csv.\n","Original Tokens (Row 7): ['oh', 'my', 'god', 'that', 'is', 'so', 'dramatic']\n","Updated Tokens (Row 7): ['oh', 'god', 'dramatic']\n","Stopwords Removed (Row 7): ['my', 'that', 'is', 'so']\n","Stopwords were removed for Row 7 in file Ses05M_impro03.csv.\n","Original Tokens (Row 8): ['so', 'cute']\n","Updated Tokens (Row 8): ['cute']\n","Stopwords Removed (Row 8): ['so']\n","Stopwords were removed for Row 8 in file Ses05M_impro03.csv.\n","Original Tokens (Row 9): ['no', 'it', 'is', 'totally', 'original', 'though']\n","Updated Tokens (Row 9): ['totally', 'original', 'though']\n","Stopwords Removed (Row 9): ['no', 'it', 'is']\n","Stopwords were removed for Row 9 in file Ses05M_impro03.csv.\n","Original Tokens (Row 10): ['oh']\n","Updated Tokens (Row 10): ['oh']\n","Stopwords Removed (Row 10): []\n","No stopwords removed for Row 10 in file Ses05M_impro03.csv.\n","Original Tokens (Row 11): ['oh', 'then', 'you', 'had', 'a', 'whole', 'weekend', 'of', 'camping']\n","Updated Tokens (Row 11): ['oh', 'whole', 'weekend', 'camping']\n","Stopwords Removed (Row 11): ['then', 'you', 'had', 'a', 'of']\n","Stopwords were removed for Row 11 in file Ses05M_impro03.csv.\n","Original Tokens (Row 12): ['oh', 'right', 'sure', 'laughter']\n","Updated Tokens (Row 12): ['oh', 'right', 'sure', 'laughter']\n","Stopwords Removed (Row 12): []\n","No stopwords removed for Row 12 in file Ses05M_impro03.csv.\n","Original Tokens (Row 13): ['so', 'where', 'are', 'you', 'going', 'to', 'have', 'your', 'wedding']\n","Updated Tokens (Row 13): ['going', 'wedding']\n","Stopwords Removed (Row 13): ['so', 'where', 'are', 'you', 'to', 'have', 'your']\n","Stopwords were removed for Row 13 in file Ses05M_impro03.csv.\n","Original Tokens (Row 14): ['yeah', 'of', 'course']\n","Updated Tokens (Row 14): ['yeah', 'course']\n","Stopwords Removed (Row 14): ['of']\n","Stopwords were removed for Row 14 in file Ses05M_impro03.csv.\n","Original Tokens (Row 15): ['okay', 'okay']\n","Updated Tokens (Row 15): ['okay', 'okay']\n","Stopwords Removed (Row 15): []\n","No stopwords removed for Row 15 in file Ses05M_impro03.csv.\n","Original Tokens (Row 16): ['where', 'is', 'she', 'right', 'now']\n","Updated Tokens (Row 16): ['right']\n","Stopwords Removed (Row 16): ['where', 'is', 'she', 'now']\n","Stopwords were removed for Row 16 in file Ses05M_impro03.csv.\n","Original Tokens (Row 17): ['yeah', 'i', 'hang', 'out', 'with', 'the', 'both', 'of', 'you']\n","Updated Tokens (Row 17): ['yeah', 'hang']\n","Stopwords Removed (Row 17): ['i', 'out', 'with', 'the', 'both', 'of', 'you']\n","Stopwords were removed for Row 17 in file Ses05M_impro03.csv.\n","Original Tokens (Row 18): ['yes']\n","Updated Tokens (Row 18): ['yes']\n","Stopwords Removed (Row 18): []\n","No stopwords removed for Row 18 in file Ses05M_impro03.csv.\n","Original Tokens (Row 19): ['oh', 'i', 'so', 'excited', 'for', 'you']\n","Updated Tokens (Row 19): ['oh', 'excited']\n","Stopwords Removed (Row 19): ['i', 'so', 'for', 'you']\n","Stopwords were removed for Row 19 in file Ses05M_impro03.csv.\n","Original Tokens (Row 20): ['oh']\n","Updated Tokens (Row 20): ['oh']\n","Stopwords Removed (Row 20): []\n","No stopwords removed for Row 20 in file Ses05M_impro03.csv.\n","Original Tokens (Row 21): ['oh', 'my', 'gosh', 'you', 'told', 'your', 'parents', 'already', 'and', 'everything']\n","Updated Tokens (Row 21): ['oh', 'gosh', 'told', 'parents', 'already', 'everything']\n","Stopwords Removed (Row 21): ['my', 'you', 'your', 'and']\n","Stopwords were removed for Row 21 in file Ses05M_impro03.csv.\n","Original Tokens (Row 22): ['are', 'they', 'so', 'excited']\n","Updated Tokens (Row 22): ['excited']\n","Stopwords Removed (Row 22): ['are', 'they', 'so']\n","Stopwords were removed for Row 22 in file Ses05M_impro03.csv.\n","Original Tokens (Row 23): ['are', 'you', 'guys', 'gon', 'na', 'have', 'kids']\n","Updated Tokens (Row 23): ['guys', 'gon', 'na', 'kids']\n","Stopwords Removed (Row 23): ['are', 'you', 'have']\n","Stopwords were removed for Row 23 in file Ses05M_impro03.csv.\n","Original Tokens (Row 24): ['yeah']\n","Updated Tokens (Row 24): ['yeah']\n","Stopwords Removed (Row 24): []\n","No stopwords removed for Row 24 in file Ses05M_impro03.csv.\n","Original Tokens (Row 25): ['whoa', 'right', 'away']\n","Updated Tokens (Row 25): ['whoa', 'right', 'away']\n","Stopwords Removed (Row 25): []\n","No stopwords removed for Row 25 in file Ses05M_impro03.csv.\n","Original Tokens (Row 26): ['are', 'you', 'going', 'to', 'start', 'right', 'away']\n","Updated Tokens (Row 26): ['going', 'start', 'right', 'away']\n","Stopwords Removed (Row 26): ['are', 'you', 'to']\n","Stopwords were removed for Row 26 in file Ses05M_impro03.csv.\n","Original Tokens (Row 27): ['yeah', 'have', 'you', 'ever', 'like', 'lived', 'with', 'someone', 'else', 'before']\n","Updated Tokens (Row 27): ['yeah', 'ever', 'like', 'lived', 'someone', 'else']\n","Stopwords Removed (Row 27): ['have', 'you', 'with', 'before']\n","Stopwords were removed for Row 27 in file Ses05M_impro03.csv.\n","Original Tokens (Row 28): ['oh', 'did', 'you', 'i', 'did', 'not', 'know', 'that']\n","Updated Tokens (Row 28): ['oh', 'know']\n","Stopwords Removed (Row 28): ['did', 'you', 'i', 'did', 'not', 'that']\n","Stopwords were removed for Row 28 in file Ses05M_impro03.csv.\n","Original Tokens (Row 29): ['oh']\n","Updated Tokens (Row 29): ['oh']\n","Stopwords Removed (Row 29): []\n","No stopwords removed for Row 29 in file Ses05M_impro03.csv.\n","Original Tokens (Row 30): ['oooh']\n","Updated Tokens (Row 30): ['oooh']\n","Stopwords Removed (Row 30): []\n","No stopwords removed for Row 30 in file Ses05M_impro03.csv.\n","Original Tokens (Row 31): ['that', 'is', 'incredible', 'yeah', 'congratulations']\n","Updated Tokens (Row 31): ['incredible', 'yeah', 'congratulations']\n","Stopwords Removed (Row 31): ['that', 'is']\n","Stopwords were removed for Row 31 in file Ses05M_impro03.csv.\n","Original Tokens (Row 32): ['guess', 'what']\n","Updated Tokens (Row 32): ['guess']\n","Stopwords Removed (Row 32): ['what']\n","Stopwords were removed for Row 32 in file Ses05M_impro03.csv.\n","Original Tokens (Row 33): ['i', 'did', 'it', 'i', 'asked', 'her', 'to', 'marry', 'me']\n","Updated Tokens (Row 33): ['asked', 'marry']\n","Stopwords Removed (Row 33): ['i', 'did', 'it', 'i', 'her', 'to', 'me']\n","Stopwords were removed for Row 33 in file Ses05M_impro03.csv.\n","Original Tokens (Row 34): ['yes', 'i', 'did', 'it']\n","Updated Tokens (Row 34): ['yes']\n","Stopwords Removed (Row 34): ['i', 'did', 'it']\n","Stopwords were removed for Row 34 in file Ses05M_impro03.csv.\n","Original Tokens (Row 35): ['oh', 'my', 'god', 'it', 'was', 'just', 'last', 'weekend']\n","Updated Tokens (Row 35): ['oh', 'god', 'last', 'weekend']\n","Stopwords Removed (Row 35): ['my', 'it', 'was', 'just']\n","Stopwords were removed for Row 35 in file Ses05M_impro03.csv.\n","Original Tokens (Row 36): ['she', 'well', 'she', 'said', 'yes', 'first', 'of', 'all', 'let', 'me', 'say', 'that', 'right', 'off', 'the', 'bat', 'well', 'i', 'would', 'like', 'to', 'assume', 'too', 'but', 'you', 'never', 'know', 'these', 'things', 'right']\n","Updated Tokens (Row 36): ['well', 'said', 'yes', 'first', 'let', 'say', 'right', 'bat', 'well', 'would', 'like', 'assume', 'never', 'know', 'things', 'right']\n","Stopwords Removed (Row 36): ['she', 'she', 'of', 'all', 'me', 'that', 'off', 'the', 'i', 'to', 'too', 'but', 'you', 'these']\n","Stopwords were removed for Row 36 in file Ses05M_impro03.csv.\n","Original Tokens (Row 37): ['um', 'but', 'no', 'it', 'was', 'it', 'was', 'great', 'it', 'was', 'really', 'great', 'i', 'think', 'she', 'was', 'really', 'surprised', 'and', 'she', 'was', 'really', 'happy', 'um']\n","Updated Tokens (Row 37): ['um', 'great', 'really', 'great', 'think', 'really', 'surprised', 'really', 'happy', 'um']\n","Stopwords Removed (Row 37): ['but', 'no', 'it', 'was', 'it', 'was', 'it', 'was', 'i', 'she', 'was', 'and', 'she', 'was']\n","Stopwords were removed for Row 37 in file Ses05M_impro03.csv.\n","Original Tokens (Row 38): ['i', 'did', 'it', 'up', 'at', 'yosemite', 'we', 'went', 'camping', 'right', 'like', 'we', 'usually', 'do', 'you', 'know', 'we', 'go', 'camping', 'up', 'there', 'all', 'the', 'time', 'but', 'um', 'the', 'waterfalls', 'had', 'died', 'down', 'a', 'little', 'bit', 'you', 'know', 'and', 'so', 'uh', 'we-i', 'had', 'her', 'climb', 'up']\n","Updated Tokens (Row 38): ['yosemite', 'went', 'camping', 'right', 'like', 'usually', 'know', 'go', 'camping', 'time', 'um', 'waterfalls', 'died', 'little', 'bit', 'know', 'uh', 'we-i', 'climb']\n","Stopwords Removed (Row 38): ['i', 'did', 'it', 'up', 'at', 'we', 'we', 'do', 'you', 'we', 'up', 'there', 'all', 'the', 'but', 'the', 'had', 'down', 'a', 'you', 'and', 'so', 'had', 'her', 'up']\n","Stopwords were removed for Row 38 in file Ses05M_impro03.csv.\n","Original Tokens (Row 39): ['you', 'know', 'we', 'did', 'some', 'you', 'know', 'some', 'rock', 'climbing', 'up', 'the', 'waterfalls', 'and', 'went', 'up', 'to', 'this', 'little', 'pool', 'that', 'was', 'up', 'there', 'and', 'then', 'it', 'is', 'great', 'um', 'you', 'have', 'to', 'climb', 'this', 'little', 'rock']\n","Updated Tokens (Row 39): ['know', 'know', 'rock', 'climbing', 'waterfalls', 'went', 'little', 'pool', 'great', 'um', 'climb', 'little', 'rock']\n","Stopwords Removed (Row 39): ['you', 'we', 'did', 'some', 'you', 'some', 'up', 'the', 'and', 'up', 'to', 'this', 'that', 'was', 'up', 'there', 'and', 'then', 'it', 'is', 'you', 'have', 'to', 'this']\n","Stopwords were removed for Row 39 in file Ses05M_impro03.csv.\n","Original Tokens (Row 40): ['and', 'you', 'can', 'climb', 'it', 'and', 'it', 'is', 'covered', 'in', 'algae', 'you', 'know', 'so', 'i', 'wanted', 'her', 'to', 'climb', 'it', 'to', 'go', 'take', 'a', 'picture', 'like', 'back', 'in', 'this', 'little', 'waterfall', 'area', 'and', 'she', 'got', 'back', 'there', 'and', 'she', 'took', 'her', 'picture', 'and', 'then', 'i', 'had', 'her', 'come', 'back', 'and', 'i', 'was', 'going', 'to', 'do', 'the', 'same', 'thing']\n","Updated Tokens (Row 40): ['climb', 'covered', 'algae', 'know', 'wanted', 'climb', 'go', 'take', 'picture', 'like', 'back', 'little', 'waterfall', 'area', 'got', 'back', 'took', 'picture', 'come', 'back', 'going', 'thing']\n","Stopwords Removed (Row 40): ['and', 'you', 'can', 'it', 'and', 'it', 'is', 'in', 'you', 'so', 'i', 'her', 'to', 'it', 'to', 'a', 'in', 'this', 'and', 'she', 'there', 'and', 'she', 'her', 'and', 'then', 'i', 'had', 'her', 'and', 'i', 'was', 'to', 'do', 'the', 'same']\n","Stopwords were removed for Row 40 in file Ses05M_impro03.csv.\n","Original Tokens (Row 41): ['well', 'instead', 'i', 'climb', 'up', 'on', 'the', 'rock', 'and', 'like', 'i', 'did', 'not', 'do', 'it', 'well', 'i', 'did', 'it', 'on', 'purpose', 'i', 'made', 'it', 'look', 'like', 'i', 'accidentally', 'did', 'it', 'i', 'slipped', 'down', 'into', 'this', 'pool', 'of', 'water', 'right', 'and', 'she', 'freaks', 'out', 'because', 'i', 'slide', 'all', 'the', 'way', 'down', 'this', 'rock', 'and', 'um']\n","Updated Tokens (Row 41): ['well', 'instead', 'climb', 'rock', 'like', 'well', 'purpose', 'made', 'look', 'like', 'accidentally', 'slipped', 'pool', 'water', 'right', 'freaks', 'slide', 'way', 'rock', 'um']\n","Stopwords Removed (Row 41): ['i', 'up', 'on', 'the', 'and', 'i', 'did', 'not', 'do', 'it', 'i', 'did', 'it', 'on', 'i', 'it', 'i', 'did', 'it', 'i', 'down', 'into', 'this', 'of', 'and', 'she', 'out', 'because', 'i', 'all', 'the', 'down', 'this', 'and']\n","Stopwords were removed for Row 41 in file Ses05M_impro03.csv.\n","Original Tokens (Row 42): ['and', 'i', 'pop', 'up', 'out', 'of', 'the', 'water', 'and', 'i', 'had', 'planned', 'it', 'already', 'you', 'know', 'i', 'pop', 'up', 'out', 'of', 'the', 'water', 'and', 'i', 'breathing', 'and', 'i', 'like', 'grab', 'her', 'hand', 'you', 'know', 'and', 'that', 'in', 'my', 'hand', 'i', 'got', 'the', 'ring']\n","Updated Tokens (Row 42): ['pop', 'water', 'planned', 'already', 'know', 'pop', 'water', 'breathing', 'like', 'grab', 'hand', 'know', 'hand', 'got', 'ring']\n","Stopwords Removed (Row 42): ['and', 'i', 'up', 'out', 'of', 'the', 'and', 'i', 'had', 'it', 'you', 'i', 'up', 'out', 'of', 'the', 'and', 'i', 'and', 'i', 'her', 'you', 'and', 'that', 'in', 'my', 'i', 'the']\n","Stopwords were removed for Row 42 in file Ses05M_impro03.csv.\n","Original Tokens (Row 43): ['and', 'she', 'is', 'like', 'she', 'feels', 'it', 'you', 'know', 'and', 'she', 'does', 'not', 'know', 'what', 'it', 'is', 'and', 'she', 'you', 'know', 'helps', 'me', 'get', 'out', 'and', 'i', 'will', 'not', 'let', 'go', 'of', 'her', 'hand', 'and', 'she', 'is', 'like', 'what', 'are', 'you', 'doing', 'i', 'and', 'said', 'you', 'saved', 'my', 'life', 'now', 'will', 'you', 'marry', 'me']\n","Updated Tokens (Row 43): ['like', 'feels', 'know', 'know', 'know', 'helps', 'get', 'let', 'go', 'hand', 'like', 'said', 'saved', 'life', 'marry']\n","Stopwords Removed (Row 43): ['and', 'she', 'is', 'she', 'it', 'you', 'and', 'she', 'does', 'not', 'what', 'it', 'is', 'and', 'she', 'you', 'me', 'out', 'and', 'i', 'will', 'not', 'of', 'her', 'and', 'she', 'is', 'what', 'are', 'you', 'doing', 'i', 'and', 'you', 'my', 'now', 'will', 'you', 'me']\n","Stopwords were removed for Row 43 in file Ses05M_impro03.csv.\n","Original Tokens (Row 44): ['was', 'not', 'that', 'great', 'i', 'did', 'not', 'want', 'it', 'to', 'be', 'too', 'hokey.but', 'but', 'she', 'liked', 'it.she', 'liked', 'it']\n","Updated Tokens (Row 44): ['great', 'want', 'hokey.but', 'liked', 'it.she', 'liked']\n","Stopwords Removed (Row 44): ['was', 'not', 'that', 'i', 'did', 'not', 'it', 'to', 'be', 'too', 'but', 'she', 'it']\n","Stopwords were removed for Row 44 in file Ses05M_impro03.csv.\n","Original Tokens (Row 45): ['yeah', 'and', 'she', 'said', 'yes', 'and', 'she', 'cried', 'of', 'course']\n","Updated Tokens (Row 45): ['yeah', 'said', 'yes', 'cried', 'course']\n","Stopwords Removed (Row 45): ['and', 'she', 'and', 'she', 'of']\n","Stopwords were removed for Row 45 in file Ses05M_impro03.csv.\n","Original Tokens (Row 46): ['yes', 'we', 'did', 'that', 'in', 'the', 'beginning', 'exactly', 'so', 'we', 'had', 'so', 'we', 'just', 'had', 'you', 'know', 'good', 'times', 'the', 'rest', 'of', 'the', 'weekend', 'yeah']\n","Updated Tokens (Row 46): ['yes', 'beginning', 'exactly', 'know', 'good', 'times', 'rest', 'weekend', 'yeah']\n","Stopwords Removed (Row 46): ['we', 'did', 'that', 'in', 'the', 'so', 'we', 'had', 'so', 'we', 'just', 'had', 'you', 'the', 'of', 'the']\n","Stopwords were removed for Row 46 in file Ses05M_impro03.csv.\n","Original Tokens (Row 47): ['it', 'was', 'a', 'lot', 'of', 'fun', 'it', 'was', 'a', 'lot', 'of', 'fun', 'she', 'is', 'great', 'and', 'i', 'so', 'happy']\n","Updated Tokens (Row 47): ['lot', 'fun', 'lot', 'fun', 'great', 'happy']\n","Stopwords Removed (Row 47): ['it', 'was', 'a', 'of', 'it', 'was', 'a', 'of', 'she', 'is', 'and', 'i', 'so']\n","Stopwords were removed for Row 47 in file Ses05M_impro03.csv.\n","Original Tokens (Row 48): ['we', 'going', 'to', 'do', 'it', 'back', 'in', 'the', 'midwest', 'where', 'her', 'family', 'all', 'is', 'they', 'are', 'all', 'out', 'there', 'you', 'know', 'so', 'um', 'and', 'so', 'just', 'gon', 'na', 'have', 'a', 'small', 'small', 'wedding', 'but', 'um', 'you', 'know', 'of', 'course', 'you', 'going', 'to', 'come', 'right']\n","Updated Tokens (Row 48): ['going', 'back', 'midwest', 'family', 'know', 'um', 'gon', 'na', 'small', 'small', 'wedding', 'um', 'know', 'course', 'going', 'come', 'right']\n","Stopwords Removed (Row 48): ['we', 'to', 'do', 'it', 'in', 'the', 'where', 'her', 'all', 'is', 'they', 'are', 'all', 'out', 'there', 'you', 'so', 'and', 'so', 'just', 'have', 'a', 'but', 'you', 'of', 'you', 'to']\n","Stopwords were removed for Row 48 in file Ses05M_impro03.csv.\n","Original Tokens (Row 49): ['okay', 'good', 'and', 'uh', 'i', 'want', 'you', 'to', 'be', 'in', 'it', 'actually']\n","Updated Tokens (Row 49): ['okay', 'good', 'uh', 'want', 'actually']\n","Stopwords Removed (Row 49): ['and', 'i', 'you', 'to', 'be', 'in', 'it']\n","Stopwords were removed for Row 49 in file Ses05M_impro03.csv.\n","Original Tokens (Row 50): ['um', 'and', 'she', 'wants', 'you', 'to', 'be', 'in', 'it', 'too', 'she', 'loves', 'you', 'so', 'much', 'she', 'thinks', 'you', 'the', 'sweetest', 'of', 'course', 'you', 'are', 'you', 'you', 'my', 'best', 'friend', 'so']\n","Updated Tokens (Row 50): ['um', 'wants', 'loves', 'much', 'thinks', 'sweetest', 'course', 'best', 'friend']\n","Stopwords Removed (Row 50): ['and', 'she', 'you', 'to', 'be', 'in', 'it', 'too', 'she', 'you', 'so', 'she', 'you', 'the', 'of', 'you', 'are', 'you', 'you', 'my', 'so']\n","Stopwords were removed for Row 50 in file Ses05M_impro03.csv.\n","Original Tokens (Row 51): ['oh', 'she', 'is', 'back', 'at', 'work', 'yeah']\n","Updated Tokens (Row 51): ['oh', 'back', 'work', 'yeah']\n","Stopwords Removed (Row 51): ['she', 'is', 'at']\n","Stopwords were removed for Row 51 in file Ses05M_impro03.csv.\n","Original Tokens (Row 52): ['of', 'course', 'we', 'go', 'out', 'to', 'dinner', 'later', 'this', 'week']\n","Updated Tokens (Row 52): ['course', 'go', 'dinner', 'later', 'week']\n","Stopwords Removed (Row 52): ['of', 'we', 'out', 'to', 'this']\n","Stopwords were removed for Row 52 in file Ses05M_impro03.csv.\n","Original Tokens (Row 53): ['it', 'will', 'be', 'perfect']\n","Updated Tokens (Row 53): ['perfect']\n","Stopwords Removed (Row 53): ['it', 'will', 'be']\n","Stopwords were removed for Row 53 in file Ses05M_impro03.csv.\n","Original Tokens (Row 54): ['yes', 'me', 'too', 'oh', 'i', 'am', 'so', 'in', 'love']\n","Updated Tokens (Row 54): ['yes', 'oh', 'love']\n","Stopwords Removed (Row 54): ['me', 'too', 'i', 'am', 'so', 'in']\n","Stopwords were removed for Row 54 in file Ses05M_impro03.csv.\n","Original Tokens (Row 55): ['she', 'is', 'the', 'one']\n","Updated Tokens (Row 55): ['one']\n","Stopwords Removed (Row 55): ['she', 'is', 'the']\n","Stopwords were removed for Row 55 in file Ses05M_impro03.csv.\n","Original Tokens (Row 56): ['of', 'course', 'i', 'told', 'them', 'right', 'away', 'we', 'called', 'them', 'all', 'right', 'them']\n","Updated Tokens (Row 56): ['course', 'told', 'right', 'away', 'called', 'right']\n","Stopwords Removed (Row 56): ['of', 'i', 'them', 'we', 'them', 'all', 'them']\n","Stopwords were removed for Row 56 in file Ses05M_impro03.csv.\n","Original Tokens (Row 57): ['oh', 'yeah', 'my', 'mom', 'freaking', 'out', 'oh', 'yeah', 'she', 'is', 'so', 'happy', 'this', 'is', 'you', 'know', 'it', 'is', 'her', 'dream', 'come', 'true', 'she', 'always', 'wanted', 'her', 'little', 'boy', 'she', 'wants', 'kids', 'you', 'know']\n","Updated Tokens (Row 57): ['oh', 'yeah', 'mom', 'freaking', 'oh', 'yeah', 'happy', 'know', 'dream', 'come', 'true', 'always', 'wanted', 'little', 'boy', 'wants', 'kids', 'know']\n","Stopwords Removed (Row 57): ['my', 'out', 'she', 'is', 'so', 'this', 'is', 'you', 'it', 'is', 'her', 'she', 'her', 'she', 'you']\n","Stopwords were removed for Row 57 in file Ses05M_impro03.csv.\n","Original Tokens (Row 58): ['she', 'wants', 'grandkids', 'so', 'we', 'be', 'working', 'on', 'that', 'right', 'away']\n","Updated Tokens (Row 58): ['wants', 'grandkids', 'working', 'right', 'away']\n","Stopwords Removed (Row 58): ['she', 'so', 'we', 'be', 'on', 'that']\n","Stopwords were removed for Row 58 in file Ses05M_impro03.csv.\n","Original Tokens (Row 59): ['of', 'course', 'we', 'gon', 'na', 'have', 'kids', 'like', 'three', 'at', 'least']\n","Updated Tokens (Row 59): ['course', 'gon', 'na', 'kids', 'like', 'three', 'least']\n","Stopwords Removed (Row 59): ['of', 'we', 'have', 'at']\n","Stopwords were removed for Row 59 in file Ses05M_impro03.csv.\n","Original Tokens (Row 60): ['she', 'wants', 'like', 'eight', 'she', 'wants', 'like', 'eight', 'kids', 'and', 'i', 'like', 'no', 'no', 'no', 'no', 'no', 'i', 'am', 'like', 'what', 'let', 'do', 'maybe', 'three', 'and', 'we', 'go', 'with', 'that']\n","Updated Tokens (Row 60): ['wants', 'like', 'eight', 'wants', 'like', 'eight', 'kids', 'like', 'like', 'let', 'maybe', 'three', 'go']\n","Stopwords Removed (Row 60): ['she', 'she', 'and', 'i', 'no', 'no', 'no', 'no', 'no', 'i', 'am', 'what', 'do', 'and', 'we', 'with', 'that']\n","Stopwords were removed for Row 60 in file Ses05M_impro03.csv.\n","Original Tokens (Row 61): ['well', 'we', 'going', 'to', 'take', 'a', 'little', 'bit', 'of', 'time', 'you', 'know', 'we', 'need', 'to', 'get', 'acclimated', 'and', 'you', 'know', 'start', 'our', 'lives', 'make', 'money', 'you', 'know', 'be', 'comfortable']\n","Updated Tokens (Row 61): ['well', 'going', 'take', 'little', 'bit', 'time', 'know', 'need', 'get', 'acclimated', 'know', 'start', 'lives', 'make', 'money', 'know', 'comfortable']\n","Stopwords Removed (Row 61): ['we', 'to', 'a', 'of', 'you', 'we', 'to', 'and', 'you', 'our', 'you', 'be']\n","Stopwords were removed for Row 61 in file Ses05M_impro03.csv.\n","Original Tokens (Row 62): ['oh', 'yeah', 'yeah', 'yeah', 'yeah', 'i', 'mean', 'actually', 'we', 'lived', 'together', 'awhile', 'back', 'when', 'we', 'yeah', 'back', 'in', 'college', 'for', 'a', 'little', 'while', 'yeah']\n","Updated Tokens (Row 62): ['oh', 'yeah', 'yeah', 'yeah', 'yeah', 'mean', 'actually', 'lived', 'together', 'awhile', 'back', 'yeah', 'back', 'college', 'little', 'yeah']\n","Stopwords Removed (Row 62): ['i', 'we', 'when', 'we', 'in', 'for', 'a', 'while']\n","Stopwords were removed for Row 62 in file Ses05M_impro03.csv.\n","Original Tokens (Row 63): ['but', 'that', 'so', 'we', 'are', 'really', 'used', 'to', 'each', 'other', 'we', 'took', 'the', 'time', 'apart', 'and', 'now', 'we', 'going', 'to', 'get', 'back', 'together', 'we', 'going', 'to', 'move', 'in', 'soon']\n","Updated Tokens (Row 63): ['really', 'used', 'took', 'time', 'apart', 'going', 'get', 'back', 'together', 'going', 'move', 'soon']\n","Stopwords Removed (Row 63): ['but', 'that', 'so', 'we', 'are', 'to', 'each', 'other', 'we', 'the', 'and', 'now', 'we', 'to', 'we', 'to', 'in']\n","Stopwords were removed for Row 63 in file Ses05M_impro03.csv.\n","Original Tokens (Row 64): ['it', 'is', 'great', 'i', 'a', 'lucky', 'man']\n","Updated Tokens (Row 64): ['great', 'lucky', 'man']\n","Stopwords Removed (Row 64): ['it', 'is', 'i', 'a']\n","Stopwords were removed for Row 64 in file Ses05M_impro03.csv.\n","Original Tokens (Row 65): ['thank', 'you']\n","Updated Tokens (Row 65): ['thank']\n","Stopwords Removed (Row 65): ['you']\n","Stopwords were removed for Row 65 in file Ses05M_impro03.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro03.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro03.csv\n","\n","Processing File: Ses05M_impro04.csv\n","Original Tokens (Row 0): ['what', 'do', 'you', 'mean']\n","Updated Tokens (Row 0): ['mean']\n","Stopwords Removed (Row 0): ['what', 'do', 'you']\n","Stopwords were removed for Row 0 in file Ses05M_impro04.csv.\n","Original Tokens (Row 1): ['really', 'it', 'is', 'been', 'that', 'long']\n","Updated Tokens (Row 1): ['really', 'long']\n","Stopwords Removed (Row 1): ['it', 'is', 'been', 'that']\n","Stopwords were removed for Row 1 in file Ses05M_impro04.csv.\n","Original Tokens (Row 2): ['wow']\n","Updated Tokens (Row 2): ['wow']\n","Stopwords Removed (Row 2): []\n","No stopwords removed for Row 2 in file Ses05M_impro04.csv.\n","Original Tokens (Row 3): ['what', 'have', 'you', 'been', 'trying']\n","Updated Tokens (Row 3): ['trying']\n","Stopwords Removed (Row 3): ['what', 'have', 'you', 'been']\n","Stopwords were removed for Row 3 in file Ses05M_impro04.csv.\n","Original Tokens (Row 4): ['right']\n","Updated Tokens (Row 4): ['right']\n","Stopwords Removed (Row 4): []\n","No stopwords removed for Row 4 in file Ses05M_impro04.csv.\n","Original Tokens (Row 5): ['well', 'i', 'mean', 'right', 'now', 'i', 'just', 'doing', 'a', 'little', 'bit', 'of', 'everything', 'and', 'i', 'do', 'not', 'i', 'do', 'not', 'think', 'that', 'i', 'in', 'like', 'a', 'profession', 'like', 'career', 'oriented', 'place']\n","Updated Tokens (Row 5): ['well', 'mean', 'right', 'little', 'bit', 'everything', 'think', 'like', 'profession', 'like', 'career', 'oriented', 'place']\n","Stopwords Removed (Row 5): ['i', 'now', 'i', 'just', 'doing', 'a', 'of', 'and', 'i', 'do', 'not', 'i', 'do', 'not', 'that', 'i', 'in', 'a']\n","Stopwords were removed for Row 5 in file Ses05M_impro04.csv.\n","Original Tokens (Row 6): ['no', 'i', 'just', 'working', 'in', 'restaurants', 'and', 'stuff', 'but', 'i', 'also', 'trying', 'to', 'audition', 'and', 'what', 'not', 'so', 'it', 'is']\n","Updated Tokens (Row 6): ['working', 'restaurants', 'stuff', 'also', 'trying', 'audition']\n","Stopwords Removed (Row 6): ['no', 'i', 'just', 'in', 'and', 'but', 'i', 'to', 'and', 'what', 'not', 'so', 'it', 'is']\n","Stopwords were removed for Row 6 in file Ses05M_impro04.csv.\n","Original Tokens (Row 7): ['really']\n","Updated Tokens (Row 7): ['really']\n","Stopwords Removed (Row 7): []\n","No stopwords removed for Row 7 in file Ses05M_impro04.csv.\n","Original Tokens (Row 8): ['l.a.', 'is', 'really', 'hard', 'i', 'mean', 'have', 'you', 'tried', 'like', 'just', 'going', 'into', 'a', 'bar', 'a', 'couple', 'of', 'times', 'to', 'make', 'friends', 'with', 'people', 'who', 'work', 'there', 'and']\n","Updated Tokens (Row 8): ['l.a.', 'really', 'hard', 'mean', 'tried', 'like', 'going', 'bar', 'couple', 'times', 'make', 'friends', 'people', 'work']\n","Stopwords Removed (Row 8): ['is', 'i', 'have', 'you', 'just', 'into', 'a', 'a', 'of', 'to', 'with', 'who', 'there', 'and']\n","Stopwords were removed for Row 8 in file Ses05M_impro04.csv.\n","Original Tokens (Row 9): ['i', 'was', 'just', 'going', 'to', 'say', 'that', 'is', 'your', 'issue', 'maybe', 'you', 'are', 'going', 'in', 'too', 'much', 'no', 'i', 'mean', 'just']\n","Updated Tokens (Row 9): ['going', 'say', 'issue', 'maybe', 'going', 'much', 'mean']\n","Stopwords Removed (Row 9): ['i', 'was', 'just', 'to', 'that', 'is', 'your', 'you', 'are', 'in', 'too', 'no', 'i', 'just']\n","Stopwords were removed for Row 9 in file Ses05M_impro04.csv.\n","Original Tokens (Row 10): ['are', 'you', 'going', 'into', 'the', 'bars', 'every', 'night']\n","Updated Tokens (Row 10): ['going', 'bars', 'every', 'night']\n","Stopwords Removed (Row 10): ['are', 'you', 'into', 'the']\n","Stopwords were removed for Row 10 in file Ses05M_impro04.csv.\n","Original Tokens (Row 11): ['well', 'i', 'do', 'not', 'really', 'know', 'i', 'do', 'not', 'i', 'do', 'not', 'know', 'you', 'in', 'like', 'a', 'job', 'situation', 'so']\n","Updated Tokens (Row 11): ['well', 'really', 'know', 'know', 'like', 'job', 'situation']\n","Stopwords Removed (Row 11): ['i', 'do', 'not', 'i', 'do', 'not', 'i', 'do', 'not', 'you', 'in', 'a', 'so']\n","Stopwords were removed for Row 11 in file Ses05M_impro04.csv.\n","Original Tokens (Row 12): ['wow', 'i', 'do', 'not', 'i', 'mean', 'do', 'you', 'do', 'you', 'have', 'an', 'attitude', 'problem', 'when', 'you', 'on', 'the', 'job']\n","Updated Tokens (Row 12): ['wow', 'mean', 'attitude', 'problem', 'job']\n","Stopwords Removed (Row 12): ['i', 'do', 'not', 'i', 'do', 'you', 'do', 'you', 'have', 'an', 'when', 'you', 'on', 'the']\n","Stopwords were removed for Row 12 in file Ses05M_impro04.csv.\n","Original Tokens (Row 13): ['maybe', 'garbage']\n","Updated Tokens (Row 13): ['maybe', 'garbage']\n","Stopwords Removed (Row 13): []\n","No stopwords removed for Row 13 in file Ses05M_impro04.csv.\n","Original Tokens (Row 14): ['right', 'maybe', 'you', 'have', 'like', 'you', 'know', 'a', 'little', 'bit', 'of', 'an', 'abrasive', 'vibe', 'or', 'something']\n","Updated Tokens (Row 14): ['right', 'maybe', 'like', 'know', 'little', 'bit', 'abrasive', 'vibe', 'something']\n","Stopwords Removed (Row 14): ['you', 'have', 'you', 'a', 'of', 'an', 'or']\n","Stopwords were removed for Row 14 in file Ses05M_impro04.csv.\n","Original Tokens (Row 15): ['i', 'do', 'not', 'know', 'i', 'i', 'just', 'trying']\n","Updated Tokens (Row 15): ['know', 'trying']\n","Stopwords Removed (Row 15): ['i', 'do', 'not', 'i', 'i', 'just']\n","Stopwords were removed for Row 15 in file Ses05M_impro04.csv.\n","Original Tokens (Row 16): ['are', 'you', 'getting', 'defensive']\n","Updated Tokens (Row 16): ['getting', 'defensive']\n","Stopwords Removed (Row 16): ['are', 'you']\n","Stopwords were removed for Row 16 in file Ses05M_impro04.csv.\n","Original Tokens (Row 17): ['yeah', 'that', 'might', 'be', 'something', 'you', 'want', 'to', 'look', 'at', 'i', 'mean']\n","Updated Tokens (Row 17): ['yeah', 'might', 'something', 'want', 'look', 'mean']\n","Stopwords Removed (Row 17): ['that', 'be', 'you', 'to', 'at', 'i']\n","Stopwords were removed for Row 17 in file Ses05M_impro04.csv.\n","Original Tokens (Row 18): ['okay']\n","Updated Tokens (Row 18): ['okay']\n","Stopwords Removed (Row 18): []\n","No stopwords removed for Row 18 in file Ses05M_impro04.csv.\n","Original Tokens (Row 19): ['i', 'understand']\n","Updated Tokens (Row 19): ['understand']\n","Stopwords Removed (Row 19): ['i']\n","Stopwords were removed for Row 19 in file Ses05M_impro04.csv.\n","Original Tokens (Row 20): ['yeah', 'it', 'is', 'stressful', 'i', 'recognize', 'that']\n","Updated Tokens (Row 20): ['yeah', 'stressful', 'recognize']\n","Stopwords Removed (Row 20): ['it', 'is', 'i', 'that']\n","Stopwords were removed for Row 20 in file Ses05M_impro04.csv.\n","Original Tokens (Row 21): ['ah']\n","Updated Tokens (Row 21): ['ah']\n","Stopwords Removed (Row 21): []\n","No stopwords removed for Row 21 in file Ses05M_impro04.csv.\n","Original Tokens (Row 22): ['not', 'not', 'selling', 'pot', 'right']\n","Updated Tokens (Row 22): ['selling', 'pot', 'right']\n","Stopwords Removed (Row 22): ['not', 'not']\n","Stopwords were removed for Row 22 in file Ses05M_impro04.csv.\n","Original Tokens (Row 23): ['okay', 'so']\n","Updated Tokens (Row 23): ['okay']\n","Stopwords Removed (Row 23): ['so']\n","Stopwords were removed for Row 23 in file Ses05M_impro04.csv.\n","Original Tokens (Row 24): ['fair', 'enough']\n","Updated Tokens (Row 24): ['fair', 'enough']\n","Stopwords Removed (Row 24): []\n","No stopwords removed for Row 24 in file Ses05M_impro04.csv.\n","Original Tokens (Row 25): ['yeah', 'laughter', 'it', 'is', 'a', 'joke']\n","Updated Tokens (Row 25): ['yeah', 'laughter', 'joke']\n","Stopwords Removed (Row 25): ['it', 'is', 'a']\n","Stopwords were removed for Row 25 in file Ses05M_impro04.csv.\n","Original Tokens (Row 26): ['sorry', 'so', 'let', 'see', 'what', 'else', 'what', 'is', 'available', 'what', 'um', 'hmm']\n","Updated Tokens (Row 26): ['sorry', 'let', 'see', 'else', 'available', 'um', 'hmm']\n","Stopwords Removed (Row 26): ['so', 'what', 'what', 'is', 'what']\n","Stopwords were removed for Row 26 in file Ses05M_impro04.csv.\n","Original Tokens (Row 27): ['well', 'not', 'off', 'the', 'top', 'of', 'head', 'it', 'will', 'just', 'take', 'you', 'know', 'take', 'a', 'minute', 'but', 'do', 'you', 'have', 'any', 'like', 'special', 'skills']\n","Updated Tokens (Row 27): ['well', 'top', 'head', 'take', 'know', 'take', 'minute', 'like', 'special', 'skills']\n","Stopwords Removed (Row 27): ['not', 'off', 'the', 'of', 'it', 'will', 'just', 'you', 'a', 'but', 'do', 'you', 'have', 'any']\n","Stopwords were removed for Row 27 in file Ses05M_impro04.csv.\n","Original Tokens (Row 28): ['well', 'maybe', 'we', 'can', 'find', 'you', 'something', 'with', 'juggling']\n","Updated Tokens (Row 28): ['well', 'maybe', 'find', 'something', 'juggling']\n","Stopwords Removed (Row 28): ['we', 'can', 'you', 'with']\n","Stopwords were removed for Row 28 in file Ses05M_impro04.csv.\n","Original Tokens (Row 29): ['have', 'you', 'checked', 'out', 'craig', 'list', 'and', 'stuff']\n","Updated Tokens (Row 29): ['checked', 'craig', 'list', 'stuff']\n","Stopwords Removed (Row 29): ['have', 'you', 'out', 'and']\n","Stopwords were removed for Row 29 in file Ses05M_impro04.csv.\n","Original Tokens (Row 30): ['what', 'if', 'you', 'do', 'kids', 'parties', 'oh', 'come', 'on']\n","Updated Tokens (Row 30): ['kids', 'parties', 'oh', 'come']\n","Stopwords Removed (Row 30): ['what', 'if', 'you', 'do', 'on']\n","Stopwords were removed for Row 30 in file Ses05M_impro04.csv.\n","Original Tokens (Row 31): ['okay', 'all', 'right']\n","Updated Tokens (Row 31): ['okay', 'right']\n","Stopwords Removed (Row 31): ['all']\n","Stopwords were removed for Row 31 in file Ses05M_impro04.csv.\n","Original Tokens (Row 32): ['okay', 'well', 'fine', 'we', 'will', 'not', 'i', 'will', 'not', 'argue', 'with', 'you', 'about', 'that']\n","Updated Tokens (Row 32): ['okay', 'well', 'fine', 'argue']\n","Stopwords Removed (Row 32): ['we', 'will', 'not', 'i', 'will', 'not', 'with', 'you', 'about', 'that']\n","Stopwords were removed for Row 32 in file Ses05M_impro04.csv.\n","Original Tokens (Row 33): ['what', 'else', 'i', 'can', 'not', 'uh', 'i', 'drawing', 'a', 'blank', 'here']\n","Updated Tokens (Row 33): ['else', 'uh', 'drawing', 'blank']\n","Stopwords Removed (Row 33): ['what', 'i', 'can', 'not', 'i', 'a', 'here']\n","Stopwords were removed for Row 33 in file Ses05M_impro04.csv.\n","Original Tokens (Row 34): ['that', 'is', 'rough', 'i', 'really', 'sorry', 'ryan']\n","Updated Tokens (Row 34): ['rough', 'really', 'sorry', 'ryan']\n","Stopwords Removed (Row 34): ['that', 'is', 'i']\n","Stopwords were removed for Row 34 in file Ses05M_impro04.csv.\n","Original Tokens (Row 35): ['well', 'um', 'is', 'that', 'kinda', 'like', 'the', 'side', 'of', 'you', 'that', 'you', 'let', 'people', 'see', 'when', 'you', 'go', 'into', 'these', 'job', 'interviews']\n","Updated Tokens (Row 35): ['well', 'um', 'kinda', 'like', 'side', 'let', 'people', 'see', 'go', 'job', 'interviews']\n","Stopwords Removed (Row 35): ['is', 'that', 'the', 'of', 'you', 'that', 'you', 'when', 'you', 'into', 'these']\n","Stopwords were removed for Row 35 in file Ses05M_impro04.csv.\n","Original Tokens (Row 36): ['okay', 'well', 'that', 'is', 'good', 'yeah', 'i', 'mean', 'you', \"you're\", 'when', 'you', 'happy', 'you', 'a', 'pretty', 'personable', 'guy', 'and', 'i', 'do', 'not', 'i', 'do', 'not']\n","Updated Tokens (Row 36): ['okay', 'well', 'good', 'yeah', 'mean', 'happy', 'pretty', 'personable', 'guy']\n","Stopwords Removed (Row 36): ['that', 'is', 'i', 'you', \"you're\", 'when', 'you', 'you', 'a', 'and', 'i', 'do', 'not', 'i', 'do', 'not']\n","Stopwords were removed for Row 36 in file Ses05M_impro04.csv.\n","Original Tokens (Row 37): ['i', 'can', 'not', 'see', 'where', 'the', 'issue', 'would', 'be', 'so']\n","Updated Tokens (Row 37): ['see', 'issue', 'would']\n","Stopwords Removed (Row 37): ['i', 'can', 'not', 'where', 'the', 'be', 'so']\n","Stopwords were removed for Row 37 in file Ses05M_impro04.csv.\n","Original Tokens (Row 38): ['i', 'sorry', 'good', 'luck', 'man']\n","Updated Tokens (Row 38): ['sorry', 'good', 'luck', 'man']\n","Stopwords Removed (Row 38): ['i']\n","Stopwords were removed for Row 38 in file Ses05M_impro04.csv.\n","Original Tokens (Row 39): ['uh', 'god', 'i', 'do', 'not', 'know', 'what', 'to', 'do', 'anymore', 'like', 'i', 'said']\n","Updated Tokens (Row 39): ['uh', 'god', 'know', 'anymore', 'like', 'said']\n","Stopwords Removed (Row 39): ['i', 'do', 'not', 'what', 'to', 'do', 'i']\n","Stopwords were removed for Row 39 in file Ses05M_impro04.csv.\n","Original Tokens (Row 40): ['i', 'do', 'not', 'know', 'there', 'nothing', 'for', 'me', 'out', 'there', 'i', 'can', 'not', 'get', 'a', 'job', 'i', 'have', 'gotten', 'a', 'job', 'in', 'a', 'year', 'three', 'years', 'what', 'is', 'it', 'three', 'years', 'now', 'right', 'that', 'i', 'have', 'been', 'able', 'to', 'have', 'a', 'job']\n","Updated Tokens (Row 40): ['know', 'nothing', 'get', 'job', 'gotten', 'job', 'year', 'three', 'years', 'three', 'years', 'right', 'able', 'job']\n","Stopwords Removed (Row 40): ['i', 'do', 'not', 'there', 'for', 'me', 'out', 'there', 'i', 'can', 'not', 'a', 'i', 'have', 'a', 'in', 'a', 'what', 'is', 'it', 'now', 'that', 'i', 'have', 'been', 'to', 'have', 'a']\n","Stopwords were removed for Row 40 in file Ses05M_impro04.csv.\n","Original Tokens (Row 41): ['something', 'like', 'that', 'i', 'can', 'not', 'even', 'remember', 'anymore', 'i', 'do', 'not', 'know', 'what', 'to', 'do', 'anymore', 'i', 'just', 'get', 'out', 'there', 'everyday', 'well', 'not', 'everyday', 'almost', 'everyday']\n","Updated Tokens (Row 41): ['something', 'like', 'even', 'remember', 'anymore', 'know', 'anymore', 'get', 'everyday', 'well', 'everyday', 'almost', 'everyday']\n","Stopwords Removed (Row 41): ['that', 'i', 'can', 'not', 'i', 'do', 'not', 'what', 'to', 'do', 'i', 'just', 'out', 'there', 'not']\n","Stopwords were removed for Row 41 in file Ses05M_impro04.csv.\n","Original Tokens (Row 42): ['and', 'try', 'to', 'do', 'something', 'i', 'mean']\n","Updated Tokens (Row 42): ['try', 'something', 'mean']\n","Stopwords Removed (Row 42): ['and', 'to', 'do', 'i']\n","Stopwords were removed for Row 42 in file Ses05M_impro04.csv.\n","Original Tokens (Row 43): ['well', 'everything', 'i', 'do', 'temping', 'you', 'know', 'office', 'work', 'you', 'know', 'whatever', 'to', 'pay', 'the', 'bills', 'you', 'know', 'i', 'do', 'anything']\n","Updated Tokens (Row 43): ['well', 'everything', 'temping', 'know', 'office', 'work', 'know', 'whatever', 'pay', 'bills', 'know', 'anything']\n","Stopwords Removed (Row 43): ['i', 'do', 'you', 'you', 'to', 'the', 'you', 'i', 'do']\n","Stopwords were removed for Row 43 in file Ses05M_impro04.csv.\n","Original Tokens (Row 44): ['but', 'i', 'mean', 'i', 'do', 'not', 'want', 'to', 'keep', 'those', 'jobs', 'i', 'do', 'not', 'want', 'those', 'jobs.it', 'is', 'not', 'what', 'i', 'want', 'to', 'do']\n","Updated Tokens (Row 44): ['mean', 'want', 'keep', 'jobs', 'want', 'jobs.it', 'want']\n","Stopwords Removed (Row 44): ['but', 'i', 'i', 'do', 'not', 'to', 'those', 'i', 'do', 'not', 'those', 'is', 'not', 'what', 'i', 'to', 'do']\n","Stopwords were removed for Row 44 in file Ses05M_impro04.csv.\n","Original Tokens (Row 45): ['but', 'i', 'do', 'not', 'know', 'god', 'what', 'am', 'i', 'going', 'to', 'do', 'should', 'i', 'go', 'back', 'to', 'school', 'i', 'can', 'not', 'i', 'can', 'not', 'afford', 'to', 'go', 'back', 'to', 'school']\n","Updated Tokens (Row 45): ['know', 'god', 'going', 'go', 'back', 'school', 'afford', 'go', 'back', 'school']\n","Stopwords Removed (Row 45): ['but', 'i', 'do', 'not', 'what', 'am', 'i', 'to', 'do', 'should', 'i', 'to', 'i', 'can', 'not', 'i', 'can', 'not', 'to', 'to']\n","Stopwords were removed for Row 45 in file Ses05M_impro04.csv.\n","Original Tokens (Row 46): ['what', 'do', 'you', 'do']\n","Updated Tokens (Row 46): []\n","Stopwords Removed (Row 46): ['what', 'do', 'you', 'do']\n","Stopwords were removed for Row 46 in file Ses05M_impro04.csv.\n","Original Tokens (Row 47): ['you', 'plan', 'on', 'being', 'there', 'forever', 'i', 'mean', 'like', 'what', 'do', 'you']\n","Updated Tokens (Row 47): ['plan', 'forever', 'mean', 'like']\n","Stopwords Removed (Row 47): ['you', 'on', 'being', 'there', 'i', 'what', 'do', 'you']\n","Stopwords were removed for Row 47 in file Ses05M_impro04.csv.\n","Original Tokens (Row 48): ['yeah']\n","Updated Tokens (Row 48): ['yeah']\n","Stopwords Removed (Row 48): []\n","No stopwords removed for Row 48 in file Ses05M_impro04.csv.\n","Original Tokens (Row 49): ['right']\n","Updated Tokens (Row 49): ['right']\n","Stopwords Removed (Row 49): []\n","No stopwords removed for Row 49 in file Ses05M_impro04.csv.\n","Original Tokens (Row 50): ['yeah', 'yeah', 'well', 'hello', 'that', 'is', 'what', 'i', 'doing', 'too', 'but', 'i', 'can', 'not', 'get', 'the', 'restaurant', 'job', 'i', 'can', 'not', 'get', 'the', 'restaurant', 'gig', 'no', 'one', 'will', 'give', 'me', 'anything']\n","Updated Tokens (Row 50): ['yeah', 'yeah', 'well', 'hello', 'get', 'restaurant', 'job', 'get', 'restaurant', 'gig', 'one', 'give', 'anything']\n","Stopwords Removed (Row 50): ['that', 'is', 'what', 'i', 'doing', 'too', 'but', 'i', 'can', 'not', 'the', 'i', 'can', 'not', 'the', 'no', 'will', 'me']\n","Stopwords were removed for Row 50 in file Ses05M_impro04.csv.\n","Original Tokens (Row 51): ['i', 'go', 'in', 'for', 'these', 'interviews', 'and', 'they', 'are', 'all', 'cool', 'and', 'everything', 'you', 'know', 'their', 'nice', 'and', 'i', 'nice', 'to', 'them', 'you', 'know', 'give', 'and', 'take', 'back', 'and', 'forth', 'and', 'whatever']\n","Updated Tokens (Row 51): ['go', 'interviews', 'cool', 'everything', 'know', 'nice', 'nice', 'know', 'give', 'take', 'back', 'forth', 'whatever']\n","Stopwords Removed (Row 51): ['i', 'in', 'for', 'these', 'and', 'they', 'are', 'all', 'and', 'you', 'their', 'and', 'i', 'to', 'them', 'you', 'and', 'and', 'and']\n","Stopwords were removed for Row 51 in file Ses05M_impro04.csv.\n","Original Tokens (Row 52): ['but', 'they', 'always', 'go', 'with', 'somebody', 'else']\n","Updated Tokens (Row 52): ['always', 'go', 'somebody', 'else']\n","Stopwords Removed (Row 52): ['but', 'they', 'with']\n","Stopwords were removed for Row 52 in file Ses05M_impro04.csv.\n","Original Tokens (Row 53): ['yeah', 'absolutely', 'hello', 'you', 'know', 'me', 'i', 'go', 'to', 'bars', 'all', 'the', 'time', 'like', 'they', 'all', 'know', 'me', 'you', 'know', 'but', 'no', 'one', 'wants', 'to', 'hire', 'me']\n","Updated Tokens (Row 53): ['yeah', 'absolutely', 'hello', 'know', 'go', 'bars', 'time', 'like', 'know', 'know', 'one', 'wants', 'hire']\n","Stopwords Removed (Row 53): ['you', 'me', 'i', 'to', 'all', 'the', 'they', 'all', 'me', 'you', 'but', 'no', 'to', 'me']\n","Stopwords were removed for Row 53 in file Ses05M_impro04.csv.\n","Original Tokens (Row 54): ['but', 'maybe', 'they', 'do', 'not', 'want', 'to', 'hire', 'me', 'because', 'they', 'know', 'me', 'i', 'do', 'not', 'know', 'what', 'is', 'wrong', 'with', 'me', 'is', 'there', 'something', 'wrong', 'with', 'me']\n","Updated Tokens (Row 54): ['maybe', 'want', 'hire', 'know', 'know', 'wrong', 'something', 'wrong']\n","Stopwords Removed (Row 54): ['but', 'they', 'do', 'not', 'to', 'me', 'because', 'they', 'me', 'i', 'do', 'not', 'what', 'is', 'with', 'me', 'is', 'there', 'with', 'me']\n","Stopwords were removed for Row 54 in file Ses05M_impro04.csv.\n","Original Tokens (Row 55): ['i', 'mean', 'you', 'can', 'tell', 'me', 'what', 'why', 'is', 'no', 'one', 'hiring', 'me', 'is', 'it', 'me', 'be', 'honest', 'you', 'can', 'tell', 'me', 'you', 'know', 'i', 'can', 'take', 'it', 'i', 'can', 'take', 'it', 'you', 'just', 'tell', 'me', 'why']\n","Updated Tokens (Row 55): ['mean', 'tell', 'one', 'hiring', 'honest', 'tell', 'know', 'take', 'take', 'tell']\n","Stopwords Removed (Row 55): ['i', 'you', 'can', 'me', 'what', 'why', 'is', 'no', 'me', 'is', 'it', 'me', 'be', 'you', 'can', 'me', 'you', 'i', 'can', 'it', 'i', 'can', 'it', 'you', 'just', 'me', 'why']\n","Stopwords were removed for Row 55 in file Ses05M_impro04.csv.\n","Original Tokens (Row 56): ['yeah', 'but', 'i', 'okay', 'well', 'how', 'about', 'personality', 'wise', 'i', 'mean', 'people', 'who', 'know', 'me', 'will', 'not', 'hire', 'me', 'why']\n","Updated Tokens (Row 56): ['yeah', 'okay', 'well', 'personality', 'wise', 'mean', 'people', 'know', 'hire']\n","Stopwords Removed (Row 56): ['but', 'i', 'how', 'about', 'i', 'who', 'me', 'will', 'not', 'me', 'why']\n","Stopwords were removed for Row 56 in file Ses05M_impro04.csv.\n","Original Tokens (Row 57): ['i', 'do', 'not', 'think', 'i', 'have', 'an', 'attitude', 'problem', 'when', 'i', 'on', 'the', 'job', 'no', 'i', 'have', 'an', 'attitude', 'problem', 'right', 'now', 'because', 'i', 'do', 'not', 'have', 'a', 'job']\n","Updated Tokens (Row 57): ['think', 'attitude', 'problem', 'job', 'attitude', 'problem', 'right', 'job']\n","Stopwords Removed (Row 57): ['i', 'do', 'not', 'i', 'have', 'an', 'when', 'i', 'on', 'the', 'no', 'i', 'have', 'an', 'now', 'because', 'i', 'do', 'not', 'have', 'a']\n","Stopwords were removed for Row 57 in file Ses05M_impro04.csv.\n","Original Tokens (Row 58): ['an', 'abrasive', 'vibe']\n","Updated Tokens (Row 58): ['abrasive', 'vibe']\n","Stopwords Removed (Row 58): ['an']\n","Stopwords were removed for Row 58 in file Ses05M_impro04.csv.\n","Original Tokens (Row 59): ['let', 'me', 'know', 'that', 'is', 'that', 'is', 'fine', 'you', 'think', 'i', 'have', 'an', 'abrasive', 'vibe', 'whatever', 'you', 'entitled', 'to', 'your', 'opinion', 'of', 'course', 'maybe', 'that', 'is', 'why', 'i', 'do', 'not', 'have', 'a', 'job']\n","Updated Tokens (Row 59): ['let', 'know', 'fine', 'think', 'abrasive', 'vibe', 'whatever', 'entitled', 'opinion', 'course', 'maybe', 'job']\n","Stopwords Removed (Row 59): ['me', 'that', 'is', 'that', 'is', 'you', 'i', 'have', 'an', 'you', 'to', 'your', 'of', 'that', 'is', 'why', 'i', 'do', 'not', 'have', 'a']\n","Stopwords were removed for Row 59 in file Ses05M_impro04.csv.\n","Original Tokens (Row 60): ['no', 'i', 'not', 'getting', 'defensive', 'i', 'not', 'getting', 'defensive', 'no', 'i', 'asked', 'you', 'a', 'question', 'you', 'told', 'me', 'what']\n","Updated Tokens (Row 60): ['getting', 'defensive', 'getting', 'defensive', 'asked', 'question', 'told']\n","Stopwords Removed (Row 60): ['no', 'i', 'not', 'i', 'not', 'no', 'i', 'you', 'a', 'you', 'me', 'what']\n","Stopwords were removed for Row 60 in file Ses05M_impro04.csv.\n","Original Tokens (Row 61): ['i', 'not', 'like', 'this', 'all', 'the', 'time', 'i', 'mean', 'i', 'do', 'not', 'i', 'just', 'frustrated', 'right', 'now', 'all', 'right', 'i', 'just', 'want', 'to', 'do']\n","Updated Tokens (Row 61): ['like', 'time', 'mean', 'frustrated', 'right', 'right', 'want']\n","Stopwords Removed (Row 61): ['i', 'not', 'this', 'all', 'the', 'i', 'i', 'do', 'not', 'i', 'just', 'now', 'all', 'i', 'just', 'to', 'do']\n","Stopwords were removed for Row 61 in file Ses05M_impro04.csv.\n","Original Tokens (Row 62): ['i', 'want', 'to', 'make', 'some', 'money', 'i', 'need', 'to', 'make', 'some', 'money', 'i', 'got', 'to', 'pay', 'some', 'bills', 'i', 'owe', 'people', 'money', 'i', 'owe', 'lots', 'of', 'people', 'money', 'i', 'need', 'to', 'make', 'some', 'money']\n","Updated Tokens (Row 62): ['want', 'make', 'money', 'need', 'make', 'money', 'got', 'pay', 'bills', 'owe', 'people', 'money', 'owe', 'lots', 'people', 'money', 'need', 'make', 'money']\n","Stopwords Removed (Row 62): ['i', 'to', 'some', 'i', 'to', 'some', 'i', 'to', 'some', 'i', 'i', 'of', 'i', 'to', 'some']\n","Stopwords were removed for Row 62 in file Ses05M_impro04.csv.\n","Original Tokens (Row 63): ['do', 'you', 'have', 'any', 'idea', 'how', 'i', 'can', 'make', 'money', 'i', 'mean', 'what', 'can', 'i', 'do', 'to', 'make', 'some', 'quick', 'money', 'something', 'anything', 'that', 'is', 'relatively', 'within', 'the', 'you', 'know', 'law']\n","Updated Tokens (Row 63): ['idea', 'make', 'money', 'mean', 'make', 'quick', 'money', 'something', 'anything', 'relatively', 'within', 'know', 'law']\n","Stopwords Removed (Row 63): ['do', 'you', 'have', 'any', 'how', 'i', 'can', 'i', 'what', 'can', 'i', 'do', 'to', 'some', 'that', 'is', 'the', 'you']\n","Stopwords were removed for Row 63 in file Ses05M_impro04.csv.\n","Original Tokens (Row 64): ['right', 'probably', 'not', 'selling', 'pot', 'i', 'do', 'not', 'want', 'to', 'go', 'to', 'jail']\n","Updated Tokens (Row 64): ['right', 'probably', 'selling', 'pot', 'want', 'go', 'jail']\n","Stopwords Removed (Row 64): ['not', 'i', 'do', 'not', 'to', 'to']\n","Stopwords were removed for Row 64 in file Ses05M_impro04.csv.\n","Original Tokens (Row 65): ['because', 'that', 'would', 'just', 'really', 'be', 'a', 'topper', 'for', 'me']\n","Updated Tokens (Row 65): ['would', 'really', 'topper']\n","Stopwords Removed (Row 65): ['because', 'that', 'just', 'be', 'a', 'for', 'me']\n","Stopwords were removed for Row 65 in file Ses05M_impro04.csv.\n","Original Tokens (Row 66): ['thank', 'you', 'ha', 'ha']\n","Updated Tokens (Row 66): ['thank', 'ha', 'ha']\n","Stopwords Removed (Row 66): ['you']\n","Stopwords were removed for Row 66 in file Ses05M_impro04.csv.\n","Original Tokens (Row 67): ['see', 'what', 'i', 'mean', 'you', 'can', 'not', 'even', 'think', 'of', 'anything']\n","Updated Tokens (Row 67): ['see', 'mean', 'even', 'think', 'anything']\n","Stopwords Removed (Row 67): ['what', 'i', 'you', 'can', 'not', 'of']\n","Stopwords were removed for Row 67 in file Ses05M_impro04.csv.\n","Original Tokens (Row 68): ['i', 'can', 'juggle']\n","Updated Tokens (Row 68): ['juggle']\n","Stopwords Removed (Row 68): ['i', 'can']\n","Stopwords were removed for Row 68 in file Ses05M_impro04.csv.\n","Original Tokens (Row 69): ['i', 'tried']\n","Updated Tokens (Row 69): ['tried']\n","Stopwords Removed (Row 69): ['i']\n","Stopwords were removed for Row 69 in file Ses05M_impro04.csv.\n","Original Tokens (Row 70): ['yes', 'nobody', 'wants', 'a', 'juggler', 'i', 'am', 'not', 'going', 'to', 'i', 'not', 'going', 'to', 'dress', 'up', 'like', 'a', 'clown', 'i', 'not', 'going', 'to', 'dress', 'up', 'like', 'a', 'freaking', 'clown', 'no']\n","Updated Tokens (Row 70): ['yes', 'nobody', 'wants', 'juggler', 'going', 'going', 'dress', 'like', 'clown', 'going', 'dress', 'like', 'freaking', 'clown']\n","Stopwords Removed (Row 70): ['a', 'i', 'am', 'not', 'to', 'i', 'not', 'to', 'up', 'a', 'i', 'not', 'to', 'up', 'a', 'no']\n","Stopwords were removed for Row 70 in file Ses05M_impro04.csv.\n","Original Tokens (Row 71): ['no', 'it', 'is', 'demeaning', 'i', 'am', 'not', 'a', 'clown', 'i', 'have', 'talent', 'clowns', 'do', 'not', 'have', 'talent']\n","Updated Tokens (Row 71): ['demeaning', 'clown', 'talent', 'clowns', 'talent']\n","Stopwords Removed (Row 71): ['no', 'it', 'is', 'i', 'am', 'not', 'a', 'i', 'have', 'do', 'not', 'have']\n","Stopwords were removed for Row 71 in file Ses05M_impro04.csv.\n","Original Tokens (Row 72): ['it', 'is', 'that', 'simple']\n","Updated Tokens (Row 72): ['simple']\n","Stopwords Removed (Row 72): ['it', 'is', 'that']\n","Stopwords were removed for Row 72 in file Ses05M_impro04.csv.\n","Original Tokens (Row 73): ['yeah']\n","Updated Tokens (Row 73): ['yeah']\n","Stopwords Removed (Row 73): []\n","No stopwords removed for Row 73 in file Ses05M_impro04.csv.\n","Original Tokens (Row 74): ['you', 'and', 'me', 'both']\n","Updated Tokens (Row 74): []\n","Stopwords Removed (Row 74): ['you', 'and', 'me', 'both']\n","Stopwords were removed for Row 74 in file Ses05M_impro04.csv.\n","Original Tokens (Row 75): ['yeah', 'life', 'sucks']\n","Updated Tokens (Row 75): ['yeah', 'life', 'sucks']\n","Stopwords Removed (Row 75): []\n","No stopwords removed for Row 75 in file Ses05M_impro04.csv.\n","Original Tokens (Row 76): ['no', 'i', 'just', 'showed', 'that', 'for', 'you', 'garbage']\n","Updated Tokens (Row 76): ['showed', 'garbage']\n","Stopwords Removed (Row 76): ['no', 'i', 'just', 'that', 'for', 'you']\n","Stopwords were removed for Row 76 in file Ses05M_impro04.csv.\n","Original Tokens (Row 77): ['i', 'like', 'to', 'think', 'so']\n","Updated Tokens (Row 77): ['like', 'think']\n","Stopwords Removed (Row 77): ['i', 'to', 'so']\n","Stopwords were removed for Row 77 in file Ses05M_impro04.csv.\n","Original Tokens (Row 78): ['see']\n","Updated Tokens (Row 78): ['see']\n","Stopwords Removed (Row 78): []\n","No stopwords removed for Row 78 in file Ses05M_impro04.csv.\n","Original Tokens (Row 79): ['yeah', 'well', 'thanks', 'for', 'your', 'help']\n","Updated Tokens (Row 79): ['yeah', 'well', 'thanks', 'help']\n","Stopwords Removed (Row 79): ['for', 'your']\n","Stopwords were removed for Row 79 in file Ses05M_impro04.csv.\n","Original Tokens (Row 80): ['i', 'need', 'it']\n","Updated Tokens (Row 80): ['need']\n","Stopwords Removed (Row 80): ['i', 'it']\n","Stopwords were removed for Row 80 in file Ses05M_impro04.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro04.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro04.csv\n","\n","Processing File: Ses05M_impro01.csv\n","Original Tokens (Row 0): ['can', 'i', 'help', 'you']\n","Updated Tokens (Row 0): ['help']\n","Stopwords Removed (Row 0): ['can', 'i', 'you']\n","Stopwords were removed for Row 0 in file Ses05M_impro01.csv.\n","Original Tokens (Row 1): ['oh', 'this', 'this', 'form', 'that', 'you', 'have', 'is', 'the', 'wrong', 'form', 'you', 'need', 'to', 'go', 'over', 'to', 'the', 'other', 'line', 'on', 'the', 'other', 'side', 'of', 'the', 'd.m.v']\n","Updated Tokens (Row 1): ['oh', 'form', 'wrong', 'form', 'need', 'go', 'line', 'side', 'd.m.v']\n","Stopwords Removed (Row 1): ['this', 'this', 'that', 'you', 'have', 'is', 'the', 'you', 'to', 'over', 'to', 'the', 'other', 'on', 'the', 'other', 'of', 'the']\n","Stopwords were removed for Row 1 in file Ses05M_impro01.csv.\n","Original Tokens (Row 2): ['right', 'but', 'this', 'is', 'the', 'wrong', 'form', 'somebody', 'gave', 'you', 'the', 'wrong', 'form']\n","Updated Tokens (Row 2): ['right', 'wrong', 'form', 'somebody', 'gave', 'wrong', 'form']\n","Stopwords Removed (Row 2): ['but', 'this', 'is', 'the', 'you', 'the']\n","Stopwords were removed for Row 2 in file Ses05M_impro01.csv.\n","Original Tokens (Row 3): ['yeah', 'so', 'i', 'can', 'not', 'i', 'can', 'not', 'do', 'anything']\n","Updated Tokens (Row 3): ['yeah', 'anything']\n","Stopwords Removed (Row 3): ['so', 'i', 'can', 'not', 'i', 'can', 'not', 'do']\n","Stopwords were removed for Row 3 in file Ses05M_impro01.csv.\n","Original Tokens (Row 4): ['no', 'but', 'this', 'is', 'for', 'um', 'replacements', 'and', 'you', 'need', 'a', 'new', 'whole', 'new', 'license', 'as', 'a', 'california']\n","Updated Tokens (Row 4): ['um', 'replacements', 'need', 'new', 'whole', 'new', 'license', 'california']\n","Stopwords Removed (Row 4): ['no', 'but', 'this', 'is', 'for', 'and', 'you', 'a', 'as', 'a']\n","Stopwords were removed for Row 4 in file Ses05M_impro01.csv.\n","Original Tokens (Row 5): ['sir', 'do', 'not', 'get', 'an', 'attitude', 'with', 'me']\n","Updated Tokens (Row 5): ['sir', 'get', 'attitude']\n","Stopwords Removed (Row 5): ['do', 'not', 'an', 'with', 'me']\n","Stopwords were removed for Row 5 in file Ses05M_impro01.csv.\n","Original Tokens (Row 6): ['no', 'i', 'understand', 'and', 'there', 'are', 'a', 'lot', 'of', 'people', 'here', 'but', 'what', 'i', 'telling', 'you', 'is', 'that', 'it', 'is', 'different', 'for', 'different', 'states', 'and', 'since', 'your', 'getting', 'a', 'new', 'license', 'in', 'the', 'state', 'of', 'california', 'you', 'have', 'to', 'fill', 'out', 'a', 'different', 'form', 'than', 'you', 'did']\n","Updated Tokens (Row 6): ['understand', 'lot', 'people', 'telling', 'different', 'different', 'states', 'since', 'getting', 'new', 'license', 'state', 'california', 'fill', 'different', 'form']\n","Stopwords Removed (Row 6): ['no', 'i', 'and', 'there', 'are', 'a', 'of', 'here', 'but', 'what', 'i', 'you', 'is', 'that', 'it', 'is', 'for', 'and', 'your', 'a', 'in', 'the', 'of', 'you', 'have', 'to', 'out', 'a', 'than', 'you', 'did']\n","Stopwords were removed for Row 6 in file Ses05M_impro01.csv.\n","Original Tokens (Row 7): ['i', 'do', 'not', 'know', 'i', 'do', 'not', 'know', 'who', 'told', 'you', 'it', 'was', 'not', 'me']\n","Updated Tokens (Row 7): ['know', 'know', 'told']\n","Stopwords Removed (Row 7): ['i', 'do', 'not', 'i', 'do', 'not', 'who', 'you', 'it', 'was', 'not', 'me']\n","Stopwords were removed for Row 7 in file Ses05M_impro01.csv.\n","Original Tokens (Row 8): ['you', 'you', 'can', 'ask', 'her', 'if', 'you', 'want', 'but', 'she', 'is', 'busy', 'and', 'she', 'probably', 'will', 'not', 'answer', 'you']\n","Updated Tokens (Row 8): ['ask', 'want', 'busy', 'probably', 'answer']\n","Stopwords Removed (Row 8): ['you', 'you', 'can', 'her', 'if', 'you', 'but', 'she', 'is', 'and', 'she', 'will', 'not', 'you']\n","Stopwords were removed for Row 8 in file Ses05M_impro01.csv.\n","Original Tokens (Row 9): ['i', 'know']\n","Updated Tokens (Row 9): ['know']\n","Stopwords Removed (Row 9): ['i']\n","Stopwords were removed for Row 9 in file Ses05M_impro01.csv.\n","Original Tokens (Row 10): ['sir', 'you', 'i', 'mean']\n","Updated Tokens (Row 10): ['sir', 'mean']\n","Stopwords Removed (Row 10): ['you', 'i']\n","Stopwords were removed for Row 10 in file Ses05M_impro01.csv.\n","Original Tokens (Row 11): ['you', 'can', 'waist', 'as', 'much', 'as', 'you', 'want']\n","Updated Tokens (Row 11): ['waist', 'much', 'want']\n","Stopwords Removed (Row 11): ['you', 'can', 'as', 'as', 'you']\n","Stopwords were removed for Row 11 in file Ses05M_impro01.csv.\n","Original Tokens (Row 12): ['yeah', 'i', 'know', 'it', 'is', 'gon', 'na', 'take', 'a', 'minute', 'but', 'you', 'so', 'you', 'might', 'as', 'well', 'get', 'started', 'now']\n","Updated Tokens (Row 12): ['yeah', 'know', 'gon', 'na', 'take', 'minute', 'might', 'well', 'get', 'started']\n","Stopwords Removed (Row 12): ['i', 'it', 'is', 'a', 'but', 'you', 'so', 'you', 'as', 'now']\n","Stopwords were removed for Row 12 in file Ses05M_impro01.csv.\n","Original Tokens (Row 13): ['i', 'can', 'not', 'take', 'this', 'one', 'sir', 'this', 'is', 'the', 'wrong', 'form']\n","Updated Tokens (Row 13): ['take', 'one', 'sir', 'wrong', 'form']\n","Stopwords Removed (Row 13): ['i', 'can', 'not', 'this', 'this', 'is', 'the']\n","Stopwords were removed for Row 13 in file Ses05M_impro01.csv.\n","Original Tokens (Row 14): ['sir', 'please', 'do', 'not', 'waste', 'my', 'time']\n","Updated Tokens (Row 14): ['sir', 'please', 'waste', 'time']\n","Stopwords Removed (Row 14): ['do', 'not', 'my']\n","Stopwords were removed for Row 14 in file Ses05M_impro01.csv.\n","Original Tokens (Row 15): ['there', 'is', 'nothing', 'i', 'can', 'do', 'about', 'it', 'you', 'need', 'to', 'take', 'this', 'other', 'form', 'and', 'fill', 'it', 'out', 'and', 'go', 'stand', 'in', 'the', 'other', 'line']\n","Updated Tokens (Row 15): ['nothing', 'need', 'take', 'form', 'fill', 'go', 'stand', 'line']\n","Stopwords Removed (Row 15): ['there', 'is', 'i', 'can', 'do', 'about', 'it', 'you', 'to', 'this', 'other', 'and', 'it', 'out', 'and', 'in', 'the', 'other']\n","Stopwords were removed for Row 15 in file Ses05M_impro01.csv.\n","Original Tokens (Row 16): ['they', 'are', 'different', 'forms', 'we', 'process', 'them', 'all', 'different']\n","Updated Tokens (Row 16): ['different', 'forms', 'process', 'different']\n","Stopwords Removed (Row 16): ['they', 'are', 'we', 'them', 'all']\n","Stopwords were removed for Row 16 in file Ses05M_impro01.csv.\n","Original Tokens (Row 17): ['i', 'there', 'no', 'way', 'i', 'make', 'an', 'exception']\n","Updated Tokens (Row 17): ['way', 'make', 'exception']\n","Stopwords Removed (Row 17): ['i', 'there', 'no', 'i', 'an']\n","Stopwords were removed for Row 17 in file Ses05M_impro01.csv.\n","Original Tokens (Row 18): ['sir', 'do', 'not', 'patronize', 'me', 'i', 'can', 'not', 'make', 'an', 'exception', 'i', 'do', 'not', 'i', 'do', 'not', 'have', 'the', 'power', 'to', 'do', 'that', 'it', 'is', 'a', 'different', 'form']\n","Updated Tokens (Row 18): ['sir', 'patronize', 'make', 'exception', 'power', 'different', 'form']\n","Stopwords Removed (Row 18): ['do', 'not', 'me', 'i', 'can', 'not', 'an', 'i', 'do', 'not', 'i', 'do', 'not', 'have', 'the', 'to', 'do', 'that', 'it', 'is', 'a']\n","Stopwords were removed for Row 18 in file Ses05M_impro01.csv.\n","Original Tokens (Row 19): ['they', 'are', 'processed', 'differently']\n","Updated Tokens (Row 19): ['processed', 'differently']\n","Stopwords Removed (Row 19): ['they', 'are']\n","Stopwords were removed for Row 19 in file Ses05M_impro01.csv.\n","Original Tokens (Row 20): ['sir', 'you', 'gon', 'na', 'have', 'to', 'go', 'stand', 'in', 'the', 'other', 'line']\n","Updated Tokens (Row 20): ['sir', 'gon', 'na', 'go', 'stand', 'line']\n","Stopwords Removed (Row 20): ['you', 'have', 'to', 'in', 'the', 'other']\n","Stopwords were removed for Row 20 in file Ses05M_impro01.csv.\n","Original Tokens (Row 21): ['i', 'gon', 'na', 'i', 'gon', 'na', 'bring', 'security', 'over', 'and', 'have', 'them', 'escort', 'you', 'out']\n","Updated Tokens (Row 21): ['gon', 'na', 'gon', 'na', 'bring', 'security', 'escort']\n","Stopwords Removed (Row 21): ['i', 'i', 'over', 'and', 'have', 'them', 'you', 'out']\n","Stopwords were removed for Row 21 in file Ses05M_impro01.csv.\n","Original Tokens (Row 22): ['but', 'you', 'filled', 'out', 'the', 'wrong', 'form', 'and', 'you', 'in', 'the', 'wrong', 'line', 'and', 'you', 'wasting', 'both', 'of', 'our', 'times']\n","Updated Tokens (Row 22): ['filled', 'wrong', 'form', 'wrong', 'line', 'wasting', 'times']\n","Stopwords Removed (Row 22): ['but', 'you', 'out', 'the', 'and', 'you', 'in', 'the', 'and', 'you', 'both', 'of', 'our']\n","Stopwords were removed for Row 22 in file Ses05M_impro01.csv.\n","Original Tokens (Row 23): ['well', 'that', 'is', 'unfortunate', 'sir', 'you', 'gon', 'na', 'have', 'to', 'go', 'stand', 'in', 'the', 'other', 'line', 'now']\n","Updated Tokens (Row 23): ['well', 'unfortunate', 'sir', 'gon', 'na', 'go', 'stand', 'line']\n","Stopwords Removed (Row 23): ['that', 'is', 'you', 'have', 'to', 'in', 'the', 'other', 'now']\n","Stopwords were removed for Row 23 in file Ses05M_impro01.csv.\n","Original Tokens (Row 24): ['yes', 'i', 'um', 'just', 'getting', 'my', 'i.d', 'i', 'need', 'a', 'new', 'i.d']\n","Updated Tokens (Row 24): ['yes', 'um', 'getting', 'i.d', 'need', 'new', 'i.d']\n","Stopwords Removed (Row 24): ['i', 'just', 'my', 'i', 'a']\n","Stopwords were removed for Row 24 in file Ses05M_impro01.csv.\n","Original Tokens (Row 25): ['what', 'do', 'you', 'mean', 'i', 'filled', 'out', 'my', 'forms', 'and', 'i', 'rushed', 'to', 'get', 'my', 'i.d']\n","Updated Tokens (Row 25): ['mean', 'filled', 'forms', 'rushed', 'get', 'i.d']\n","Stopwords Removed (Row 25): ['what', 'do', 'you', 'i', 'out', 'my', 'and', 'i', 'to', 'my']\n","Stopwords were removed for Row 25 in file Ses05M_impro01.csv.\n","Original Tokens (Row 26): ['the', 'wrong', 'form']\n","Updated Tokens (Row 26): ['wrong', 'form']\n","Stopwords Removed (Row 26): ['the']\n","Stopwords were removed for Row 26 in file Ses05M_impro01.csv.\n","Original Tokens (Row 27): ['what', 'is', 'wrong', 'about', 'this', 'form', 'it', 'says', 'new', 'i.d', 'on', 'it']\n","Updated Tokens (Row 27): ['wrong', 'form', 'says', 'new', 'i.d']\n","Stopwords Removed (Row 27): ['what', 'is', 'about', 'this', 'it', 'on', 'it']\n","Stopwords were removed for Row 27 in file Ses05M_impro01.csv.\n","Original Tokens (Row 28): ['what', 'is', 'the', 'difference', 'what', 'is', 'the', 'difference', 'between', 'that', 'form', 'and', 'this', 'form']\n","Updated Tokens (Row 28): ['difference', 'difference', 'form', 'form']\n","Stopwords Removed (Row 28): ['what', 'is', 'the', 'what', 'is', 'the', 'between', 'that', 'and', 'this']\n","Stopwords were removed for Row 28 in file Ses05M_impro01.csv.\n","Original Tokens (Row 29): ['i', 'not', 'getting', 'a', 'well', 'you', 'wait', 'in', 'this', 'line', 'and', 'not', 'get', 'an', 'attitude']\n","Updated Tokens (Row 29): ['getting', 'well', 'wait', 'line', 'get', 'attitude']\n","Stopwords Removed (Row 29): ['i', 'not', 'a', 'you', 'in', 'this', 'and', 'not', 'an']\n","Stopwords were removed for Row 29 in file Ses05M_impro01.csv.\n","Original Tokens (Row 30): ['yeah']\n","Updated Tokens (Row 30): ['yeah']\n","Stopwords Removed (Row 30): []\n","No stopwords removed for Row 30 in file Ses05M_impro01.csv.\n","Original Tokens (Row 31): ['right']\n","Updated Tokens (Row 31): ['right']\n","Stopwords Removed (Row 31): []\n","No stopwords removed for Row 31 in file Ses05M_impro01.csv.\n","Original Tokens (Row 32): ['well', 'then', 'when', 'i', 'showed', 'them', 'my', 'i.d', 'before', 'and', 'i', 'said', 'i', 'had', 'to', 'get', 'a', 'new', 'i.d', 'why', 'did', 'not', 'they', 'tell', 'me', 'to', 'fill', 'out', 'the', 'right', 'form']\n","Updated Tokens (Row 32): ['well', 'showed', 'i.d', 'said', 'get', 'new', 'i.d', 'tell', 'fill', 'right', 'form']\n","Stopwords Removed (Row 32): ['then', 'when', 'i', 'them', 'my', 'before', 'and', 'i', 'i', 'had', 'to', 'a', 'why', 'did', 'not', 'they', 'me', 'to', 'out', 'the']\n","Stopwords were removed for Row 32 in file Ses05M_impro01.csv.\n","Original Tokens (Row 33): ['well', 'it', 'was', 'this', 'girl', 'standing', 'right', 'next', 'to', 'you', 'can', 'we', 'ask', 'her', 'why', 'she', 'did', 'not', 'let', 'me', 'fill', 'out', 'the', 'right', 'form']\n","Updated Tokens (Row 33): ['well', 'girl', 'standing', 'right', 'next', 'ask', 'let', 'fill', 'right', 'form']\n","Stopwords Removed (Row 33): ['it', 'was', 'this', 'to', 'you', 'can', 'we', 'her', 'why', 'she', 'did', 'not', 'me', 'out', 'the']\n","Stopwords were removed for Row 33 in file Ses05M_impro01.csv.\n","Original Tokens (Row 34): ['this', 'is', 'ridiculous', 'i', 'been', 'here', 'for', 'forty', 'five', 'minutes', 'just', 'standing', 'in', 'this', 'one', 'line', 'i', 'took', 'fifteen', 'minutes', 'to', 'fill', 'out', 'that', 'form']\n","Updated Tokens (Row 34): ['ridiculous', 'forty', 'five', 'minutes', 'standing', 'one', 'line', 'took', 'fifteen', 'minutes', 'fill', 'form']\n","Stopwords Removed (Row 34): ['this', 'is', 'i', 'been', 'here', 'for', 'just', 'in', 'this', 'i', 'to', 'out', 'that']\n","Stopwords were removed for Row 34 in file Ses05M_impro01.csv.\n","Original Tokens (Row 35): ['do', 'you', 'know', 'how', 'long', 'it', 'is', 'gon', 'na', 'take', 'me', 'to', 'start', 'all', 'over', 'and', 'fill', 'out', 'the', 'new', 'form']\n","Updated Tokens (Row 35): ['know', 'long', 'gon', 'na', 'take', 'start', 'fill', 'new', 'form']\n","Stopwords Removed (Row 35): ['do', 'you', 'how', 'it', 'is', 'me', 'to', 'all', 'over', 'and', 'out', 'the']\n","Stopwords were removed for Row 35 in file Ses05M_impro01.csv.\n","Original Tokens (Row 36): ['might', 'as', 'well', 'get', 'started', 'now', 'but', 'just', 'take', 'this', 'one']\n","Updated Tokens (Row 36): ['might', 'well', 'get', 'started', 'take', 'one']\n","Stopwords Removed (Row 36): ['as', 'now', 'but', 'just', 'this']\n","Stopwords were removed for Row 36 in file Ses05M_impro01.csv.\n","Original Tokens (Row 37): ['why', 'can', 'not', 'we', 'just', 'you', 'know', 'what', 'how', 'about', 'if', 'we', 'just', 'pretend', 'that', 'i', 'getting', 'a', 'renewing', 'my', 'california', 'i.d', 'and', 'we', 'just', 'do', 'not', 'tell', 'anybody', 'that', 'i', 'getting', 'a', 'new', 'one', 'from', 'a', 'different', 'state']\n","Updated Tokens (Row 37): ['know', 'pretend', 'getting', 'renewing', 'california', 'i.d', 'tell', 'anybody', 'getting', 'new', 'one', 'different', 'state']\n","Stopwords Removed (Row 37): ['why', 'can', 'not', 'we', 'just', 'you', 'what', 'how', 'about', 'if', 'we', 'just', 'that', 'i', 'a', 'my', 'and', 'we', 'just', 'do', 'not', 'that', 'i', 'a', 'from', 'a']\n","Stopwords were removed for Row 37 in file Ses05M_impro01.csv.\n","Original Tokens (Row 38): ['come', 'on', 'you', 'know', 'you', 'can', 'not', 'just', 'take', 'make', 'a', 'little', 'exception', 'to', 'the', 'rule', 'i', 'know', 'that', 'you', 'guys', 'make', 'exceptions', 'i', 'see', 'you', 'know', 'if', 'i', 'was-if', 'i', 'was', 'your', 'friend', 'and', 'you', 'knew', 'me', 'or', 'something', 'like', 'that', 'you', 'probably', 'make', 'a', 'little', 'exception', 'for', 'me', 'would', 'not', 'you']\n","Updated Tokens (Row 38): ['come', 'know', 'take', 'make', 'little', 'exception', 'rule', 'know', 'guys', 'make', 'exceptions', 'see', 'know', 'was-if', 'friend', 'knew', 'something', 'like', 'probably', 'make', 'little', 'exception', 'would']\n","Stopwords Removed (Row 38): ['on', 'you', 'you', 'can', 'not', 'just', 'a', 'to', 'the', 'i', 'that', 'you', 'i', 'you', 'if', 'i', 'i', 'was', 'your', 'and', 'you', 'me', 'or', 'that', 'you', 'a', 'for', 'me', 'not', 'you']\n","Stopwords were removed for Row 38 in file Ses05M_impro01.csv.\n","Original Tokens (Row 39): ['would', 'not', 'you', 'oh', 'come', 'on', 'you', 'just', 'tell', 'me', 'you', 'would', 'make', 'an', 'exception', 'for', 'me']\n","Updated Tokens (Row 39): ['would', 'oh', 'come', 'tell', 'would', 'make', 'exception']\n","Stopwords Removed (Row 39): ['not', 'you', 'on', 'you', 'just', 'me', 'you', 'an', 'for', 'me']\n","Stopwords were removed for Row 39 in file Ses05M_impro01.csv.\n","Original Tokens (Row 40): ['shh', 'i', 'know', 'you', 'have', 'got', 'the', 'power', 'to', 'do', 'that']\n","Updated Tokens (Row 40): ['shh', 'know', 'got', 'power']\n","Stopwords Removed (Row 40): ['i', 'you', 'have', 'the', 'to', 'do', 'that']\n","Stopwords were removed for Row 40 in file Ses05M_impro01.csv.\n","Original Tokens (Row 41): ['that', 'is', 'crap', 'you', 'crap', 'i', 'do', 'not', 'buy', 'it']\n","Updated Tokens (Row 41): ['crap', 'crap', 'buy']\n","Stopwords Removed (Row 41): ['that', 'is', 'you', 'i', 'do', 'not', 'it']\n","Stopwords were removed for Row 41 in file Ses05M_impro01.csv.\n","Original Tokens (Row 42): ['i', 'not', 'leaving', 'this', 'line', 'until', 'i', 'get', 'my', 'new', 'i.d', 'that', 'is', 'as', 'simple', 'as', 'it', 'is', 'i', 'not', 'leaving', 'this', 'line', 'until', 'i', 'get', 'my', 'new', 'i.d']\n","Updated Tokens (Row 42): ['leaving', 'line', 'get', 'new', 'i.d', 'simple', 'leaving', 'line', 'get', 'new', 'i.d']\n","Stopwords Removed (Row 42): ['i', 'not', 'this', 'until', 'i', 'my', 'that', 'is', 'as', 'as', 'it', 'is', 'i', 'not', 'this', 'until', 'i', 'my']\n","Stopwords were removed for Row 42 in file Ses05M_impro01.csv.\n","Original Tokens (Row 43): ['well', 'then', 'you', 'just', 'gon', 'na', 'look', 'stupid', 'because', 'i', 'just', 'waiting', 'for', 'an', 'i.d', 'and', 'you', 'gon', 'na', 'make', 'security', 'take', 'me', 'out', 'because', 'i', 'want', 'my', 'i.d']\n","Updated Tokens (Row 43): ['well', 'gon', 'na', 'look', 'stupid', 'waiting', 'i.d', 'gon', 'na', 'make', 'security', 'take', 'want', 'i.d']\n","Stopwords Removed (Row 43): ['then', 'you', 'just', 'because', 'i', 'just', 'for', 'an', 'and', 'you', 'me', 'out', 'because', 'i', 'my']\n","Stopwords were removed for Row 43 in file Ses05M_impro01.csv.\n","Original Tokens (Row 44): ['that', 'is', 'just', 'dumb']\n","Updated Tokens (Row 44): ['dumb']\n","Stopwords Removed (Row 44): ['that', 'is', 'just']\n","Stopwords were removed for Row 44 in file Ses05M_impro01.csv.\n","Original Tokens (Row 45): ['i', 'filled', 'out', 'the', 'wrong', 'form', 'because', 'they', 'made', 'me', 'fill', 'out', 'the', 'wrong', 'form']\n","Updated Tokens (Row 45): ['filled', 'wrong', 'form', 'made', 'fill', 'wrong', 'form']\n","Stopwords Removed (Row 45): ['i', 'out', 'the', 'because', 'they', 'me', 'out', 'the']\n","Stopwords were removed for Row 45 in file Ses05M_impro01.csv.\n","Original Tokens (Row 46): ['this', 'is', 'crap', 'you', 'know', 'i', 'do', 'not', 'even', 'know', 'why', 'i', 'in', 'this', 'state', 'screw', 'california', 'i', 'out', 'of', 'here']\n","Updated Tokens (Row 46): ['crap', 'know', 'even', 'know', 'state', 'screw', 'california']\n","Stopwords Removed (Row 46): ['this', 'is', 'you', 'i', 'do', 'not', 'why', 'i', 'in', 'this', 'i', 'out', 'of', 'here']\n","Stopwords were removed for Row 46 in file Ses05M_impro01.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro01.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro01.csv\n","\n","Processing File: Ses05M_impro05.csv\n","Original Tokens (Row 0): ['hmm', 'hmm']\n","Updated Tokens (Row 0): ['hmm', 'hmm']\n","Stopwords Removed (Row 0): []\n","No stopwords removed for Row 0 in file Ses05M_impro05.csv.\n","Original Tokens (Row 1): ['how', 'long', 'ago', 'was', 'that']\n","Updated Tokens (Row 1): ['long', 'ago']\n","Stopwords Removed (Row 1): ['how', 'was', 'that']\n","Stopwords were removed for Row 1 in file Ses05M_impro05.csv.\n","Original Tokens (Row 2): ['uh-hmm']\n","Updated Tokens (Row 2): ['uh-hmm']\n","Stopwords Removed (Row 2): []\n","No stopwords removed for Row 2 in file Ses05M_impro05.csv.\n","Original Tokens (Row 3): ['um', 'okay', 'well', 'you', 'can', 'fly', 'file', 'a', 'claim', 'where', 'were', 'you', 'coming', 'from']\n","Updated Tokens (Row 3): ['um', 'okay', 'well', 'fly', 'file', 'claim', 'coming']\n","Stopwords Removed (Row 3): ['you', 'can', 'a', 'where', 'were', 'you', 'from']\n","Stopwords were removed for Row 3 in file Ses05M_impro05.csv.\n","Original Tokens (Row 4): ['so', 'within', 'the', 'country', 'though', 'umm']\n","Updated Tokens (Row 4): ['within', 'country', 'though', 'umm']\n","Stopwords Removed (Row 4): ['so', 'the']\n","Stopwords were removed for Row 4 in file Ses05M_impro05.csv.\n","Original Tokens (Row 5): ['yeah', 'well', 'the', 'chances', 'of', 'it', 'being', 'lost', 'forever', 'you', 'know', 'are', 'slight', 'because', 'you', 'were', 'in', 'the']\n","Updated Tokens (Row 5): ['yeah', 'well', 'chances', 'lost', 'forever', 'know', 'slight']\n","Stopwords Removed (Row 5): ['the', 'of', 'it', 'being', 'you', 'are', 'because', 'you', 'were', 'in', 'the']\n","Stopwords were removed for Row 5 in file Ses05M_impro05.csv.\n","Original Tokens (Row 6): ['well', 'i', 'mean', 'you', 'know', 'that', 'happens', 'pretty', 'often', 'that', 'sometimes', 'baggage', 'gets', 'lost']\n","Updated Tokens (Row 6): ['well', 'mean', 'know', 'happens', 'pretty', 'often', 'sometimes', 'baggage', 'gets', 'lost']\n","Stopwords Removed (Row 6): ['i', 'you', 'that', 'that']\n","Stopwords were removed for Row 6 in file Ses05M_impro05.csv.\n","Original Tokens (Row 7): ['yeah']\n","Updated Tokens (Row 7): ['yeah']\n","Stopwords Removed (Row 7): []\n","No stopwords removed for Row 7 in file Ses05M_impro05.csv.\n","Original Tokens (Row 8): ['okay']\n","Updated Tokens (Row 8): ['okay']\n","Stopwords Removed (Row 8): []\n","No stopwords removed for Row 8 in file Ses05M_impro05.csv.\n","Original Tokens (Row 9): ['did', 'you', 'have', 'insurance', 'on', 'your', 'flight']\n","Updated Tokens (Row 9): ['insurance', 'flight']\n","Stopwords Removed (Row 9): ['did', 'you', 'have', 'on', 'your']\n","Stopwords were removed for Row 9 in file Ses05M_impro05.csv.\n","Original Tokens (Row 10): ['no', 'you', 'have', 'to', 'buy', 'it', 'now', 'it', 'is', 'like', 'thirty', 'dollar', 'extra']\n","Updated Tokens (Row 10): ['buy', 'like', 'thirty', 'dollar', 'extra']\n","Stopwords Removed (Row 10): ['no', 'you', 'have', 'to', 'it', 'now', 'it', 'is']\n","Stopwords were removed for Row 10 in file Ses05M_impro05.csv.\n","Original Tokens (Row 11): ['well', 'it', 'is', 'something', 'that', 'worth']\n","Updated Tokens (Row 11): ['well', 'something', 'worth']\n","Stopwords Removed (Row 11): ['it', 'is', 'that']\n","Stopwords were removed for Row 11 in file Ses05M_impro05.csv.\n","Original Tokens (Row 12): ['yeah', 'i', 'do', 'not', 'know']\n","Updated Tokens (Row 12): ['yeah', 'know']\n","Stopwords Removed (Row 12): ['i', 'do', 'not']\n","Stopwords were removed for Row 12 in file Ses05M_impro05.csv.\n","Original Tokens (Row 13): ['chances', 'are', 'it', 'is', 'probably', 'just', 'you', 'know', 'taking', 'time', 'being', 'um', 'unloaded', 'from', 'the', 'airplane']\n","Updated Tokens (Row 13): ['chances', 'probably', 'know', 'taking', 'time', 'um', 'unloaded', 'airplane']\n","Stopwords Removed (Row 13): ['are', 'it', 'is', 'just', 'you', 'being', 'from', 'the']\n","Stopwords were removed for Row 13 in file Ses05M_impro05.csv.\n","Original Tokens (Row 14): ['um', 'well', 'there', 'not', 'much', 'i', 'can', 'do', 'i', 'can', 'you', 'can', 'file', 'this', 'report', 'and', 'we', 'call', 'you', 'when', 'it', 'comes', 'in']\n","Updated Tokens (Row 14): ['um', 'well', 'much', 'file', 'report', 'call', 'comes']\n","Stopwords Removed (Row 14): ['there', 'not', 'i', 'can', 'do', 'i', 'can', 'you', 'can', 'this', 'and', 'we', 'you', 'when', 'it', 'in']\n","Stopwords were removed for Row 14 in file Ses05M_impro05.csv.\n","Original Tokens (Row 15): ['wow']\n","Updated Tokens (Row 15): ['wow']\n","Stopwords Removed (Row 15): []\n","No stopwords removed for Row 15 in file Ses05M_impro05.csv.\n","Original Tokens (Row 16): ['wow', 'well', 'that', 'is', 'really', 'important', 'obviously', 'but', 'um']\n","Updated Tokens (Row 16): ['wow', 'well', 'really', 'important', 'obviously', 'um']\n","Stopwords Removed (Row 16): ['that', 'is', 'but']\n","Stopwords were removed for Row 16 in file Ses05M_impro05.csv.\n","Original Tokens (Row 17): ['uh', 'actually', 'i', 'do', 'not', 'know', 'that', 'that', 'is', 'legal', 'um', 'it', 'is', 'the', 'issue']\n","Updated Tokens (Row 17): ['uh', 'actually', 'know', 'legal', 'um', 'issue']\n","Stopwords Removed (Row 17): ['i', 'do', 'not', 'that', 'that', 'is', 'it', 'is', 'the']\n","Stopwords were removed for Row 17 in file Ses05M_impro05.csv.\n","Original Tokens (Row 18): ['yeah', 'i', 'mean', 'your', 'bag', 'might', 'have', 'been', 'confiscated', 'because', 'it', 'is']\n","Updated Tokens (Row 18): ['yeah', 'mean', 'bag', 'might', 'confiscated']\n","Stopwords Removed (Row 18): ['i', 'your', 'have', 'been', 'because', 'it', 'is']\n","Stopwords were removed for Row 18 in file Ses05M_impro05.csv.\n","Original Tokens (Row 19): ['it', 'is', 'a', 'biohazard', 'so', 'um']\n","Updated Tokens (Row 19): ['biohazard', 'um']\n","Stopwords Removed (Row 19): ['it', 'is', 'a', 'so']\n","Stopwords were removed for Row 19 in file Ses05M_impro05.csv.\n","Original Tokens (Row 20): ['yeah', 'let', 'me', 'just', 'call', 'security']\n","Updated Tokens (Row 20): ['yeah', 'let', 'call', 'security']\n","Stopwords Removed (Row 20): ['me', 'just']\n","Stopwords were removed for Row 20 in file Ses05M_impro05.csv.\n","Original Tokens (Row 21): ['laughter', 'okay', 'hold', 'on']\n","Updated Tokens (Row 21): ['laughter', 'okay', 'hold']\n","Stopwords Removed (Row 21): ['on']\n","Stopwords were removed for Row 21 in file Ses05M_impro05.csv.\n","Original Tokens (Row 22): ['hi', 'um', 'my', 'luggage', 'did', 'not', 'come', 'out', 'of', 'the', 'conveyor', 'thingy']\n","Updated Tokens (Row 22): ['hi', 'um', 'luggage', 'come', 'conveyor', 'thingy']\n","Stopwords Removed (Row 22): ['my', 'did', 'not', 'out', 'of', 'the']\n","Stopwords were removed for Row 22 in file Ses05M_impro05.csv.\n","Original Tokens (Row 23): ['so', 'um', 'what', 'do', 'i', 'do']\n","Updated Tokens (Row 23): ['um']\n","Stopwords Removed (Row 23): ['so', 'what', 'do', 'i', 'do']\n","Stopwords were removed for Row 23 in file Ses05M_impro05.csv.\n","Original Tokens (Row 24): ['uh', 'like', 'an', 'hour', 'and', 'a', 'half', 'ago', 'i', 'talked', 'to', 'somebody', 'who', 'was', 'standing', 'out', 'there', 'and', 'they', 'said', 'wait', 'sometimes', 'like', 'random', 'butt', 'pieces', 'come', 'out', 'late']\n","Updated Tokens (Row 24): ['uh', 'like', 'hour', 'half', 'ago', 'talked', 'somebody', 'standing', 'said', 'wait', 'sometimes', 'like', 'random', 'butt', 'pieces', 'come', 'late']\n","Stopwords Removed (Row 24): ['an', 'and', 'a', 'i', 'to', 'who', 'was', 'out', 'there', 'and', 'they', 'out']\n","Stopwords were removed for Row 24 in file Ses05M_impro05.csv.\n","Original Tokens (Row 25): ['and', 'so', 'i', 'waited', 'there', 'but', 'nothing', 'came']\n","Updated Tokens (Row 25): ['waited', 'nothing', 'came']\n","Stopwords Removed (Row 25): ['and', 'so', 'i', 'there', 'but']\n","Stopwords were removed for Row 25 in file Ses05M_impro05.csv.\n","Original Tokens (Row 26): ['i', 'was', 'coming', 'from', 'um', 'the', 'midwest', 'like', 'iowa']\n","Updated Tokens (Row 26): ['coming', 'um', 'midwest', 'like', 'iowa']\n","Stopwords Removed (Row 26): ['i', 'was', 'from', 'the']\n","Stopwords were removed for Row 26 in file Ses05M_impro05.csv.\n","Original Tokens (Row 27): ['yeah', 'i', 'know', 'i', 'was', 'in', 'the', 'country', 'i', 'mean', 'it', 'is', 'not', 'that', 'complicated']\n","Updated Tokens (Row 27): ['yeah', 'know', 'country', 'mean', 'complicated']\n","Stopwords Removed (Row 27): ['i', 'i', 'was', 'in', 'the', 'i', 'it', 'is', 'not', 'that']\n","Stopwords were removed for Row 27 in file Ses05M_impro05.csv.\n","Original Tokens (Row 28): ['well', 'i', 'would', 'hope', 'so']\n","Updated Tokens (Row 28): ['well', 'would', 'hope']\n","Stopwords Removed (Row 28): ['i', 'so']\n","Stopwords were removed for Row 28 in file Ses05M_impro05.csv.\n","Original Tokens (Row 29): ['people', 'lose']\n","Updated Tokens (Row 29): ['people', 'lose']\n","Stopwords Removed (Row 29): []\n","No stopwords removed for Row 29 in file Ses05M_impro05.csv.\n","Original Tokens (Row 30): ['forever']\n","Updated Tokens (Row 30): ['forever']\n","Stopwords Removed (Row 30): []\n","No stopwords removed for Row 30 in file Ses05M_impro05.csv.\n","Original Tokens (Row 31): ['you', 'know', 'this', 'is', 'actually', 'i', 'mean', 'it', 'is', 'it', 'is', 'a', 'really', 'important', 'piece', 'of', 'luggage']\n","Updated Tokens (Row 31): ['know', 'actually', 'mean', 'really', 'important', 'piece', 'luggage']\n","Stopwords Removed (Row 31): ['you', 'this', 'is', 'i', 'it', 'is', 'it', 'is', 'a', 'of']\n","Stopwords were removed for Row 31 in file Ses05M_impro05.csv.\n","Original Tokens (Row 32): ['i', 'mean', 'it', 'is', 'not', 'big', 'or', 'anything', 'like', 'that', 'i', 'mean', 'it', 'is', 'not', 'worth', 'a', 'lot', 'of', 'money', 'or', 'anything']\n","Updated Tokens (Row 32): ['mean', 'big', 'anything', 'like', 'mean', 'worth', 'lot', 'money', 'anything']\n","Stopwords Removed (Row 32): ['i', 'it', 'is', 'not', 'or', 'that', 'i', 'it', 'is', 'not', 'a', 'of', 'or']\n","Stopwords were removed for Row 32 in file Ses05M_impro05.csv.\n","Original Tokens (Row 33): ['no', 'i', 'mean', 'do', 'not', 'you', 'get', 'insurance', 'when', 'you', 'buy', 'your', 'ticket', 'or', 'something']\n","Updated Tokens (Row 33): ['mean', 'get', 'insurance', 'buy', 'ticket', 'something']\n","Stopwords Removed (Row 33): ['no', 'i', 'do', 'not', 'you', 'when', 'you', 'your', 'or']\n","Stopwords were removed for Row 33 in file Ses05M_impro05.csv.\n","Original Tokens (Row 34): ['well', 'no', 'one', 'even', 'told', 'me', 'about', 'that', 'like', 'why', 'would', 'i', 'think', 'to', 'buy', 'insurance', 'i', 'was', 'it', 'is', 'like', 'a', 'three', 'hour', 'flight']\n","Updated Tokens (Row 34): ['well', 'one', 'even', 'told', 'like', 'would', 'think', 'buy', 'insurance', 'like', 'three', 'hour', 'flight']\n","Stopwords Removed (Row 34): ['no', 'me', 'about', 'that', 'why', 'i', 'to', 'i', 'was', 'it', 'is', 'a']\n","Stopwords were removed for Row 34 in file Ses05M_impro05.csv.\n","Original Tokens (Row 35): ['how', 'can', 'you', 'lose', 'my', 'luggage', 'like', 'from', 'like', 'in']\n","Updated Tokens (Row 35): ['lose', 'luggage', 'like', 'like']\n","Stopwords Removed (Row 35): ['how', 'can', 'you', 'my', 'from', 'in']\n","Stopwords were removed for Row 35 in file Ses05M_impro05.csv.\n","Original Tokens (Row 36): ['four', 'hundred', 'miles']\n","Updated Tokens (Row 36): ['four', 'hundred', 'miles']\n","Stopwords Removed (Row 36): []\n","No stopwords removed for Row 36 in file Ses05M_impro05.csv.\n","Original Tokens (Row 37): ['i', 'should', 'hope', 'so', 'you', 'know', 'i', 'need', 'that', 'today']\n","Updated Tokens (Row 37): ['hope', 'know', 'need', 'today']\n","Stopwords Removed (Row 37): ['i', 'should', 'so', 'you', 'i', 'that']\n","Stopwords were removed for Row 37 in file Ses05M_impro05.csv.\n","Original Tokens (Row 38): ['let', 'me', 'explain', 'to', 'you', 'what', 'the', 'problem', 'is', 'my', 'grandfather', 'remains', 'are', 'in', 'that', 'bag', 'and', 'i', 'have', 'to', 'like', 'distribute', 'them', 'today', 'we', 'suppose', 'to', 'you', 'know', 'throw', 'them', 'out', 'to', 'the', 'sea', 'today']\n","Updated Tokens (Row 38): ['let', 'explain', 'problem', 'grandfather', 'remains', 'bag', 'like', 'distribute', 'today', 'suppose', 'know', 'throw', 'sea', 'today']\n","Stopwords Removed (Row 38): ['me', 'to', 'you', 'what', 'the', 'is', 'my', 'are', 'in', 'that', 'and', 'i', 'have', 'to', 'them', 'we', 'to', 'you', 'them', 'out', 'to', 'the']\n","Stopwords were removed for Row 38 in file Ses05M_impro05.csv.\n","Original Tokens (Row 39): ['yeah', 'i', 'mean', 'if', 'you', 'have', 'a', 'suggestion', 'like', 'it', 'would', 'be', 'great', 'to', 'help', 'me', 'out', 'here']\n","Updated Tokens (Row 39): ['yeah', 'mean', 'suggestion', 'like', 'would', 'great', 'help']\n","Stopwords Removed (Row 39): ['i', 'if', 'you', 'have', 'a', 'it', 'be', 'to', 'me', 'out', 'here']\n","Stopwords were removed for Row 39 in file Ses05M_impro05.csv.\n","Original Tokens (Row 40): ['well', 'i', 'do', 'not', 'care', 'if', 'it', 'is', 'legal', 'it', 'is', 'happened', 'it', 'is', 'already', 'done']\n","Updated Tokens (Row 40): ['well', 'care', 'legal', 'happened', 'already', 'done']\n","Stopwords Removed (Row 40): ['i', 'do', 'not', 'if', 'it', 'is', 'it', 'is', 'it', 'is']\n","Stopwords were removed for Row 40 in file Ses05M_impro05.csv.\n","Original Tokens (Row 41): ['well', 'could', 'you', 'tell', 'me', 'if', 'it', 'is', 'been', 'confiscated', 'then']\n","Updated Tokens (Row 41): ['well', 'could', 'tell', 'confiscated']\n","Stopwords Removed (Row 41): ['you', 'me', 'if', 'it', 'is', 'been', 'then']\n","Stopwords were removed for Row 41 in file Ses05M_impro05.csv.\n","Original Tokens (Row 42): ['i', 'mean', 'some', 'information', 'here', 'would', 'be', 'great', 'some', 'help', 'can', 'you', 'like', 'type', 'something', 'in', 'and', 'find', 'out']\n","Updated Tokens (Row 42): ['mean', 'information', 'would', 'great', 'help', 'like', 'type', 'something', 'find']\n","Stopwords Removed (Row 42): ['i', 'some', 'here', 'be', 'some', 'can', 'you', 'in', 'and', 'out']\n","Stopwords were removed for Row 42 in file Ses05M_impro05.csv.\n","Original Tokens (Row 43): ['that', 'would', 'be', 'great', 'thank', 'you', 'very', 'much']\n","Updated Tokens (Row 43): ['would', 'great', 'thank', 'much']\n","Stopwords Removed (Row 43): ['that', 'be', 'you', 'very']\n","Stopwords were removed for Row 43 in file Ses05M_impro05.csv.\n","Original Tokens (Row 44): ['thank', 'you']\n","Updated Tokens (Row 44): ['thank']\n","Stopwords Removed (Row 44): ['you']\n","Stopwords were removed for Row 44 in file Ses05M_impro05.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro05.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro05.csv\n","\n","Processing File: Ses05M_impro06.csv\n","Original Tokens (Row 0): ['ryan', 'what', 'is', 'wrong']\n","Updated Tokens (Row 0): ['ryan', 'wrong']\n","Stopwords Removed (Row 0): ['what', 'is']\n","Stopwords were removed for Row 0 in file Ses05M_impro06.csv.\n","Original Tokens (Row 1): ['what']\n","Updated Tokens (Row 1): []\n","Stopwords Removed (Row 1): ['what']\n","Stopwords were removed for Row 1 in file Ses05M_impro06.csv.\n","Original Tokens (Row 2): ['oh', 'i', 'so', 'sorry']\n","Updated Tokens (Row 2): ['oh', 'sorry']\n","Stopwords Removed (Row 2): ['i', 'so']\n","Stopwords were removed for Row 2 in file Ses05M_impro06.csv.\n","Original Tokens (Row 3): ['oh', 'my', 'gosh']\n","Updated Tokens (Row 3): ['oh', 'gosh']\n","Stopwords Removed (Row 3): ['my']\n","Stopwords were removed for Row 3 in file Ses05M_impro06.csv.\n","Original Tokens (Row 4): ['what', 'did', 'he', 'do']\n","Updated Tokens (Row 4): []\n","Stopwords Removed (Row 4): ['what', 'did', 'he', 'do']\n","Stopwords were removed for Row 4 in file Ses05M_impro06.csv.\n","Original Tokens (Row 5): ['yeah', 'i', 'so', 'sorry']\n","Updated Tokens (Row 5): ['yeah', 'sorry']\n","Stopwords Removed (Row 5): ['i', 'so']\n","Stopwords were removed for Row 5 in file Ses05M_impro06.csv.\n","Original Tokens (Row 6): ['you', 'guys', 'have', 'been']\n","Updated Tokens (Row 6): ['guys']\n","Stopwords Removed (Row 6): ['you', 'have', 'been']\n","Stopwords were removed for Row 6 in file Ses05M_impro06.csv.\n","Original Tokens (Row 7): ['i', 'sorry']\n","Updated Tokens (Row 7): ['sorry']\n","Stopwords Removed (Row 7): ['i']\n","Stopwords were removed for Row 7 in file Ses05M_impro06.csv.\n","Original Tokens (Row 8): ['wow', 'ryan', 'i', 'know', 'that', 'you', 'are', 'hurting', 'right', 'now', 'but', 'i', 'do', 'not', 'think', 'you', 'always', 'feel', 'like', 'that']\n","Updated Tokens (Row 8): ['wow', 'ryan', 'know', 'hurting', 'right', 'think', 'always', 'feel', 'like']\n","Stopwords Removed (Row 8): ['i', 'that', 'you', 'are', 'now', 'but', 'i', 'do', 'not', 'you', 'that']\n","Stopwords were removed for Row 8 in file Ses05M_impro06.csv.\n","Original Tokens (Row 9): ['yeah', 'i', 'understand', 'i', 'think', 'it', 'is', 'really', 'healthy', 'to', 'grieve']\n","Updated Tokens (Row 9): ['yeah', 'understand', 'think', 'really', 'healthy', 'grieve']\n","Stopwords Removed (Row 9): ['i', 'i', 'it', 'is', 'to']\n","Stopwords were removed for Row 9 in file Ses05M_impro06.csv.\n","Original Tokens (Row 10): ['if', 'there', 'anything', 'i', 'can', 'do', 'to', 'be', 'there', 'for', 'you']\n","Updated Tokens (Row 10): ['anything']\n","Stopwords Removed (Row 10): ['if', 'there', 'i', 'can', 'do', 'to', 'be', 'there', 'for', 'you']\n","Stopwords were removed for Row 10 in file Ses05M_impro06.csv.\n","Original Tokens (Row 11): ['i', 'just', 'got', 'some', 'bad', 'news']\n","Updated Tokens (Row 11): ['got', 'bad', 'news']\n","Stopwords Removed (Row 11): ['i', 'just', 'some']\n","Stopwords were removed for Row 11 in file Ses05M_impro06.csv.\n","Original Tokens (Row 12): ['my', 'friend', 'shotty', 'passed', 'away']\n","Updated Tokens (Row 12): ['friend', 'shotty', 'passed', 'away']\n","Stopwords Removed (Row 12): ['my']\n","Stopwords were removed for Row 12 in file Ses05M_impro06.csv.\n","Original Tokens (Row 13): ['the', 'end', 'he', 'is', 'been', 'sick', 'for', 'awhile', 'he', 'had', 'cancer']\n","Updated Tokens (Row 13): ['end', 'sick', 'awhile', 'cancer']\n","Stopwords Removed (Row 13): ['the', 'he', 'is', 'been', 'for', 'he', 'had']\n","Stopwords were removed for Row 13 in file Ses05M_impro06.csv.\n","Original Tokens (Row 14): ['yeah', 'it', 'is', 'just', 'i', 'never', 'thought', 'it', 'would', 'actually', 'happen', 'you', 'know', 'i', 'mean', 'he', 'is', 'such', 'a', 'fighter', 'and', 'he', 'is', 'always', 'so', 'positive', 'about', 'everything']\n","Updated Tokens (Row 14): ['yeah', 'never', 'thought', 'would', 'actually', 'happen', 'know', 'mean', 'fighter', 'always', 'positive', 'everything']\n","Stopwords Removed (Row 14): ['it', 'is', 'just', 'i', 'it', 'you', 'i', 'he', 'is', 'such', 'a', 'and', 'he', 'is', 'so', 'about']\n","Stopwords were removed for Row 14 in file Ses05M_impro06.csv.\n","Original Tokens (Row 15): ['you', 'know', 'he', 'was', 'gon', 'na', 'and', 'we', 'all', 'the', 'way', 'up', 'to', 'the', 'end', 'we', 'were', 'just', 'talking', 'about', 'how', 'you', 'know', 'all', 'the', 'stuff', 'we', 'were', 'gon', 'na', 'do', 'and', 'you', 'know', 'when', 'he', 'finally', 'kicked', 'this', 'stupid', 'cancer', 'you', 'know', 'and', 'we', 'were', 'gon', 'na']\n","Updated Tokens (Row 15): ['know', 'gon', 'na', 'way', 'end', 'talking', 'know', 'stuff', 'gon', 'na', 'know', 'finally', 'kicked', 'stupid', 'cancer', 'know', 'gon', 'na']\n","Stopwords Removed (Row 15): ['you', 'he', 'was', 'and', 'we', 'all', 'the', 'up', 'to', 'the', 'we', 'were', 'just', 'about', 'how', 'you', 'all', 'the', 'we', 'were', 'do', 'and', 'you', 'when', 'he', 'this', 'you', 'and', 'we', 'were']\n","Stopwords were removed for Row 15 in file Ses05M_impro06.csv.\n","Original Tokens (Row 16): ['he', 'wanted', 'to', 'travel', 'you', 'know', 'and', 'he', 'is', 'so', 'talented', 'probably', 'the', 'most', 'talented', 'person', 'i', 'have', 'ever', 'met', 'in', 'my', 'entire', 'life']\n","Updated Tokens (Row 16): ['wanted', 'travel', 'know', 'talented', 'probably', 'talented', 'person', 'ever', 'met', 'entire', 'life']\n","Stopwords Removed (Row 16): ['he', 'to', 'you', 'and', 'he', 'is', 'so', 'the', 'most', 'i', 'have', 'in', 'my']\n","Stopwords were removed for Row 16 in file Ses05M_impro06.csv.\n","Original Tokens (Row 17): ['he', 'was', 'a', 'designer', 'you', 'know', 'but', 'he', 'did', 'everything', 'you', 'know', 'he', 'painted', 'and', 'he', 'and', 'he', 'did', 'costume', 'design', 'he', 'did', 'set', 'design', 'he', 'did', 'lighting', 'he', 'was']\n","Updated Tokens (Row 17): ['designer', 'know', 'everything', 'know', 'painted', 'costume', 'design', 'set', 'design', 'lighting']\n","Stopwords Removed (Row 17): ['he', 'was', 'a', 'you', 'but', 'he', 'did', 'you', 'he', 'and', 'he', 'and', 'he', 'did', 'he', 'did', 'he', 'did', 'he', 'was']\n","Stopwords were removed for Row 17 in file Ses05M_impro06.csv.\n","Original Tokens (Row 18): ['he', 'just', 'did', 'everything', 'he', 'was', 'literally', 'literally', 'the', 'most', 'talented', 'guy', 'i', 'have', 'ever', 'met', 'in', 'my', 'entire', 'life']\n","Updated Tokens (Row 18): ['everything', 'literally', 'literally', 'talented', 'guy', 'ever', 'met', 'entire', 'life']\n","Stopwords Removed (Row 18): ['he', 'just', 'did', 'he', 'was', 'the', 'most', 'i', 'have', 'in', 'my']\n","Stopwords were removed for Row 18 in file Ses05M_impro06.csv.\n","Original Tokens (Row 19): ['and', 'he', 'is', 'gone', 'now', 'and', 'i', 'i', 'just', 'can', 'not', 'believe', 'it']\n","Updated Tokens (Row 19): ['gone', 'believe']\n","Stopwords Removed (Row 19): ['and', 'he', 'is', 'now', 'and', 'i', 'i', 'just', 'can', 'not', 'it']\n","Stopwords were removed for Row 19 in file Ses05M_impro06.csv.\n","Original Tokens (Row 20): ['i', 'mean', 'one', 'second', 'you', 'think', 'you', 'know', 'you', 'just', 'having', 'a', 'conversation', 'and', 'then']\n","Updated Tokens (Row 20): ['mean', 'one', 'second', 'think', 'know', 'conversation']\n","Stopwords Removed (Row 20): ['i', 'you', 'you', 'you', 'just', 'having', 'a', 'and', 'then']\n","Stopwords were removed for Row 20 in file Ses05M_impro06.csv.\n","Original Tokens (Row 21): ['you', 'know', 'sometimes', 'you', 'think', 'you', 'want', 'to', 'make', 'that', 'phone', 'call', 'or', 'you', 'think', 'you', 'want', 'to', 'tell', 'somebody', 'something', 'or', 'something', 'like', 'that', 'do', 'you', 'know', 'what', 'i', 'mean', 'like', 'that', 'is', 'he', 'was', 'the', 'person', 'that', 'i', 'did', 'that', 'with', 'you', 'know', 'like', 'that', 'is', 'the', 'person', 'who', 'i', 'needed', 'to', 'call', 'to', 'tell', 'things', 'to', 'all', 'the', 'time']\n","Updated Tokens (Row 21): ['know', 'sometimes', 'think', 'want', 'make', 'phone', 'call', 'think', 'want', 'tell', 'somebody', 'something', 'something', 'like', 'know', 'mean', 'like', 'person', 'know', 'like', 'person', 'needed', 'call', 'tell', 'things', 'time']\n","Stopwords Removed (Row 21): ['you', 'you', 'you', 'to', 'that', 'or', 'you', 'you', 'to', 'or', 'that', 'do', 'you', 'what', 'i', 'that', 'is', 'he', 'was', 'the', 'that', 'i', 'did', 'that', 'with', 'you', 'that', 'is', 'the', 'who', 'i', 'to', 'to', 'to', 'all', 'the']\n","Stopwords were removed for Row 21 in file Ses05M_impro06.csv.\n","Original Tokens (Row 22): ['and', 'now', 'i', 'do', 'not', 'have', 'that', 'person', 'anymore', 'you', 'know', 'and', 'it', 'is', 'it', 'is', 'just', 'you']\n","Updated Tokens (Row 22): ['person', 'anymore', 'know']\n","Stopwords Removed (Row 22): ['and', 'now', 'i', 'do', 'not', 'have', 'that', 'you', 'and', 'it', 'is', 'it', 'is', 'just', 'you']\n","Stopwords were removed for Row 22 in file Ses05M_impro06.csv.\n","Original Tokens (Row 23): ['you', 'think', 'that', 'things', 'get', 'easier', 'you', 'know', 'as', 'you', 'as', 'you', 'get', 'older', 'and', 'you']\n","Updated Tokens (Row 23): ['think', 'things', 'get', 'easier', 'know', 'get', 'older']\n","Stopwords Removed (Row 23): ['you', 'that', 'you', 'as', 'you', 'as', 'you', 'and', 'you']\n","Stopwords were removed for Row 23 in file Ses05M_impro06.csv.\n","Original Tokens (Row 24): ['and', 'it', 'just', 'gets', 'worse', 'it', 'just', 'gets', 'worse', 'everything', 'is', 'bad', 'all', 'the', 'time', 'people', 'die', 'your', 'friends', 'die', 'family', 'dies', 'your', 'best', 'friends', 'die', 'it']\n","Updated Tokens (Row 24): ['gets', 'worse', 'gets', 'worse', 'everything', 'bad', 'time', 'people', 'die', 'friends', 'die', 'family', 'dies', 'best', 'friends', 'die']\n","Stopwords Removed (Row 24): ['and', 'it', 'just', 'it', 'just', 'is', 'all', 'the', 'your', 'your', 'it']\n","Stopwords were removed for Row 24 in file Ses05M_impro06.csv.\n","Original Tokens (Row 25): ['you', 'always', 'think', 'you', 'know', 'when', 'you', 'were', 'you', 'know', 'when', 'you', 'were', 'a', 'little', 'kid', 'and', 'you', 'think', 'something', 'is', 'gon', 'na', 'happen', 'like', 'it', 'will', 'all', 'be', 'better', 'when', 'i', 'am', 'older', 'you', 'know']\n","Updated Tokens (Row 25): ['always', 'think', 'know', 'know', 'little', 'kid', 'think', 'something', 'gon', 'na', 'happen', 'like', 'better', 'older', 'know']\n","Stopwords Removed (Row 25): ['you', 'you', 'when', 'you', 'were', 'you', 'when', 'you', 'were', 'a', 'and', 'you', 'is', 'it', 'will', 'all', 'be', 'when', 'i', 'am', 'you']\n","Stopwords were removed for Row 25 in file Ses05M_impro06.csv.\n","Original Tokens (Row 26): ['and', 'i', 'do', 'not', 'know', 'why', 'people', 'do', 'not', 'just', 'tell', 'you', 'off', 'the', 'bat', 'that', 'it', 'is', 'just', 'gon', 'na', 'suck', 'anyway', 'you', 'know', 'like', 'what', 'is', 'the', 'point']\n","Updated Tokens (Row 26): ['know', 'people', 'tell', 'bat', 'gon', 'na', 'suck', 'anyway', 'know', 'like', 'point']\n","Stopwords Removed (Row 26): ['and', 'i', 'do', 'not', 'why', 'do', 'not', 'just', 'you', 'off', 'the', 'that', 'it', 'is', 'just', 'you', 'what', 'is', 'the']\n","Stopwords were removed for Row 26 in file Ses05M_impro06.csv.\n","Original Tokens (Row 27): ['all', 'the', 'best', 'people', 'die', 'all', 'the', 'bad', 'people', 'live', 'and', 'they', 'make', 'life', 'shitty', 'for', 'you', 'anyway']\n","Updated Tokens (Row 27): ['best', 'people', 'die', 'bad', 'people', 'live', 'make', 'life', 'shitty', 'anyway']\n","Stopwords Removed (Row 27): ['all', 'the', 'all', 'the', 'and', 'they', 'for', 'you']\n","Stopwords were removed for Row 27 in file Ses05M_impro06.csv.\n","Original Tokens (Row 28): ['no', 'you', 'right', 'i', 'do', 'not', 'you', 'right']\n","Updated Tokens (Row 28): ['right', 'right']\n","Stopwords Removed (Row 28): ['no', 'you', 'i', 'do', 'not', 'you']\n","Stopwords were removed for Row 28 in file Ses05M_impro06.csv.\n","Original Tokens (Row 29): ['even', 'yeah', 'he', 'does', 'not', 'he', 'would', 'never', 'feel', 'that', 'way', 'he', 'would', 'never', 'want', 'me', 'to', 'feel', 'that', 'way', 'of', 'course', 'not', 'but', 'that', 'is', 'just', 'where', 'i', 'am', 'right', 'now', 'and', 'i', 'do', 'not', 'know', 'what', 'else', 'to', 'do', 'with', 'it']\n","Updated Tokens (Row 29): ['even', 'yeah', 'would', 'never', 'feel', 'way', 'would', 'never', 'want', 'feel', 'way', 'course', 'right', 'know', 'else']\n","Stopwords Removed (Row 29): ['he', 'does', 'not', 'he', 'that', 'he', 'me', 'to', 'that', 'of', 'not', 'but', 'that', 'is', 'just', 'where', 'i', 'am', 'now', 'and', 'i', 'do', 'not', 'what', 'to', 'do', 'with', 'it']\n","Stopwords were removed for Row 29 in file Ses05M_impro06.csv.\n","Original Tokens (Row 30): ['i', 'just', 'miss', 'him']\n","Updated Tokens (Row 30): ['miss']\n","Stopwords Removed (Row 30): ['i', 'just', 'him']\n","Stopwords were removed for Row 30 in file Ses05M_impro06.csv.\n","Original Tokens (Row 31): ['thanks']\n","Updated Tokens (Row 31): ['thanks']\n","Stopwords Removed (Row 31): []\n","No stopwords removed for Row 31 in file Ses05M_impro06.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro06.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro06.csv\n","\n","Processing File: Ses05M_impro02.csv\n","Original Tokens (Row 0): ['what', 'is', 'it']\n","Updated Tokens (Row 0): []\n","Stopwords Removed (Row 0): ['what', 'is', 'it']\n","Stopwords were removed for Row 0 in file Ses05M_impro02.csv.\n","Original Tokens (Row 1): ['what']\n","Updated Tokens (Row 1): []\n","Stopwords Removed (Row 1): ['what']\n","Stopwords were removed for Row 1 in file Ses05M_impro02.csv.\n","Original Tokens (Row 2): ['what', 'no', 'you', 'can', 'not']\n","Updated Tokens (Row 2): []\n","Stopwords Removed (Row 2): ['what', 'no', 'you', 'can', 'not']\n","Stopwords were removed for Row 2 in file Ses05M_impro02.csv.\n","Original Tokens (Row 3): ['you', 'did', 'not', 'did', 'you', 'tell', 'them', 'you', 'have', 'two', 'young', 'children', 'at', 'home']\n","Updated Tokens (Row 3): ['tell', 'two', 'young', 'children', 'home']\n","Stopwords Removed (Row 3): ['you', 'did', 'not', 'did', 'you', 'them', 'you', 'have', 'at']\n","Stopwords were removed for Row 3 in file Ses05M_impro02.csv.\n","Original Tokens (Row 4): ['and', 'they', 'did', 'not', 'care']\n","Updated Tokens (Row 4): ['care']\n","Stopwords Removed (Row 4): ['and', 'they', 'did', 'not']\n","Stopwords were removed for Row 4 in file Ses05M_impro02.csv.\n","Original Tokens (Row 5): ['they', 'can', 'not', 'do', 'that', 'to', 'you']\n","Updated Tokens (Row 5): []\n","Stopwords Removed (Row 5): ['they', 'can', 'not', 'do', 'that', 'to', 'you']\n","Stopwords were removed for Row 5 in file Ses05M_impro02.csv.\n","Original Tokens (Row 6): ['no', 'we', 'have', 'there', 'got', 'to', 'be', 'something', 'you', 'can', 'do', 'you', 'can', 'not', 'go']\n","Updated Tokens (Row 6): ['got', 'something', 'go']\n","Stopwords Removed (Row 6): ['no', 'we', 'have', 'there', 'to', 'be', 'you', 'can', 'do', 'you', 'can', 'not']\n","Stopwords were removed for Row 6 in file Ses05M_impro02.csv.\n","Original Tokens (Row 7): ['how', 'long', 'do', 'you', 'have', 'to', 'go', 'for']\n","Updated Tokens (Row 7): ['long', 'go']\n","Stopwords Removed (Row 7): ['how', 'do', 'you', 'have', 'to', 'for']\n","Stopwords were removed for Row 7 in file Ses05M_impro02.csv.\n","Original Tokens (Row 8): ['what']\n","Updated Tokens (Row 8): []\n","Stopwords Removed (Row 8): ['what']\n","Stopwords were removed for Row 8 in file Ses05M_impro02.csv.\n","Original Tokens (Row 9): ['there', 'got', 'to', 'be', 'something', 'we', 'can', 'do', 'you', 'can', 'not', 'just', 'go']\n","Updated Tokens (Row 9): ['got', 'something', 'go']\n","Stopwords Removed (Row 9): ['there', 'to', 'be', 'we', 'can', 'do', 'you', 'can', 'not', 'just']\n","Stopwords were removed for Row 9 in file Ses05M_impro02.csv.\n","Original Tokens (Row 10): ['why', 'do', 'not', 'we', 'do', 'that', 'can', 'can', 'we', 'just', 'leave', 'the', 'country']\n","Updated Tokens (Row 10): ['leave', 'country']\n","Stopwords Removed (Row 10): ['why', 'do', 'not', 'we', 'do', 'that', 'can', 'can', 'we', 'just', 'the']\n","Stopwords were removed for Row 10 in file Ses05M_impro02.csv.\n","Original Tokens (Row 11): ['i', 'do', 'not', 'know']\n","Updated Tokens (Row 11): ['know']\n","Stopwords Removed (Row 11): ['i', 'do', 'not']\n","Stopwords were removed for Row 11 in file Ses05M_impro02.csv.\n","Original Tokens (Row 12): ['what', 'would', 'be', 'the', 'worst', 'that', 'would', 'happen', 'if', 'they', 'found', 'you', 'somewhere', 'else']\n","Updated Tokens (Row 12): ['would', 'worst', 'would', 'happen', 'found', 'somewhere', 'else']\n","Stopwords Removed (Row 12): ['what', 'be', 'the', 'that', 'if', 'they', 'you']\n","Stopwords were removed for Row 12 in file Ses05M_impro02.csv.\n","Original Tokens (Row 13): ['well', 'they', 'are', 'so', 'young']\n","Updated Tokens (Row 13): ['well', 'young']\n","Stopwords Removed (Row 13): ['they', 'are', 'so']\n","Stopwords were removed for Row 13 in file Ses05M_impro02.csv.\n","Original Tokens (Row 14): ['where', 'are', 'you', 'gon', 'na', 'be', 'stationed', 'what', 'are', 'you', 'gon', 'na', 'be', 'doing']\n","Updated Tokens (Row 14): ['gon', 'na', 'stationed', 'gon', 'na']\n","Stopwords Removed (Row 14): ['where', 'are', 'you', 'be', 'what', 'are', 'you', 'be', 'doing']\n","Stopwords were removed for Row 14 in file Ses05M_impro02.csv.\n","Original Tokens (Row 15): ['are', 'you', 'gon', 'na', 'be', 'like', 'in', 'tanks', 'running', 'around', 'what', 'i', 'mean', 'what', 'does', 'that', 'mean']\n","Updated Tokens (Row 15): ['gon', 'na', 'like', 'tanks', 'running', 'around', 'mean', 'mean']\n","Stopwords Removed (Row 15): ['are', 'you', 'be', 'in', 'what', 'i', 'what', 'does', 'that']\n","Stopwords were removed for Row 15 in file Ses05M_impro02.csv.\n","Original Tokens (Row 16): ['oh', 'my', 'god']\n","Updated Tokens (Row 16): ['oh', 'god']\n","Stopwords Removed (Row 16): ['my']\n","Stopwords were removed for Row 16 in file Ses05M_impro02.csv.\n","Original Tokens (Row 17): ['but', 'so', 'many', 'people', 'have', 'died']\n","Updated Tokens (Row 17): ['many', 'people', 'died']\n","Stopwords Removed (Row 17): ['but', 'so', 'have']\n","Stopwords were removed for Row 17 in file Ses05M_impro02.csv.\n","Original Tokens (Row 18): ['i', 'know', 'i', 'know', 'i', 'know', 'i', 'know', 'you', 'good', 'you', 'good', 'at', 'what', 'you', 'do', 'but', 'there', 'just', 'so', 'much', 'chance', 'involved']\n","Updated Tokens (Row 18): ['know', 'know', 'know', 'know', 'good', 'good', 'much', 'chance', 'involved']\n","Stopwords Removed (Row 18): ['i', 'i', 'i', 'i', 'you', 'you', 'at', 'what', 'you', 'do', 'but', 'there', 'just', 'so']\n","Stopwords were removed for Row 18 in file Ses05M_impro02.csv.\n","Original Tokens (Row 19): ['i', 'mean', 'i-i', 'know', 'that', 'you', 'a', 'good', 'soldier', 'but', 'not', 'everybody', 'else', 'is', 'and', 'what', 'if']\n","Updated Tokens (Row 19): ['mean', 'i-i', 'know', 'good', 'soldier', 'everybody', 'else']\n","Stopwords Removed (Row 19): ['i', 'that', 'you', 'a', 'but', 'not', 'is', 'and', 'what', 'if']\n","Stopwords were removed for Row 19 in file Ses05M_impro02.csv.\n","Original Tokens (Row 20): ['it', 'is', 'just', 'so', 'much']\n","Updated Tokens (Row 20): ['much']\n","Stopwords Removed (Row 20): ['it', 'is', 'just', 'so']\n","Stopwords were removed for Row 20 in file Ses05M_impro02.csv.\n","Original Tokens (Row 21): ['garbage', 'you', 'have', 'to', 'write', 'me', 'everyday']\n","Updated Tokens (Row 21): ['garbage', 'write', 'everyday']\n","Stopwords Removed (Row 21): ['you', 'have', 'to', 'me']\n","Stopwords were removed for Row 21 in file Ses05M_impro02.csv.\n","Original Tokens (Row 22): ['can', 'i', 'send', 'you', 'like', 'videos', 'and', 'stuff', 'what', 'about', 'when', 'they', 'start', 'walking']\n","Updated Tokens (Row 22): ['send', 'like', 'videos', 'stuff', 'start', 'walking']\n","Stopwords Removed (Row 22): ['can', 'i', 'you', 'and', 'what', 'about', 'when', 'they']\n","Stopwords were removed for Row 22 in file Ses05M_impro02.csv.\n","Original Tokens (Row 23): ['okay']\n","Updated Tokens (Row 23): ['okay']\n","Stopwords Removed (Row 23): []\n","No stopwords removed for Row 23 in file Ses05M_impro02.csv.\n","Original Tokens (Row 24): ['garbage']\n","Updated Tokens (Row 24): ['garbage']\n","Stopwords Removed (Row 24): []\n","No stopwords removed for Row 24 in file Ses05M_impro02.csv.\n","Original Tokens (Row 25): ['sweetheart', 'i', 'got', 'to', 'tell', 'you', 'something', 'i', 'just', 'got', 'a', 'call', 'i', 'going', 'to', 'iraq']\n","Updated Tokens (Row 25): ['sweetheart', 'got', 'tell', 'something', 'got', 'call', 'going', 'iraq']\n","Stopwords Removed (Row 25): ['i', 'to', 'you', 'i', 'just', 'a', 'i', 'to']\n","Stopwords were removed for Row 25 in file Ses05M_impro02.csv.\n","Original Tokens (Row 26): ['i', 'know', 'it', 'is', 'really', 'crappy', 'timing', 'but', 'i', 'do', 'not', 'have', 'a', 'choice']\n","Updated Tokens (Row 26): ['know', 'really', 'crappy', 'timing', 'choice']\n","Stopwords Removed (Row 26): ['i', 'it', 'is', 'but', 'i', 'do', 'not', 'have', 'a']\n","Stopwords were removed for Row 26 in file Ses05M_impro02.csv.\n","Original Tokens (Row 27): ['i', 'know', 'i', 'have', 'to', 'go']\n","Updated Tokens (Row 27): ['know', 'go']\n","Stopwords Removed (Row 27): ['i', 'i', 'have', 'to']\n","Stopwords were removed for Row 27 in file Ses05M_impro02.csv.\n","Original Tokens (Row 28): ['you', 'think', 'they', 'listen', 'to', 'me', 'no', 'of', 'course', 'i', 'told', 'them', 'that']\n","Updated Tokens (Row 28): ['think', 'listen', 'course', 'told']\n","Stopwords Removed (Row 28): ['you', 'they', 'to', 'me', 'no', 'of', 'i', 'them', 'that']\n","Stopwords were removed for Row 28 in file Ses05M_impro02.csv.\n","Original Tokens (Row 29): ['no']\n","Updated Tokens (Row 29): []\n","Stopwords Removed (Row 29): ['no']\n","Stopwords were removed for Row 29 in file Ses05M_impro02.csv.\n","Original Tokens (Row 30): ['i', 'do', 'not', 'know', 'what', 'to', 'do', 'i', 'sorry']\n","Updated Tokens (Row 30): ['know', 'sorry']\n","Stopwords Removed (Row 30): ['i', 'do', 'not', 'what', 'to', 'do', 'i']\n","Stopwords were removed for Row 30 in file Ses05M_impro02.csv.\n","Original Tokens (Row 31): ['i', 'know']\n","Updated Tokens (Row 31): ['know']\n","Stopwords Removed (Row 31): ['i']\n","Stopwords were removed for Row 31 in file Ses05M_impro02.csv.\n","Original Tokens (Row 32): ['i', 'do', 'not', 'have', 'a', 'choice', 'i', 'have', 'to', 'go', 'if', 'i', 'do', 'not', 'go', 'they', 'come', 'and', 'take', 'me']\n","Updated Tokens (Row 32): ['choice', 'go', 'go', 'come', 'take']\n","Stopwords Removed (Row 32): ['i', 'do', 'not', 'have', 'a', 'i', 'have', 'to', 'if', 'i', 'do', 'not', 'they', 'and', 'me']\n","Stopwords were removed for Row 32 in file Ses05M_impro02.csv.\n","Original Tokens (Row 33): ['i', 'tried', 'everything', 'i', 'called', 'everyone', 'i', 'know', 'i', 'tried', 'everything', 'no', 'one', 'can', 'do', 'anything', 'for', 'me', 'or', 'they', 'will', 'not', 'do', 'anything', 'for', 'me']\n","Updated Tokens (Row 33): ['tried', 'everything', 'called', 'everyone', 'know', 'tried', 'everything', 'one', 'anything', 'anything']\n","Stopwords Removed (Row 33): ['i', 'i', 'i', 'i', 'no', 'can', 'do', 'for', 'me', 'or', 'they', 'will', 'not', 'do', 'for', 'me']\n","Stopwords were removed for Row 33 in file Ses05M_impro02.csv.\n","Original Tokens (Row 34): ['at', 'least', 'a', 'year']\n","Updated Tokens (Row 34): ['least', 'year']\n","Stopwords Removed (Row 34): ['at', 'a']\n","Stopwords were removed for Row 34 in file Ses05M_impro02.csv.\n","Original Tokens (Row 35): ['i', 'know']\n","Updated Tokens (Row 35): ['know']\n","Stopwords Removed (Row 35): ['i']\n","Stopwords were removed for Row 35 in file Ses05M_impro02.csv.\n","Original Tokens (Row 36): ['i', 'do', 'not', 'want', 'to', 'the', 'kids', 'you', 'have', 'got', 'to', 'take', 'care', 'of', 'them', 'you', 'have', 'got', 'you', 'have', 'got', 'to']\n","Updated Tokens (Row 36): ['want', 'kids', 'got', 'take', 'care', 'got', 'got']\n","Stopwords Removed (Row 36): ['i', 'do', 'not', 'to', 'the', 'you', 'have', 'to', 'of', 'them', 'you', 'have', 'you', 'have', 'to']\n","Stopwords were removed for Row 36 in file Ses05M_impro02.csv.\n","Original Tokens (Row 37): ['tell', 'them', 'about', 'me', 'and', 'show', 'them', 'pictures', 'of', 'me', 'and', 'everything', 'like', 'that', 'because', 'they', 'are', 'not', 'going', 'to', 'see', 'me', 'for', 'such', 'a', 'long', 'time', 'and', 'it', 'is', 'such', 'an', 'important', 'time', 'and', 'i', 'just', 'do', 'not', 'want', 'to', 'miss', 'it']\n","Updated Tokens (Row 37): ['tell', 'show', 'pictures', 'everything', 'like', 'going', 'see', 'long', 'time', 'important', 'time', 'want', 'miss']\n","Stopwords Removed (Row 37): ['them', 'about', 'me', 'and', 'them', 'of', 'me', 'and', 'that', 'because', 'they', 'are', 'not', 'to', 'me', 'for', 'such', 'a', 'and', 'it', 'is', 'such', 'an', 'and', 'i', 'just', 'do', 'not', 'to', 'it']\n","Stopwords were removed for Row 37 in file Ses05M_impro02.csv.\n","Original Tokens (Row 38): ['i', 'do', 'not', 'have', 'i', 'know', 'what', 'are', 'we', 'gon', 'na', 'what', 'are', 'just', 'run', 'away', 'what', 'can', 'i', 'do', 'where', 'can', 'we', 'go']\n","Updated Tokens (Row 38): ['know', 'gon', 'na', 'run', 'away', 'go']\n","Stopwords Removed (Row 38): ['i', 'do', 'not', 'have', 'i', 'what', 'are', 'we', 'what', 'are', 'just', 'what', 'can', 'i', 'do', 'where', 'can', 'we']\n","Stopwords were removed for Row 38 in file Ses05M_impro02.csv.\n","Original Tokens (Row 39): ['where', 'are', 'we', 'gon', 'na', 'go']\n","Updated Tokens (Row 39): ['gon', 'na', 'go']\n","Stopwords Removed (Row 39): ['where', 'are', 'we']\n","Stopwords were removed for Row 39 in file Ses05M_impro02.csv.\n","Original Tokens (Row 40): ['where', 'are', 'we', 'gon', 'na', 'go']\n","Updated Tokens (Row 40): ['gon', 'na', 'go']\n","Stopwords Removed (Row 40): ['where', 'are', 'we']\n","Stopwords were removed for Row 40 in file Ses05M_impro02.csv.\n","Original Tokens (Row 41): ['they', 'find', 'me', 'anyway', 'you', 'know', 'they', 'will']\n","Updated Tokens (Row 41): ['find', 'anyway', 'know']\n","Stopwords Removed (Row 41): ['they', 'me', 'you', 'they', 'will']\n","Stopwords were removed for Row 41 in file Ses05M_impro02.csv.\n","Original Tokens (Row 42): ['they', 'put', 'me', 'in', 'jail', 'and', 'then', 'how', 'long', 'when', 'will', 'i', 'get', 'to', 'see', 'the', 'kids', 'what', 'ten', 'years', 'i', 'do', 'not', 'know']\n","Updated Tokens (Row 42): ['put', 'jail', 'long', 'get', 'see', 'kids', 'ten', 'years', 'know']\n","Stopwords Removed (Row 42): ['they', 'me', 'in', 'and', 'then', 'how', 'when', 'will', 'i', 'to', 'the', 'what', 'i', 'do', 'not']\n","Stopwords were removed for Row 42 in file Ses05M_impro02.csv.\n","Original Tokens (Row 43): ['i', 'know', 'but', \"i'll-i\", 'send', 'the', 'pictures', 'all', 'the', 'time', 'and', 'i', 'write', 'them', 'emails', 'and', 'you', 'can', 'read', 'them', 'the', 'emails', 'that', 'i', 'send', 'them']\n","Updated Tokens (Row 43): ['know', \"i'll-i\", 'send', 'pictures', 'time', 'write', 'emails', 'read', 'emails', 'send']\n","Stopwords Removed (Row 43): ['i', 'but', 'the', 'all', 'the', 'and', 'i', 'them', 'and', 'you', 'can', 'them', 'the', 'that', 'i', 'them']\n","Stopwords were removed for Row 43 in file Ses05M_impro02.csv.\n","Original Tokens (Row 44): ['i', 'gon', 'na', 'be', 'in', 'bagdad', 'just', 'doing', 'security']\n","Updated Tokens (Row 44): ['gon', 'na', 'bagdad', 'security']\n","Stopwords Removed (Row 44): ['i', 'be', 'in', 'just', 'doing']\n","Stopwords were removed for Row 44 in file Ses05M_impro02.csv.\n","Original Tokens (Row 45): ['yeah', 'it', 'is', 'gon', 'na', 'be', 'everything', 'i', 'gon', 'na', 'be', 'in', 'the', 'front', 'i', 'be', 'it', 'is', 'not', 'gon', 'na', 'be', 'safe']\n","Updated Tokens (Row 45): ['yeah', 'gon', 'na', 'everything', 'gon', 'na', 'front', 'gon', 'na', 'safe']\n","Stopwords Removed (Row 45): ['it', 'is', 'be', 'i', 'be', 'in', 'the', 'i', 'be', 'it', 'is', 'not', 'be']\n","Stopwords were removed for Row 45 in file Ses05M_impro02.csv.\n","Original Tokens (Row 46): ['i', 'just', 'want', 'to', 'be', 'honest', 'with', 'you', 'i', 'do', 'not', 'want', 'you', 'to']\n","Updated Tokens (Row 46): ['want', 'honest', 'want']\n","Stopwords Removed (Row 46): ['i', 'just', 'to', 'be', 'with', 'you', 'i', 'do', 'not', 'you', 'to']\n","Stopwords were removed for Row 46 in file Ses05M_impro02.csv.\n","Original Tokens (Row 47): ['but', 'it', 'is', 'gon', 'na', 'be', 'fine', 'i', 'gon', 'na', 'be', 'fine', 'you', 'know', 'i', 'good', 'at', 'this', 'i', 'can', 'do', 'this', 'that', 'is', 'why', 'i', 'trained', 'all', 'this', 'time', 'i', 'good', 'at', 'this', 'okay']\n","Updated Tokens (Row 47): ['gon', 'na', 'fine', 'gon', 'na', 'fine', 'know', 'good', 'trained', 'time', 'good', 'okay']\n","Stopwords Removed (Row 47): ['but', 'it', 'is', 'be', 'i', 'be', 'you', 'i', 'at', 'this', 'i', 'can', 'do', 'this', 'that', 'is', 'why', 'i', 'all', 'this', 'i', 'at', 'this']\n","Stopwords were removed for Row 47 in file Ses05M_impro02.csv.\n","Original Tokens (Row 48): ['i', 'know', 'i', 'know', 'i', 'know', 'but', 'you', 'know', 'what', 'that', 'does', 'not', 'mean', 'it', 'is', 'gon', 'na', 'be', 'me', 'does', 'it']\n","Updated Tokens (Row 48): ['know', 'know', 'know', 'know', 'mean', 'gon', 'na']\n","Stopwords Removed (Row 48): ['i', 'i', 'i', 'but', 'you', 'what', 'that', 'does', 'not', 'it', 'is', 'be', 'me', 'does', 'it']\n","Stopwords were removed for Row 48 in file Ses05M_impro02.csv.\n","Original Tokens (Row 49): ['no', 'it', 'does', 'not', 'and', 'you', 'can', 'not', 'think', 'like', 'that']\n","Updated Tokens (Row 49): ['think', 'like']\n","Stopwords Removed (Row 49): ['no', 'it', 'does', 'not', 'and', 'you', 'can', 'not', 'that']\n","Stopwords were removed for Row 49 in file Ses05M_impro02.csv.\n","Original Tokens (Row 50): ['i', 'do', 'not', 'want', 'you', 'to', 'i', 'know', 'i', 'know', 'you', 'can', 'not', 'worry', 'about', 'me', 'you', 'have', 'got', 'to', 'worry', 'about', 'the', 'kids', 'and', 'you', 'have', 'got', 'to', 'take', 'care', 'of', 'the', 'kids', 'for', 'me', 'okay', 'take', 'care', 'of', 'the', 'kids', 'for', 'me', 'all', 'right']\n","Updated Tokens (Row 50): ['want', 'know', 'know', 'worry', 'got', 'worry', 'kids', 'got', 'take', 'care', 'kids', 'okay', 'take', 'care', 'kids', 'right']\n","Stopwords Removed (Row 50): ['i', 'do', 'not', 'you', 'to', 'i', 'i', 'you', 'can', 'not', 'about', 'me', 'you', 'have', 'to', 'about', 'the', 'and', 'you', 'have', 'to', 'of', 'the', 'for', 'me', 'of', 'the', 'for', 'me', 'all']\n","Stopwords were removed for Row 50 in file Ses05M_impro02.csv.\n","Original Tokens (Row 51): ['and', 'you', 'know', 'my', 'mom', 'here', 'she', 'come', 'over', 'and', 'she', 'be', 'with', 'you', 'all', 'the', 'time', 'whenever', 'you', 'need', 'her']\n","Updated Tokens (Row 51): ['know', 'mom', 'come', 'time', 'whenever', 'need']\n","Stopwords Removed (Row 51): ['and', 'you', 'my', 'here', 'she', 'over', 'and', 'she', 'be', 'with', 'you', 'all', 'the', 'you', 'her']\n","Stopwords were removed for Row 51 in file Ses05M_impro02.csv.\n","Original Tokens (Row 52): ['i', 'miss', 'you', 'baby']\n","Updated Tokens (Row 52): ['miss', 'baby']\n","Stopwords Removed (Row 52): ['i', 'you']\n","Stopwords were removed for Row 52 in file Ses05M_impro02.csv.\n","Original Tokens (Row 53): ['all', 'i', 'write', 'you', 'everyday', 'all', 'the', 'time', 'and', 'i', 'send', 'you', 'pictures', 'and', 'you', 'send', 'me', 'pictures', 'i', 'know', 'we', 'have', 'got', 'email', 'out', 'there', 'we', 'have', 'got', 'email', 'and', 'i', 'can', 'see', 'stuff', 'and', 'you', 'can', 'send', 'me', 'stuff', 'all', 'the', 'time', 'okay']\n","Updated Tokens (Row 53): ['write', 'everyday', 'time', 'send', 'pictures', 'send', 'pictures', 'know', 'got', 'email', 'got', 'email', 'see', 'stuff', 'send', 'stuff', 'time', 'okay']\n","Stopwords Removed (Row 53): ['all', 'i', 'you', 'all', 'the', 'and', 'i', 'you', 'and', 'you', 'me', 'i', 'we', 'have', 'out', 'there', 'we', 'have', 'and', 'i', 'can', 'and', 'you', 'can', 'me', 'all', 'the']\n","Stopwords were removed for Row 53 in file Ses05M_impro02.csv.\n","Original Tokens (Row 54): ['yeah', 'yeah', 'yeah']\n","Updated Tokens (Row 54): ['yeah', 'yeah', 'yeah']\n","Stopwords Removed (Row 54): []\n","No stopwords removed for Row 54 in file Ses05M_impro02.csv.\n","Original Tokens (Row 55): ['you', 'you', 'record', 'every', 'second', 'you', 'record', 'every', 'second', 'because', 'i', 'want', 'to', 'see', 'it', 'all', 'okay']\n","Updated Tokens (Row 55): ['record', 'every', 'second', 'record', 'every', 'second', 'want', 'see', 'okay']\n","Stopwords Removed (Row 55): ['you', 'you', 'you', 'because', 'i', 'to', 'it', 'all']\n","Stopwords were removed for Row 55 in file Ses05M_impro02.csv.\n","Original Tokens (Row 56): ['if', 'i', 'do', 'not', 'get', 'to', 'see', 'it', 'now', 'i', 'get', 'to', 'see', 'it', 'later', 'at', 'least', 'you', 'know', 'you', 'have', 'got', 'to', 'keep', 'it', 'all', 'for', 'me', 'all', 'right']\n","Updated Tokens (Row 56): ['get', 'see', 'get', 'see', 'later', 'least', 'know', 'got', 'keep', 'right']\n","Stopwords Removed (Row 56): ['if', 'i', 'do', 'not', 'to', 'it', 'now', 'i', 'to', 'it', 'at', 'you', 'you', 'have', 'to', 'it', 'all', 'for', 'me', 'all']\n","Stopwords were removed for Row 56 in file Ses05M_impro02.csv.\n","Original Tokens (Row 57): ['i', 'love', 'you', 'okay']\n","Updated Tokens (Row 57): ['love', 'okay']\n","Stopwords Removed (Row 57): ['i', 'you']\n","Stopwords were removed for Row 57 in file Ses05M_impro02.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro02.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro02.csv\n","\n","Processing File: Ses05M_impro07.csv\n","Original Tokens (Row 0): ['what']\n","Updated Tokens (Row 0): []\n","Stopwords Removed (Row 0): ['what']\n","Stopwords were removed for Row 0 in file Ses05M_impro07.csv.\n","Original Tokens (Row 1): ['oh', 'for', 'real']\n","Updated Tokens (Row 1): ['oh', 'real']\n","Stopwords Removed (Row 1): ['for']\n","Stopwords were removed for Row 1 in file Ses05M_impro07.csv.\n","Original Tokens (Row 2): ['that', 'is', 'awesome']\n","Updated Tokens (Row 2): ['awesome']\n","Stopwords Removed (Row 2): ['that', 'is']\n","Stopwords were removed for Row 2 in file Ses05M_impro07.csv.\n","Original Tokens (Row 3): ['oh', 'i', 'so', 'glad']\n","Updated Tokens (Row 3): ['oh', 'glad']\n","Stopwords Removed (Row 3): ['i', 'so']\n","Stopwords were removed for Row 3 in file Ses05M_impro07.csv.\n","Original Tokens (Row 4): ['what', 'are', 'you', 'gon', 'na', 'study']\n","Updated Tokens (Row 4): ['gon', 'na', 'study']\n","Stopwords Removed (Row 4): ['what', 'are', 'you']\n","Stopwords were removed for Row 4 in file Ses05M_impro07.csv.\n","Original Tokens (Row 5): ['really', 'are', 'you', 'doing', 'the', 'm.f.a', 'program']\n","Updated Tokens (Row 5): ['really', 'm.f.a', 'program']\n","Stopwords Removed (Row 5): ['are', 'you', 'doing', 'the']\n","Stopwords were removed for Row 5 in file Ses05M_impro07.csv.\n","Original Tokens (Row 6): ['oh', 'my', 'gosh']\n","Updated Tokens (Row 6): ['oh', 'gosh']\n","Stopwords Removed (Row 6): ['my']\n","Stopwords were removed for Row 6 in file Ses05M_impro07.csv.\n","Original Tokens (Row 7): ['i', 'heard', 'it', 'is', 'so', 'tough', 'to', 'get', 'into']\n","Updated Tokens (Row 7): ['heard', 'tough', 'get']\n","Stopwords Removed (Row 7): ['i', 'it', 'is', 'so', 'to', 'into']\n","Stopwords were removed for Row 7 in file Ses05M_impro07.csv.\n","Original Tokens (Row 8): ['that', 'is', 'awesome']\n","Updated Tokens (Row 8): ['awesome']\n","Stopwords Removed (Row 8): ['that', 'is']\n","Stopwords were removed for Row 8 in file Ses05M_impro07.csv.\n","Original Tokens (Row 9): ['yeah', 'that', 'is', 'awesome']\n","Updated Tokens (Row 9): ['yeah', 'awesome']\n","Stopwords Removed (Row 9): ['that', 'is']\n","Stopwords were removed for Row 9 in file Ses05M_impro07.csv.\n","Original Tokens (Row 10): ['no']\n","Updated Tokens (Row 10): []\n","Stopwords Removed (Row 10): ['no']\n","Stopwords were removed for Row 10 in file Ses05M_impro07.csv.\n","Original Tokens (Row 11): ['uh', 'huh', 'yes', 'seriously', 'for', 'years']\n","Updated Tokens (Row 11): ['uh', 'huh', 'yes', 'seriously', 'years']\n","Stopwords Removed (Row 11): ['for']\n","Stopwords were removed for Row 11 in file Ses05M_impro07.csv.\n","Original Tokens (Row 12): ['i', 'know', 'i', 'know', \"i'm\", 'i', 'definitely', 'i', 'realize', 'laughter']\n","Updated Tokens (Row 12): ['know', 'know', \"i'm\", 'definitely', 'realize', 'laughter']\n","Stopwords Removed (Row 12): ['i', 'i', 'i', 'i']\n","Stopwords were removed for Row 12 in file Ses05M_impro07.csv.\n","Original Tokens (Row 13): ['um', 'i', 'gon', 'na', 'be', 'studying', 'at', 'u.s.c.', 'too']\n","Updated Tokens (Row 13): ['um', 'gon', 'na', 'studying', 'u.s.c.']\n","Stopwords Removed (Row 13): ['i', 'be', 'at', 'too']\n","Stopwords were removed for Row 13 in file Ses05M_impro07.csv.\n","Original Tokens (Row 14): ['not', 'on', 'campus', 'but', 'um', 'i', 'probably', 'will', 'not', 'live', 'too', 'far', 'maybe', 'i', 'do', 'not', 'know', 'i', 'might', 'go', 'to', 'silver', 'lake', 'or', 'something']\n","Updated Tokens (Row 14): ['campus', 'um', 'probably', 'live', 'far', 'maybe', 'know', 'might', 'go', 'silver', 'lake', 'something']\n","Stopwords Removed (Row 14): ['not', 'on', 'but', 'i', 'will', 'not', 'too', 'i', 'do', 'not', 'i', 'to', 'or']\n","Stopwords were removed for Row 14 in file Ses05M_impro07.csv.\n","Original Tokens (Row 15): ['yeah', 'totally', 'well', 'where', 'are', 'you', 'going', 'to', 'live']\n","Updated Tokens (Row 15): ['yeah', 'totally', 'well', 'going', 'live']\n","Stopwords Removed (Row 15): ['where', 'are', 'you', 'to']\n","Stopwords were removed for Row 15 in file Ses05M_impro07.csv.\n","Original Tokens (Row 16): ['oh', 'yeah']\n","Updated Tokens (Row 16): ['oh', 'yeah']\n","Stopwords Removed (Row 16): []\n","No stopwords removed for Row 16 in file Ses05M_impro07.csv.\n","Original Tokens (Row 17): ['good', 'tradeoff']\n","Updated Tokens (Row 17): ['good', 'tradeoff']\n","Stopwords Removed (Row 17): []\n","No stopwords removed for Row 17 in file Ses05M_impro07.csv.\n","Original Tokens (Row 18): ['i', 'do', 'not', 'i', 'do', 'not', 'think', 'it', 'is', 'that', 'bad']\n","Updated Tokens (Row 18): ['think', 'bad']\n","Stopwords Removed (Row 18): ['i', 'do', 'not', 'i', 'do', 'not', 'it', 'is', 'that']\n","Stopwords were removed for Row 18 in file Ses05M_impro07.csv.\n","Original Tokens (Row 19): ['yeah']\n","Updated Tokens (Row 19): ['yeah']\n","Stopwords Removed (Row 19): []\n","No stopwords removed for Row 19 in file Ses05M_impro07.csv.\n","Original Tokens (Row 20): ['yeah', 'i', 'think', 'it', 'is', 'really', 'also', 'if', 'you', 'if', 'you', 'consider', 'yourself', 'like', 'us', 'and', 'them', 'kind', 'of', 'thing', 'if', 'you', 'think', 'you', 'part', 'of', 'your', 'community', 'then', 'you', 'going', 'to', 'like', 'it', 'more']\n","Updated Tokens (Row 20): ['yeah', 'think', 'really', 'also', 'consider', 'like', 'us', 'kind', 'thing', 'think', 'part', 'community', 'going', 'like']\n","Stopwords Removed (Row 20): ['i', 'it', 'is', 'if', 'you', 'if', 'you', 'yourself', 'and', 'them', 'of', 'if', 'you', 'you', 'of', 'your', 'then', 'you', 'to', 'it', 'more']\n","Stopwords were removed for Row 20 in file Ses05M_impro07.csv.\n","Original Tokens (Row 21): ['right', 'exactly']\n","Updated Tokens (Row 21): ['right', 'exactly']\n","Stopwords Removed (Row 21): []\n","No stopwords removed for Row 21 in file Ses05M_impro07.csv.\n","Original Tokens (Row 22): ['oh', 'i', 'so', 'glad']\n","Updated Tokens (Row 22): ['oh', 'glad']\n","Stopwords Removed (Row 22): ['i', 'so']\n","Stopwords were removed for Row 22 in file Ses05M_impro07.csv.\n","Original Tokens (Row 23): ['so', 'when', 'do', 'you', 'know', 'like', 'where', 'you', 'gon', 'na', 'live', 'and']\n","Updated Tokens (Row 23): ['know', 'like', 'gon', 'na', 'live']\n","Stopwords Removed (Row 23): ['so', 'when', 'do', 'you', 'where', 'you', 'and']\n","Stopwords were removed for Row 23 in file Ses05M_impro07.csv.\n","Original Tokens (Row 24): ['oh', 'wow']\n","Updated Tokens (Row 24): ['oh', 'wow']\n","Stopwords Removed (Row 24): []\n","No stopwords removed for Row 24 in file Ses05M_impro07.csv.\n","Original Tokens (Row 25): ['um']\n","Updated Tokens (Row 25): ['um']\n","Stopwords Removed (Row 25): []\n","No stopwords removed for Row 25 in file Ses05M_impro07.csv.\n","Original Tokens (Row 26): ['yeah', 'i', 'mean', 'i', 'know', 'i', 'know', 'like', 'the', 'the', 'housing', 'surrounding', 'the', 'campus', 'pretty', 'well']\n","Updated Tokens (Row 26): ['yeah', 'mean', 'know', 'know', 'like', 'housing', 'surrounding', 'campus', 'pretty', 'well']\n","Stopwords Removed (Row 26): ['i', 'i', 'i', 'the', 'the', 'the']\n","Stopwords were removed for Row 26 in file Ses05M_impro07.csv.\n","Original Tokens (Row 27): ['um', 'how', 'many', 'people', 'do', 'you', 'want', 'to', 'live', 'with']\n","Updated Tokens (Row 27): ['um', 'many', 'people', 'want', 'live']\n","Stopwords Removed (Row 27): ['how', 'do', 'you', 'to', 'with']\n","Stopwords were removed for Row 27 in file Ses05M_impro07.csv.\n","Original Tokens (Row 28): ['all', 'dudes']\n","Updated Tokens (Row 28): ['dudes']\n","Stopwords Removed (Row 28): ['all']\n","Stopwords were removed for Row 28 in file Ses05M_impro07.csv.\n","Original Tokens (Row 29): ['um', 'i', 'think', 'i', 'have', 'some', 'friends']\n","Updated Tokens (Row 29): ['um', 'think', 'friends']\n","Stopwords Removed (Row 29): ['i', 'i', 'have', 'some']\n","Stopwords were removed for Row 29 in file Ses05M_impro07.csv.\n","Original Tokens (Row 30): ['yeah']\n","Updated Tokens (Row 30): ['yeah']\n","Stopwords Removed (Row 30): []\n","No stopwords removed for Row 30 in file Ses05M_impro07.csv.\n","Original Tokens (Row 31): ['there', 'actually', 'a', 'friend', 'of', 'mine', 'is', 'um', 'moving', 'out', 'of', 'her', 'place', 'and', 'her', 'place', 'is', 'amazing', 'and', 'it', 'is', 'really', 'cheap']\n","Updated Tokens (Row 31): ['actually', 'friend', 'mine', 'um', 'moving', 'place', 'place', 'amazing', 'really', 'cheap']\n","Stopwords Removed (Row 31): ['there', 'a', 'of', 'is', 'out', 'of', 'her', 'and', 'her', 'is', 'and', 'it', 'is']\n","Stopwords were removed for Row 31 in file Ses05M_impro07.csv.\n","Original Tokens (Row 32): ['yeah']\n","Updated Tokens (Row 32): ['yeah']\n","Stopwords Removed (Row 32): []\n","No stopwords removed for Row 32 in file Ses05M_impro07.csv.\n","Original Tokens (Row 33): ['okay']\n","Updated Tokens (Row 33): ['okay']\n","Stopwords Removed (Row 33): []\n","No stopwords removed for Row 33 in file Ses05M_impro07.csv.\n","Original Tokens (Row 34): ['how', 'are', 'you', 'going', 'to', 'pay', 'for', 'school', 'did', 'did', 'you']\n","Updated Tokens (Row 34): ['going', 'pay', 'school']\n","Stopwords Removed (Row 34): ['how', 'are', 'you', 'to', 'for', 'did', 'did', 'you']\n","Stopwords were removed for Row 34 in file Ses05M_impro07.csv.\n","Original Tokens (Row 35): ['you', 'have', 'got', 'a', 'lot', 'oh', 'awesome']\n","Updated Tokens (Row 35): ['got', 'lot', 'oh', 'awesome']\n","Stopwords Removed (Row 35): ['you', 'have', 'a']\n","Stopwords were removed for Row 35 in file Ses05M_impro07.csv.\n","Original Tokens (Row 36): ['oh', 'cool']\n","Updated Tokens (Row 36): ['oh', 'cool']\n","Stopwords Removed (Row 36): []\n","No stopwords removed for Row 36 in file Ses05M_impro07.csv.\n","Original Tokens (Row 37): ['yeah']\n","Updated Tokens (Row 37): ['yeah']\n","Stopwords Removed (Row 37): []\n","No stopwords removed for Row 37 in file Ses05M_impro07.csv.\n","Original Tokens (Row 38): ['totally']\n","Updated Tokens (Row 38): ['totally']\n","Stopwords Removed (Row 38): []\n","No stopwords removed for Row 38 in file Ses05M_impro07.csv.\n","Original Tokens (Row 39): ['good', 'for', 'you']\n","Updated Tokens (Row 39): ['good']\n","Stopwords Removed (Row 39): ['for', 'you']\n","Stopwords were removed for Row 39 in file Ses05M_impro07.csv.\n","Original Tokens (Row 40): ['the', 'way', 'to', 'do', 'it']\n","Updated Tokens (Row 40): ['way']\n","Stopwords Removed (Row 40): ['the', 'to', 'do', 'it']\n","Stopwords were removed for Row 40 in file Ses05M_impro07.csv.\n","Original Tokens (Row 41): ['wow', 'are', 'you', 'so', 'excited']\n","Updated Tokens (Row 41): ['wow', 'excited']\n","Stopwords Removed (Row 41): ['are', 'you', 'so']\n","Stopwords were removed for Row 41 in file Ses05M_impro07.csv.\n","Original Tokens (Row 42): ['you', 'gon', 'na', 'be', 'so', 'busy', 'too', 'you', 'going', 'to', 'have', 'to', 'work', 'so', 'hard']\n","Updated Tokens (Row 42): ['gon', 'na', 'busy', 'going', 'work', 'hard']\n","Stopwords Removed (Row 42): ['you', 'be', 'so', 'too', 'you', 'to', 'have', 'to', 'so']\n","Stopwords were removed for Row 42 in file Ses05M_impro07.csv.\n","Original Tokens (Row 43): ['oh', 'totally']\n","Updated Tokens (Row 43): ['oh', 'totally']\n","Stopwords Removed (Row 43): []\n","No stopwords removed for Row 43 in file Ses05M_impro07.csv.\n","Original Tokens (Row 44): ['all', 'right', 'wow', 'so', 'exciting']\n","Updated Tokens (Row 44): ['right', 'wow', 'exciting']\n","Stopwords Removed (Row 44): ['all', 'so']\n","Stopwords were removed for Row 44 in file Ses05M_impro07.csv.\n","Original Tokens (Row 45): ['yeah', 'we', 'have', 'so', 'much', 'fun']\n","Updated Tokens (Row 45): ['yeah', 'much', 'fun']\n","Stopwords Removed (Row 45): ['we', 'have', 'so']\n","Stopwords were removed for Row 45 in file Ses05M_impro07.csv.\n","Original Tokens (Row 46): ['cool']\n","Updated Tokens (Row 46): ['cool']\n","Stopwords Removed (Row 46): []\n","No stopwords removed for Row 46 in file Ses05M_impro07.csv.\n","Original Tokens (Row 47): ['guess', 'what']\n","Updated Tokens (Row 47): ['guess']\n","Stopwords Removed (Row 47): ['what']\n","Stopwords were removed for Row 47 in file Ses05M_impro07.csv.\n","Original Tokens (Row 48): ['i', 'got', 'it', 'i', 'got', 'accepted', 'to', 'u.s.c']\n","Updated Tokens (Row 48): ['got', 'got', 'accepted', 'u.s.c']\n","Stopwords Removed (Row 48): ['i', 'it', 'i', 'to']\n","Stopwords were removed for Row 48 in file Ses05M_impro07.csv.\n","Original Tokens (Row 49): ['yes', 'i', 'just', 'found', 'out', 'today', 'i', 'just', 'got', 'the', 'letter']\n","Updated Tokens (Row 49): ['yes', 'found', 'today', 'got', 'letter']\n","Stopwords Removed (Row 49): ['i', 'just', 'out', 'i', 'just', 'the']\n","Stopwords were removed for Row 49 in file Ses05M_impro07.csv.\n","Original Tokens (Row 50): ['i', 'know', 'i', 'know', 'i', 'so', 'excited']\n","Updated Tokens (Row 50): ['know', 'know', 'excited']\n","Stopwords Removed (Row 50): ['i', 'i', 'i', 'so']\n","Stopwords were removed for Row 50 in file Ses05M_impro07.csv.\n","Original Tokens (Row 51): ['oh', 'theater', 'yeah', 'yeah']\n","Updated Tokens (Row 51): ['oh', 'theater', 'yeah', 'yeah']\n","Stopwords Removed (Row 51): []\n","No stopwords removed for Row 51 in file Ses05M_impro07.csv.\n","Original Tokens (Row 52): ['yes']\n","Updated Tokens (Row 52): ['yes']\n","Stopwords Removed (Row 52): []\n","No stopwords removed for Row 52 in file Ses05M_impro07.csv.\n","Original Tokens (Row 53): ['oh']\n","Updated Tokens (Row 53): ['oh']\n","Stopwords Removed (Row 53): []\n","No stopwords removed for Row 53 in file Ses05M_impro07.csv.\n","Original Tokens (Row 54): ['it', 'is', 'exactly', 'what', 'i', 'wanted']\n","Updated Tokens (Row 54): ['exactly', 'wanted']\n","Stopwords Removed (Row 54): ['it', 'is', 'what', 'i']\n","Stopwords were removed for Row 54 in file Ses05M_impro07.csv.\n","Original Tokens (Row 55): ['oh', 'of', 'course', 'no', 'i', 'did', 'not', 'know', 'it', 'was', 'that', 'tough', 'i', 'just', 'happy', 'that', 'i', 'made', 'it']\n","Updated Tokens (Row 55): ['oh', 'course', 'know', 'tough', 'happy', 'made']\n","Stopwords Removed (Row 55): ['of', 'no', 'i', 'did', 'not', 'it', 'was', 'that', 'i', 'just', 'that', 'i', 'it']\n","Stopwords were removed for Row 55 in file Ses05M_impro07.csv.\n","Original Tokens (Row 56): ['i', 'worked', 'really', 'hard', 'i', 'say', 'i', 'worked', 'really', 'hard', 'you', 'know', 'i', 'i', 'not', 'bragging', 'or', 'anything', 'like', 'that', 'but']\n","Updated Tokens (Row 56): ['worked', 'really', 'hard', 'say', 'worked', 'really', 'hard', 'know', 'bragging', 'anything', 'like']\n","Stopwords Removed (Row 56): ['i', 'i', 'i', 'you', 'i', 'i', 'not', 'or', 'that', 'but']\n","Stopwords were removed for Row 56 in file Ses05M_impro07.csv.\n","Original Tokens (Row 57): ['no', 'no', 'i', 'really', 'looking', 'forward', 'to', 'it', 'you', 'know', 'how', 'long', 'i', 'have', 'been', 'talking', 'about', 'this', 'forever', 'right', 'right']\n","Updated Tokens (Row 57): ['really', 'looking', 'forward', 'know', 'long', 'talking', 'forever', 'right', 'right']\n","Stopwords Removed (Row 57): ['no', 'no', 'i', 'to', 'it', 'you', 'how', 'i', 'have', 'been', 'about', 'this']\n","Stopwords were removed for Row 57 in file Ses05M_impro07.csv.\n","Original Tokens (Row 58): ['finally', 'i', 'so', 'excited', 'we', 'gon', 'na', 'well', 'i', 'be', 'here', 'we', 'still', 'gon', 'na', 'be', 'able', 'to', 'see', 'each', 'other']\n","Updated Tokens (Row 58): ['finally', 'excited', 'gon', 'na', 'well', 'still', 'gon', 'na', 'able', 'see']\n","Stopwords Removed (Row 58): ['i', 'so', 'we', 'i', 'be', 'here', 'we', 'be', 'to', 'each', 'other']\n","Stopwords were removed for Row 58 in file Ses05M_impro07.csv.\n","Original Tokens (Row 59): ['we', 'gon', 'na', 'hang', 'out', 'right']\n","Updated Tokens (Row 59): ['gon', 'na', 'hang', 'right']\n","Stopwords Removed (Row 59): ['we', 'out']\n","Stopwords were removed for Row 59 in file Ses05M_impro07.csv.\n","Original Tokens (Row 60): ['what', 'are', 'you', 'wait', 'what', 'are', 'you', 'doing']\n","Updated Tokens (Row 60): ['wait']\n","Stopwords Removed (Row 60): ['what', 'are', 'you', 'what', 'are', 'you', 'doing']\n","Stopwords were removed for Row 60 in file Ses05M_impro07.csv.\n","Original Tokens (Row 61): ['perfect', 'oh', 'my', 'god', 'are', 'you', 'staying', 'are', 'you', 'going', 'to', 'live', 'on', 'campus']\n","Updated Tokens (Row 61): ['perfect', 'oh', 'god', 'staying', 'going', 'live', 'campus']\n","Stopwords Removed (Row 61): ['my', 'are', 'you', 'are', 'you', 'to', 'on']\n","Stopwords were removed for Row 61 in file Ses05M_impro07.csv.\n","Original Tokens (Row 62): ['we', 'are', 'gon', 'na', 'party', 'all', 'the', 'time']\n","Updated Tokens (Row 62): ['gon', 'na', 'party', 'time']\n","Stopwords Removed (Row 62): ['we', 'are', 'all', 'the']\n","Stopwords were removed for Row 62 in file Ses05M_impro07.csv.\n","Original Tokens (Row 63): ['we', 'are', 'gon', 'na', 'have', 'a', 'great', 'time']\n","Updated Tokens (Row 63): ['gon', 'na', 'great', 'time']\n","Stopwords Removed (Row 63): ['we', 'are', 'have', 'a']\n","Stopwords were removed for Row 63 in file Ses05M_impro07.csv.\n","Original Tokens (Row 64): ['garbage', 'i', 'going', 'to', 'live', 'on', 'campus', 'i', 'mean', 'well', 'around', 'campus', 'anyway', 'yeah', 'housing', 'around', 'campus']\n","Updated Tokens (Row 64): ['garbage', 'going', 'live', 'campus', 'mean', 'well', 'around', 'campus', 'anyway', 'yeah', 'housing', 'around', 'campus']\n","Stopwords Removed (Row 64): ['i', 'to', 'on', 'i']\n","Stopwords were removed for Row 64 in file Ses05M_impro07.csv.\n","Original Tokens (Row 65): ['i', 'just', 'want', 'to', 'be', 'really', 'close', 'to', 'things', 'you', 'know', 'i', 'know', 'it', 'is', 'not', 'exactly', 'the', 'best', 'neighborhood', 'in', 'the', 'entire', 'world', 'but', 'uh']\n","Updated Tokens (Row 65): ['want', 'really', 'close', 'things', 'know', 'know', 'exactly', 'best', 'neighborhood', 'entire', 'world', 'uh']\n","Stopwords Removed (Row 65): ['i', 'just', 'to', 'be', 'to', 'you', 'i', 'it', 'is', 'not', 'the', 'in', 'the', 'but']\n","Stopwords were removed for Row 65 in file Ses05M_impro07.csv.\n","Original Tokens (Row 66): ['i', 'do', 'not', 'you', 'know', 'i', 'feel', 'the', 'same', 'way', 'you', 'know', 'what', 'i', 'mean', 'and', 'everybody', 'says', 'a', 'lot', 'of', 'other', 'crap', 'you', 'know', 'they', 'do', 'not', 'know', 'what', 'they', 'are', 'talking', 'about', 'anyway']\n","Updated Tokens (Row 66): ['know', 'feel', 'way', 'know', 'mean', 'everybody', 'says', 'lot', 'crap', 'know', 'know', 'talking', 'anyway']\n","Stopwords Removed (Row 66): ['i', 'do', 'not', 'you', 'i', 'the', 'same', 'you', 'what', 'i', 'and', 'a', 'of', 'other', 'you', 'they', 'do', 'not', 'what', 'they', 'are', 'about']\n","Stopwords were removed for Row 66 in file Ses05M_impro07.csv.\n","Original Tokens (Row 67): ['they', 'do', 'not', 'live', 'here', 'they', 'do', 'not', 'know', 'right']\n","Updated Tokens (Row 67): ['live', 'know', 'right']\n","Stopwords Removed (Row 67): ['they', 'do', 'not', 'here', 'they', 'do', 'not']\n","Stopwords were removed for Row 67 in file Ses05M_impro07.csv.\n","Original Tokens (Row 68): ['yeah']\n","Updated Tokens (Row 68): ['yeah']\n","Stopwords Removed (Row 68): []\n","No stopwords removed for Row 68 in file Ses05M_impro07.csv.\n","Original Tokens (Row 69): ['exactly', 'you', 'make', 'it', 'what', 'you', 'make', 'it', 'you', 'know', 'right', 'and', 'i', 'gon', 'na', 'make', 'it', 'so', 'freaking', 'awesome']\n","Updated Tokens (Row 69): ['exactly', 'make', 'make', 'know', 'right', 'gon', 'na', 'make', 'freaking', 'awesome']\n","Stopwords Removed (Row 69): ['you', 'it', 'what', 'you', 'it', 'you', 'and', 'i', 'it', 'so']\n","Stopwords were removed for Row 69 in file Ses05M_impro07.csv.\n","Original Tokens (Row 70): ['yeah']\n","Updated Tokens (Row 70): ['yeah']\n","Stopwords Removed (Row 70): []\n","No stopwords removed for Row 70 in file Ses05M_impro07.csv.\n","Original Tokens (Row 71): ['well', 'i', 'do', 'not', 'know', 'i', 'got', 'to', 'go', 'look', 'for', 'a', 'place']\n","Updated Tokens (Row 71): ['well', 'know', 'got', 'go', 'look', 'place']\n","Stopwords Removed (Row 71): ['i', 'do', 'not', 'i', 'to', 'for', 'a']\n","Stopwords were removed for Row 71 in file Ses05M_impro07.csv.\n","Original Tokens (Row 72): ['yeah', 'yeah', 'i', 'do', 'not', 'i', 'do', 'not', 'know', 'do', 'you', 'have', 'any', 'suggestions']\n","Updated Tokens (Row 72): ['yeah', 'yeah', 'know', 'suggestions']\n","Stopwords Removed (Row 72): ['i', 'do', 'not', 'i', 'do', 'not', 'do', 'you', 'have', 'any']\n","Stopwords were removed for Row 72 in file Ses05M_impro07.csv.\n","Original Tokens (Row 73): ['you', 'know', 'the', 'area', 'better', 'than', 'i', 'do']\n","Updated Tokens (Row 73): ['know', 'area', 'better']\n","Stopwords Removed (Row 73): ['you', 'the', 'than', 'i', 'do']\n","Stopwords were removed for Row 73 in file Ses05M_impro07.csv.\n","Original Tokens (Row 74): ['yeah', 'yeah']\n","Updated Tokens (Row 74): ['yeah', 'yeah']\n","Stopwords Removed (Row 74): []\n","No stopwords removed for Row 74 in file Ses05M_impro07.csv.\n","Original Tokens (Row 75): ['not', 'a', 'lot', 'i', 'mean', 'i', 'would', 'not', 'want', 'to', 'live', 'with', 'more', 'than', 'three', 'other', 'people', 'so', 'like', 'four', 'of', 'us', 'total', 'right']\n","Updated Tokens (Row 75): ['lot', 'mean', 'would', 'want', 'live', 'three', 'people', 'like', 'four', 'us', 'total', 'right']\n","Stopwords Removed (Row 75): ['not', 'a', 'i', 'i', 'not', 'to', 'with', 'more', 'than', 'other', 'so', 'of']\n","Stopwords were removed for Row 75 in file Ses05M_impro07.csv.\n","Original Tokens (Row 76): ['i', 'do', 'not', 'care', 'i', 'do', 'not', 'care']\n","Updated Tokens (Row 76): ['care', 'care']\n","Stopwords Removed (Row 76): ['i', 'do', 'not', 'i', 'do', 'not']\n","Stopwords were removed for Row 76 in file Ses05M_impro07.csv.\n","Original Tokens (Row 77): ['yeah']\n","Updated Tokens (Row 77): ['yeah']\n","Stopwords Removed (Row 77): []\n","No stopwords removed for Row 77 in file Ses05M_impro07.csv.\n","Original Tokens (Row 78): ['that', 'would', 'be', 'perfect']\n","Updated Tokens (Row 78): ['would', 'perfect']\n","Stopwords Removed (Row 78): ['that', 'be']\n","Stopwords were removed for Row 78 in file Ses05M_impro07.csv.\n","Original Tokens (Row 79): ['really']\n","Updated Tokens (Row 79): ['really']\n","Stopwords Removed (Row 79): []\n","No stopwords removed for Row 79 in file Ses05M_impro07.csv.\n","Original Tokens (Row 80): ['really']\n","Updated Tokens (Row 80): ['really']\n","Stopwords Removed (Row 80): []\n","No stopwords removed for Row 80 in file Ses05M_impro07.csv.\n","Original Tokens (Row 81): ['cheap', 'is', 'exactly', 'what', 'i', 'need', 'because', 'i', 'have', 'no', 'money', 'at', 'all']\n","Updated Tokens (Row 81): ['cheap', 'exactly', 'need', 'money']\n","Stopwords Removed (Row 81): ['is', 'what', 'i', 'because', 'i', 'have', 'no', 'at', 'all']\n","Stopwords were removed for Row 81 in file Ses05M_impro07.csv.\n","Original Tokens (Row 82): ['but', 'uh']\n","Updated Tokens (Row 82): ['uh']\n","Stopwords Removed (Row 82): ['but']\n","Stopwords were removed for Row 82 in file Ses05M_impro07.csv.\n","Original Tokens (Row 83): ['loans', 'scholarships', 'i', 'got', 'a', 'lot', 'of', 'scholarships', 'yeah', 'yeah', \"i'm\", 'i', 'half', 'native', 'american', 'so', 'i', 'get', 'all', 'those', 'scholarships', 'too', 'yeah']\n","Updated Tokens (Row 83): ['loans', 'scholarships', 'got', 'lot', 'scholarships', 'yeah', 'yeah', \"i'm\", 'half', 'native', 'american', 'get', 'scholarships', 'yeah']\n","Stopwords Removed (Row 83): ['i', 'a', 'of', 'i', 'so', 'i', 'all', 'those', 'too']\n","Stopwords were removed for Row 83 in file Ses05M_impro07.csv.\n","Original Tokens (Row 84): ['so', 'it', 'comes', 'indian', 'like', 'and', 'you', 'know', 'i', 'kind', 'of', 'smart', 'so']\n","Updated Tokens (Row 84): ['comes', 'indian', 'like', 'know', 'kind', 'smart']\n","Stopwords Removed (Row 84): ['so', 'it', 'and', 'you', 'i', 'of', 'so']\n","Stopwords were removed for Row 84 in file Ses05M_impro07.csv.\n","Original Tokens (Row 85): ['that', 'helps', 'right', 'get', 'some', 'academic', 'scholarships', 'and', 'uh']\n","Updated Tokens (Row 85): ['helps', 'right', 'get', 'academic', 'scholarships', 'uh']\n","Stopwords Removed (Row 85): ['that', 'some', 'and']\n","Stopwords were removed for Row 85 in file Ses05M_impro07.csv.\n","Original Tokens (Row 86): ['and', 'yeah', 'well', 'i', 'mean', 'basically', 'i', 'just', 'applied', 'for', 'any', 'and', 'every', 'possible', 'scholarship', 'and', 'grant', 'that', 'could', 'come', 'by', 'so', 'i', 'can', 'go']\n","Updated Tokens (Row 86): ['yeah', 'well', 'mean', 'basically', 'applied', 'every', 'possible', 'scholarship', 'grant', 'could', 'come', 'go']\n","Stopwords Removed (Row 86): ['and', 'i', 'i', 'just', 'for', 'any', 'and', 'and', 'that', 'by', 'so', 'i', 'can']\n","Stopwords were removed for Row 86 in file Ses05M_impro07.csv.\n","Original Tokens (Row 87): ['yeah', 'yeah', 'yeah', 'and', 'it', 'is', 'gon', 'na', 'work', 'out', 'i', 'gon', 'na', 'be', 'able', 'to', 'pay', 'for', 'it', 'i', 'gon', 'na', 'go', 'i', 'mean', 'i', 'have', 'a', 'little', 'debt', 'in', 'the', 'end', 'but', 'i', 'do', 'not', 'care']\n","Updated Tokens (Row 87): ['yeah', 'yeah', 'yeah', 'gon', 'na', 'work', 'gon', 'na', 'able', 'pay', 'gon', 'na', 'go', 'mean', 'little', 'debt', 'end', 'care']\n","Stopwords Removed (Row 87): ['and', 'it', 'is', 'out', 'i', 'be', 'to', 'for', 'it', 'i', 'i', 'i', 'have', 'a', 'in', 'the', 'but', 'i', 'do', 'not']\n","Stopwords were removed for Row 87 in file Ses05M_impro07.csv.\n","Original Tokens (Row 88): ['it', 'is', 'just', 'you', 'know', 'a', 'dream', 'come', 'true', 'how', 'could', 'you', 'not', 'be', 'excited', 'about', 'a', 'dream', 'come', 'true']\n","Updated Tokens (Row 88): ['know', 'dream', 'come', 'true', 'could', 'excited', 'dream', 'come', 'true']\n","Stopwords Removed (Row 88): ['it', 'is', 'just', 'you', 'a', 'how', 'you', 'not', 'be', 'about', 'a']\n","Stopwords were removed for Row 88 in file Ses05M_impro07.csv.\n","Original Tokens (Row 89): ['oh', 'i', 'know', 'i', 'know']\n","Updated Tokens (Row 89): ['oh', 'know', 'know']\n","Stopwords Removed (Row 89): ['i', 'i']\n","Stopwords were removed for Row 89 in file Ses05M_impro07.csv.\n","Original Tokens (Row 90): ['but', 'i', 'so', 'looking', 'forward', 'to', 'being', 'so', 'busy', 'you', 'know', 'what', 'i', 'mean', 'it', 'is', 'the', 'kind', 'of', 'busy', 'you', 'have', 'got', 'to', 'love', 'right']\n","Updated Tokens (Row 90): ['looking', 'forward', 'busy', 'know', 'mean', 'kind', 'busy', 'got', 'love', 'right']\n","Stopwords Removed (Row 90): ['but', 'i', 'so', 'to', 'being', 'so', 'you', 'what', 'i', 'it', 'is', 'the', 'of', 'you', 'have', 'to']\n","Stopwords were removed for Row 90 in file Ses05M_impro07.csv.\n","Original Tokens (Row 91): ['because', 'you', 'doing', 'something', 'you', 'love', 'that', 'is', 'the', 'kind', 'of', 'busy', 'you', 'want', 'i', 'want', 'to', 'be', 'able', 'to', 'do', 'that', 'for', 'the', 'rest', 'of', 'my', 'life', 'be', 'that', 'kind', 'of', 'busy']\n","Updated Tokens (Row 91): ['something', 'love', 'kind', 'busy', 'want', 'want', 'able', 'rest', 'life', 'kind', 'busy']\n","Stopwords Removed (Row 91): ['because', 'you', 'doing', 'you', 'that', 'is', 'the', 'of', 'you', 'i', 'to', 'be', 'to', 'do', 'that', 'for', 'the', 'of', 'my', 'be', 'that', 'of']\n","Stopwords were removed for Row 91 in file Ses05M_impro07.csv.\n","Original Tokens (Row 92): ['i', 'had', 'to', 'tell', 'you', 'right', 'away', 'i', 'knew', 'you', 'be', 'excited']\n","Updated Tokens (Row 92): ['tell', 'right', 'away', 'knew', 'excited']\n","Stopwords Removed (Row 92): ['i', 'had', 'to', 'you', 'i', 'you', 'be']\n","Stopwords were removed for Row 92 in file Ses05M_impro07.csv.\n","Original Tokens (Row 93): ['we', 'have', 'fun']\n","Updated Tokens (Row 93): ['fun']\n","Stopwords Removed (Row 93): ['we', 'have']\n","Stopwords were removed for Row 93 in file Ses05M_impro07.csv.\n","Original Tokens (Row 94): ['great', 'okay']\n","Updated Tokens (Row 94): ['great', 'okay']\n","Stopwords Removed (Row 94): []\n","No stopwords removed for Row 94 in file Ses05M_impro07.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro07.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro07.csv\n","\n","Processing File: Ses05M_impro08.csv\n","Original Tokens (Row 0): ['hi', 'i', 'need', 'i', 'need', 'some', 'help', 'i', 'been', 'transferred', 'to', 'like', 'eight', 'different', 'departments', 'and', 'i', 'told', 'my', 'problem', 'to', 'every', 'single', 'department', 'and', 'then', 'they', 'just', 'send', 'me', 'to', 'another', 'one', 'and', 'say', 'they', 'are', 'going', 'to', 'send', 'all', 'my', 'information', 'so', 'i', 'will', 'not', 'have', 'to', 'repeat', 'it', 'and', 'then', 'that', 'person', 'does', 'not', 'know', 'what', 'is', 'going', 'on', 'and', 'i', 'restated', 'my', 'story', 'about', 'eight', 'different', 'times', 'and', 'i', 'just', 'want', 'somebody', 'to', 'help', 'me', 'get', 'my', 'connection', 'back', 'because', 'this', 'happens', 'every', 'two', 'weeks', 'and', 'i', 'want', 'to', 'know', 'what', 'to', 'do', 'to', 'stop', 'it', 'from', 'happening', 'again']\n","Updated Tokens (Row 0): ['hi', 'need', 'need', 'help', 'transferred', 'like', 'eight', 'different', 'departments', 'told', 'problem', 'every', 'single', 'department', 'send', 'another', 'one', 'say', 'going', 'send', 'information', 'repeat', 'person', 'know', 'going', 'restated', 'story', 'eight', 'different', 'times', 'want', 'somebody', 'help', 'get', 'connection', 'back', 'happens', 'every', 'two', 'weeks', 'want', 'know', 'stop', 'happening']\n","Stopwords Removed (Row 0): ['i', 'i', 'some', 'i', 'been', 'to', 'and', 'i', 'my', 'to', 'and', 'then', 'they', 'just', 'me', 'to', 'and', 'they', 'are', 'to', 'all', 'my', 'so', 'i', 'will', 'not', 'have', 'to', 'it', 'and', 'then', 'that', 'does', 'not', 'what', 'is', 'on', 'and', 'i', 'my', 'about', 'and', 'i', 'just', 'to', 'me', 'my', 'because', 'this', 'and', 'i', 'to', 'what', 'to', 'do', 'to', 'it', 'from', 'again']\n","Stopwords were removed for Row 0 in file Ses05M_impro08.csv.\n","Original Tokens (Row 1): ['yeah', 'that', 'my', 'service', 'just', 'goes', 'out']\n","Updated Tokens (Row 1): ['yeah', 'service', 'goes']\n","Stopwords Removed (Row 1): ['that', 'my', 'just', 'out']\n","Stopwords were removed for Row 1 in file Ses05M_impro08.csv.\n","Original Tokens (Row 2): ['yeah']\n","Updated Tokens (Row 2): ['yeah']\n","Stopwords Removed (Row 2): []\n","No stopwords removed for Row 2 in file Ses05M_impro08.csv.\n","Original Tokens (Row 3): ['and', 'i', 'reset', 'the', 'ip', 'address', 'i', 'will', 'do', 'like', 'you', 'know', 'direct', 'connect', 'the', 'modem', 'to', 'my', 'computer', 'and', 'then', 'reset', 'everything', 'and', 'then', 'put', 'the', 'router', 'back', 'in', 'and']\n","Updated Tokens (Row 3): ['reset', 'ip', 'address', 'like', 'know', 'direct', 'connect', 'modem', 'computer', 'reset', 'everything', 'put', 'router', 'back']\n","Stopwords Removed (Row 3): ['and', 'i', 'the', 'i', 'will', 'do', 'you', 'the', 'to', 'my', 'and', 'then', 'and', 'then', 'the', 'in', 'and']\n","Stopwords were removed for Row 3 in file Ses05M_impro08.csv.\n","Original Tokens (Row 4): ['is', 'not', 'it', 'it', 'it', 'will', 'work', 'again', 'for', 'like', 'a', 'week', 'and', 'then', 'it', 'goes', 'out', 'again']\n","Updated Tokens (Row 4): ['work', 'like', 'week', 'goes']\n","Stopwords Removed (Row 4): ['is', 'not', 'it', 'it', 'it', 'will', 'again', 'for', 'a', 'and', 'then', 'it', 'out', 'again']\n","Stopwords were removed for Row 4 in file Ses05M_impro08.csv.\n","Original Tokens (Row 5): ['uh', 'yeah', 'we', 'have', 'pinned', 'it', 'a', 'couple', 'of', 'times']\n","Updated Tokens (Row 5): ['uh', 'yeah', 'pinned', 'couple', 'times']\n","Stopwords Removed (Row 5): ['we', 'have', 'it', 'a', 'of']\n","Stopwords were removed for Row 5 in file Ses05M_impro08.csv.\n","Original Tokens (Row 6): ['pretty', 'much', 'yeah', 'i', 'do', 'not', 'know', 'if', 'it', 'is', 'like', 'bad', 'phone', 'lines', 'or', 'something']\n","Updated Tokens (Row 6): ['pretty', 'much', 'yeah', 'know', 'like', 'bad', 'phone', 'lines', 'something']\n","Stopwords Removed (Row 6): ['i', 'do', 'not', 'if', 'it', 'is', 'or']\n","Stopwords were removed for Row 6 in file Ses05M_impro08.csv.\n","Original Tokens (Row 7): ['hmm', 'mmm']\n","Updated Tokens (Row 7): ['hmm', 'mmm']\n","Stopwords Removed (Row 7): []\n","No stopwords removed for Row 7 in file Ses05M_impro08.csv.\n","Original Tokens (Row 8): ['yeah']\n","Updated Tokens (Row 8): ['yeah']\n","Stopwords Removed (Row 8): []\n","No stopwords removed for Row 8 in file Ses05M_impro08.csv.\n","Original Tokens (Row 9): ['it', 'goes', 'it', 'goes', 'like', 'through', 'doorways', 'but', 'it', 'goes', 'a', 'long', 'distance']\n","Updated Tokens (Row 9): ['goes', 'goes', 'like', 'doorways', 'goes', 'long', 'distance']\n","Stopwords Removed (Row 9): ['it', 'it', 'through', 'but', 'it', 'a']\n","Stopwords were removed for Row 9 in file Ses05M_impro08.csv.\n","Original Tokens (Row 10): ['oh', 'really']\n","Updated Tokens (Row 10): ['oh', 'really']\n","Stopwords Removed (Row 10): []\n","No stopwords removed for Row 10 in file Ses05M_impro08.csv.\n","Original Tokens (Row 11): ['well', 'i', 'can', 'check', 'that', 'is', 'there', 'anything', 'else', 'we', 'can', 'do', 'too', 'like', 'i', 'go', 'through', 'and', 'check', 'the', 'line', 'throughout', 'the', 'house', 'but']\n","Updated Tokens (Row 11): ['well', 'check', 'anything', 'else', 'like', 'go', 'check', 'line', 'throughout', 'house']\n","Stopwords Removed (Row 11): ['i', 'can', 'that', 'is', 'there', 'we', 'can', 'do', 'too', 'i', 'through', 'and', 'the', 'the', 'but']\n","Stopwords were removed for Row 11 in file Ses05M_impro08.csv.\n","Original Tokens (Row 12): ['uh', 'huh']\n","Updated Tokens (Row 12): ['uh', 'huh']\n","Stopwords Removed (Row 12): []\n","No stopwords removed for Row 12 in file Ses05M_impro08.csv.\n","Original Tokens (Row 13): ['all', 'right']\n","Updated Tokens (Row 13): ['right']\n","Stopwords Removed (Row 13): ['all']\n","Stopwords were removed for Row 13 in file Ses05M_impro08.csv.\n","Original Tokens (Row 14): ['yeah', 'i', 'see', 'that']\n","Updated Tokens (Row 14): ['yeah', 'see']\n","Stopwords Removed (Row 14): ['i', 'that']\n","Stopwords were removed for Row 14 in file Ses05M_impro08.csv.\n","Original Tokens (Row 15): ['okay']\n","Updated Tokens (Row 15): ['okay']\n","Stopwords Removed (Row 15): []\n","No stopwords removed for Row 15 in file Ses05M_impro08.csv.\n","Original Tokens (Row 16): ['okay']\n","Updated Tokens (Row 16): ['okay']\n","Stopwords Removed (Row 16): []\n","No stopwords removed for Row 16 in file Ses05M_impro08.csv.\n","Original Tokens (Row 17): ['uh', 'it', 'it', 'is', 'like', 'a', 'bunch', 'of', 'different', 'letter', 'and', 'numbers', 'and', 'stuff']\n","Updated Tokens (Row 17): ['uh', 'like', 'bunch', 'different', 'letter', 'numbers', 'stuff']\n","Stopwords Removed (Row 17): ['it', 'it', 'is', 'a', 'of', 'and', 'and']\n","Stopwords were removed for Row 17 in file Ses05M_impro08.csv.\n","Original Tokens (Row 18): ['uh', 'huh', 'okay']\n","Updated Tokens (Row 18): ['uh', 'huh', 'okay']\n","Stopwords Removed (Row 18): []\n","No stopwords removed for Row 18 in file Ses05M_impro08.csv.\n","Original Tokens (Row 19): ['uh', 'yeah', 'looks', 'no', 'no', 'it', 'is', 'set', 'to', 'zeros']\n","Updated Tokens (Row 19): ['uh', 'yeah', 'looks', 'set', 'zeros']\n","Stopwords Removed (Row 19): ['no', 'no', 'it', 'is', 'to']\n","Stopwords were removed for Row 19 in file Ses05M_impro08.csv.\n","Original Tokens (Row 20): ['what', 'happening', 'so', 'if', 'we', 'reset', 'this', 'how', 'will', 'i', 'know', 'it', 'is', 'not', 'going', 'to', 'happen', 'again', 'every', 'other', 'week']\n","Updated Tokens (Row 20): ['happening', 'reset', 'know', 'going', 'happen', 'every', 'week']\n","Stopwords Removed (Row 20): ['what', 'so', 'if', 'we', 'this', 'how', 'will', 'i', 'it', 'is', 'not', 'to', 'again', 'other']\n","Stopwords were removed for Row 20 in file Ses05M_impro08.csv.\n","Original Tokens (Row 21): ['wow', 'that', 'would', 'be', 'amazing', 'really']\n","Updated Tokens (Row 21): ['wow', 'would', 'amazing', 'really']\n","Stopwords Removed (Row 21): ['that', 'be']\n","Stopwords were removed for Row 21 in file Ses05M_impro08.csv.\n","Original Tokens (Row 22): ['oh', 'my', 'god', 'i', 'can', 'not', 'even', 'tell', 'you', 'how', 'much', 'of', 'a', 'relief', 'that', 'is', 'i', 'literally', 'call', 'and', 'talk', 'to', 'five', 'different', 'people', 'like', 'last', 'week', 'it', 'went', 'off', 'and', 'i', 'spent', 'an', 'hour', 'and', 'a', 'half', 'on', 'the', 'phone', 'with', 'different', 'people', 'and', 'i', 'been', 'doing', 'that', 'like', 'every', 'every', 'other', 'week', 'for', 'months', 'now']\n","Updated Tokens (Row 22): ['oh', 'god', 'even', 'tell', 'much', 'relief', 'literally', 'call', 'talk', 'five', 'different', 'people', 'like', 'last', 'week', 'went', 'spent', 'hour', 'half', 'phone', 'different', 'people', 'like', 'every', 'every', 'week', 'months']\n","Stopwords Removed (Row 22): ['my', 'i', 'can', 'not', 'you', 'how', 'of', 'a', 'that', 'is', 'i', 'and', 'to', 'it', 'off', 'and', 'i', 'an', 'and', 'a', 'on', 'the', 'with', 'and', 'i', 'been', 'doing', 'that', 'other', 'for', 'now']\n","Stopwords were removed for Row 22 in file Ses05M_impro08.csv.\n","Original Tokens (Row 23): ['it', 'is', 'so', 'frustrating']\n","Updated Tokens (Row 23): ['frustrating']\n","Stopwords Removed (Row 23): ['it', 'is', 'so']\n","Stopwords were removed for Row 23 in file Ses05M_impro08.csv.\n","Original Tokens (Row 24): ['thank', 'you', 'so', 'much']\n","Updated Tokens (Row 24): ['thank', 'much']\n","Stopwords Removed (Row 24): ['you', 'so']\n","Stopwords were removed for Row 24 in file Ses05M_impro08.csv.\n","Original Tokens (Row 25): ['yeah', 'accountability', 'it', 'is', 'awesome']\n","Updated Tokens (Row 25): ['yeah', 'accountability', 'awesome']\n","Stopwords Removed (Row 25): ['it', 'is']\n","Stopwords were removed for Row 25 in file Ses05M_impro08.csv.\n","Original Tokens (Row 26): ['wow', 'you', 'know', 'i', 'was', 'thinking', 'about', 'changing', 'internet', 'providers', 'but', 'but', 'that', 'that', 'really', 'is', 'enough', 'to', 'change', 'my', 'mind']\n","Updated Tokens (Row 26): ['wow', 'know', 'thinking', 'changing', 'internet', 'providers', 'really', 'enough', 'change', 'mind']\n","Stopwords Removed (Row 26): ['you', 'i', 'was', 'about', 'but', 'but', 'that', 'that', 'is', 'to', 'my']\n","Stopwords were removed for Row 26 in file Ses05M_impro08.csv.\n","Original Tokens (Row 27): ['no', 'i', 'just', 'gon', 'na', 'go', 'have', 'a', 'fantastic', 'day', 'now']\n","Updated Tokens (Row 27): ['gon', 'na', 'go', 'fantastic', 'day']\n","Stopwords Removed (Row 27): ['no', 'i', 'just', 'have', 'a', 'now']\n","Stopwords were removed for Row 27 in file Ses05M_impro08.csv.\n","Original Tokens (Row 28): ['okay', 'thanks']\n","Updated Tokens (Row 28): ['okay', 'thanks']\n","Stopwords Removed (Row 28): []\n","No stopwords removed for Row 28 in file Ses05M_impro08.csv.\n","Original Tokens (Row 29): ['d.s.l', 'extreme', 'can', 'i', 'help', 'you']\n","Updated Tokens (Row 29): ['d.s.l', 'extreme', 'help']\n","Stopwords Removed (Row 29): ['can', 'i', 'you']\n","Stopwords were removed for Row 29 in file Ses05M_impro08.csv.\n","Original Tokens (Row 30): ['this', 'happens', 'every', 'two', 'weeks']\n","Updated Tokens (Row 30): ['happens', 'every', 'two', 'weeks']\n","Stopwords Removed (Row 30): ['this']\n","Stopwords were removed for Row 30 in file Ses05M_impro08.csv.\n","Original Tokens (Row 31): ['you', 'have', 'lost', 'your', 'connection']\n","Updated Tokens (Row 31): ['lost', 'connection']\n","Stopwords Removed (Row 31): ['you', 'have', 'your']\n","Stopwords were removed for Row 31 in file Ses05M_impro08.csv.\n","Original Tokens (Row 32): ['okay']\n","Updated Tokens (Row 32): ['okay']\n","Stopwords Removed (Row 32): []\n","No stopwords removed for Row 32 in file Ses05M_impro08.csv.\n","Original Tokens (Row 33): ['hmm', 'mmm']\n","Updated Tokens (Row 33): ['hmm', 'mmm']\n","Stopwords Removed (Row 33): []\n","No stopwords removed for Row 33 in file Ses05M_impro08.csv.\n","Original Tokens (Row 34): ['has', 'somebody', 'tried', 'to', 'pin', 'your', 'site']\n","Updated Tokens (Row 34): ['somebody', 'tried', 'pin', 'site']\n","Stopwords Removed (Row 34): ['has', 'to', 'your']\n","Stopwords were removed for Row 34 in file Ses05M_impro08.csv.\n","Original Tokens (Row 35): ['okay', 'um', 'well', 'i', 'do', 'not', 'know', 'and', 'it', 'consistently', 'happens', 'every', 'two', 'weeks']\n","Updated Tokens (Row 35): ['okay', 'um', 'well', 'know', 'consistently', 'happens', 'every', 'two', 'weeks']\n","Stopwords Removed (Row 35): ['i', 'do', 'not', 'and', 'it']\n","Stopwords were removed for Row 35 in file Ses05M_impro08.csv.\n","Original Tokens (Row 36): ['well', 'you', 'know', 'what', 'does', 'your', 'd.s.l', 'cable', 'you', 'have', 'd.s.l.', 'right']\n","Updated Tokens (Row 36): ['well', 'know', 'd.s.l', 'cable', 'd.s.l.', 'right']\n","Stopwords Removed (Row 36): ['you', 'what', 'does', 'your', 'you', 'have']\n","Stopwords were removed for Row 36 in file Ses05M_impro08.csv.\n","Original Tokens (Row 37): ['okay', 'does', 'your', 'd.s.l', 'cable', 'you', 'know', 'travel', 'a', 'long', 'distance', 'by', 'any', 'chance', 'does', 'it', 'go', 'through', 'any', 'windows', 'i', 'mean', 'is', 'it']\n","Updated Tokens (Row 37): ['okay', 'd.s.l', 'cable', 'know', 'travel', 'long', 'distance', 'chance', 'go', 'windows', 'mean']\n","Stopwords Removed (Row 37): ['does', 'your', 'you', 'a', 'by', 'any', 'does', 'it', 'through', 'any', 'i', 'is', 'it']\n","Stopwords were removed for Row 37 in file Ses05M_impro08.csv.\n","Original Tokens (Row 38): ['okay', 'is', 'it', 'being', 'is', 'it', 'being', 'compressed', 'between', 'anything', 'by', 'any', 'chance', 'because', 'sometimes', 'your', 'connection', 'can', 'be', 'you', 'know', 'disrupted', 'by', 'you', 'know', 'the', 'cable', 'being', 'squished']\n","Updated Tokens (Row 38): ['okay', 'compressed', 'anything', 'chance', 'sometimes', 'connection', 'know', 'disrupted', 'know', 'cable', 'squished']\n","Stopwords Removed (Row 38): ['is', 'it', 'being', 'is', 'it', 'being', 'between', 'by', 'any', 'because', 'your', 'can', 'be', 'you', 'by', 'you', 'the', 'being']\n","Stopwords were removed for Row 38 in file Ses05M_impro08.csv.\n","Original Tokens (Row 39): ['yeah', 'that', 'can', 'be', 'that', 'can', 'create', 'a', 'bad', 'connection', 'and', 'it', 'will', 'not', 'always', 'be', 'a', 'bad', 'connection', 'but', 'it', 'will', 'be', 'bad', 'off', 'and', 'on']\n","Updated Tokens (Row 39): ['yeah', 'create', 'bad', 'connection', 'always', 'bad', 'connection', 'bad']\n","Stopwords Removed (Row 39): ['that', 'can', 'be', 'that', 'can', 'a', 'and', 'it', 'will', 'not', 'be', 'a', 'but', 'it', 'will', 'be', 'off', 'and', 'on']\n","Stopwords were removed for Row 39 in file Ses05M_impro08.csv.\n","Original Tokens (Row 40): ['yeah', 'well', 'absolutely', 'what', 'we', 'can', 'let', 'just', 'go', 'ahead', 'and', 'just', 'do', 'a', 'basic', 'diagnostic', 'of', 'your', 'system', 'first', 'off', 'okay', 'can', 'you', 'go', 'down', 'to', 'your', 'start', 'button']\n","Updated Tokens (Row 40): ['yeah', 'well', 'absolutely', 'let', 'go', 'ahead', 'basic', 'diagnostic', 'system', 'first', 'okay', 'go', 'start', 'button']\n","Stopwords Removed (Row 40): ['what', 'we', 'can', 'just', 'and', 'just', 'do', 'a', 'of', 'your', 'off', 'can', 'you', 'down', 'to', 'your']\n","Stopwords were removed for Row 40 in file Ses05M_impro08.csv.\n","Original Tokens (Row 41): ['okay', 'and', 'uh', 'go', 'ahead', 'and', 'click', 'on', 'run']\n","Updated Tokens (Row 41): ['okay', 'uh', 'go', 'ahead', 'click', 'run']\n","Stopwords Removed (Row 41): ['and', 'and', 'on']\n","Stopwords were removed for Row 41 in file Ses05M_impro08.csv.\n","Original Tokens (Row 42): ['okay', 'we', 'gon', 'na', 'get', 'your', 'a', 'little', 'black', 'box', 'is', 'going', 'to', 'come', 'up', 'do', 'you', 'see', 'that']\n","Updated Tokens (Row 42): ['okay', 'gon', 'na', 'get', 'little', 'black', 'box', 'going', 'come', 'see']\n","Stopwords Removed (Row 42): ['we', 'your', 'a', 'is', 'to', 'up', 'do', 'you', 'that']\n","Stopwords were removed for Row 42 in file Ses05M_impro08.csv.\n","Original Tokens (Row 43): ['okay', 'uh', 'you', 'have', 'got', 'your', 'calling', 'go', 'ahead', 'and', 'type', 'in', 'directory', 'list']\n","Updated Tokens (Row 43): ['okay', 'uh', 'got', 'calling', 'go', 'ahead', 'type', 'directory', 'list']\n","Stopwords Removed (Row 43): ['you', 'have', 'your', 'and', 'in']\n","Stopwords were removed for Row 43 in file Ses05M_impro08.csv.\n","Original Tokens (Row 44): ['and', 'hit', 'enter']\n","Updated Tokens (Row 44): ['hit', 'enter']\n","Stopwords Removed (Row 44): ['and']\n","Stopwords were removed for Row 44 in file Ses05M_impro08.csv.\n","Original Tokens (Row 45): ['okay', 'can', 'you', 'tell', 'me', 'what', 'that', 'says']\n","Updated Tokens (Row 45): ['okay', 'tell', 'says']\n","Stopwords Removed (Row 45): ['can', 'you', 'me', 'what', 'that']\n","Stopwords were removed for Row 45 in file Ses05M_impro08.csv.\n","Original Tokens (Row 46): ['okay', 'okay', 'and', 'um', 'letters', 'and', 'numbers', 'and', 'stuff', 'uh', 'can', 'you', 'can', 'you', 'just', 'type', 'in', 'ip', 'address', 'search', 'and', 'hit', 'enter']\n","Updated Tokens (Row 46): ['okay', 'okay', 'um', 'letters', 'numbers', 'stuff', 'uh', 'type', 'ip', 'address', 'search', 'hit', 'enter']\n","Stopwords Removed (Row 46): ['and', 'and', 'and', 'can', 'you', 'can', 'you', 'just', 'in', 'and']\n","Stopwords were removed for Row 46 in file Ses05M_impro08.csv.\n","Original Tokens (Row 47): ['okay', 'does', 'it', 'list', 'your', 'ip', 'address', 'there']\n","Updated Tokens (Row 47): ['okay', 'list', 'ip', 'address']\n","Stopwords Removed (Row 47): ['does', 'it', 'your', 'there']\n","Stopwords were removed for Row 47 in file Ses05M_impro08.csv.\n","Original Tokens (Row 48): ['it', 'is', 'set', 'to', 'zeros', 'okay', 'maybe', 'that', 'is', 'our', 'problem', 'that', 'could', 'very', 'well', 'be', 'our', 'problem', 'there', 'somehow', 'you', 'have', 'lost', 'your', 'ip', 'address', 'i', 'not', 'sure', 'why', 'that', 'would', 'happen', 'every', 'week', 'it', 'could', 'be', 'a', 'cycling', 'issue', 'something', 'like', 'that', 'but', 'let', 'go', 'ahead', 'and', 'type', 'your', 'ip', 'address', 'in', 'again']\n","Updated Tokens (Row 48): ['set', 'zeros', 'okay', 'maybe', 'problem', 'could', 'well', 'problem', 'somehow', 'lost', 'ip', 'address', 'sure', 'would', 'happen', 'every', 'week', 'could', 'cycling', 'issue', 'something', 'like', 'let', 'go', 'ahead', 'type', 'ip', 'address']\n","Stopwords Removed (Row 48): ['it', 'is', 'to', 'that', 'is', 'our', 'that', 'very', 'be', 'our', 'there', 'you', 'have', 'your', 'i', 'not', 'why', 'that', 'it', 'be', 'a', 'that', 'but', 'and', 'your', 'in', 'again']\n","Stopwords were removed for Row 48 in file Ses05M_impro08.csv.\n","Original Tokens (Row 49): ['well', 'if', 'it', 'does', 'happen', 'again', 'let', 'me', 'give', 'you', 'my', 'direct', 'number', 'and', 'you', 'can', 'call', 'me', 'actually', 'i', 'give', 'you', 'my', 'cell', 'number', 'um', 'it', 'is']\n","Updated Tokens (Row 49): ['well', 'happen', 'let', 'give', 'direct', 'number', 'call', 'actually', 'give', 'cell', 'number', 'um']\n","Stopwords Removed (Row 49): ['if', 'it', 'does', 'again', 'me', 'you', 'my', 'and', 'you', 'can', 'me', 'i', 'you', 'my', 'it', 'is']\n","Stopwords were removed for Row 49 in file Ses05M_impro08.csv.\n","Original Tokens (Row 50): ['of', 'course', 'we', 'seriously', 'yeah', 'i', 'mean', 'obviously', 'you', 'have', 'worked', 'you', 'know', 'i', 'do', 'not', 'want', 'to', 'hassle', 'you', 'anymore']\n","Updated Tokens (Row 50): ['course', 'seriously', 'yeah', 'mean', 'obviously', 'worked', 'know', 'want', 'hassle', 'anymore']\n","Stopwords Removed (Row 50): ['of', 'we', 'i', 'you', 'have', 'you', 'i', 'do', 'not', 'to', 'you']\n","Stopwords were removed for Row 50 in file Ses05M_impro08.csv.\n","Original Tokens (Row 51): ['i', 'completely', 'understand']\n","Updated Tokens (Row 51): ['completely', 'understand']\n","Stopwords Removed (Row 51): ['i']\n","Stopwords were removed for Row 51 in file Ses05M_impro08.csv.\n","Original Tokens (Row 52): ['absolutely', 'and', 'i', 'just', 'do', 'not', 'want', 'that', 'to', 'happen', 'to', 'you', 'anymore']\n","Updated Tokens (Row 52): ['absolutely', 'want', 'happen', 'anymore']\n","Stopwords Removed (Row 52): ['and', 'i', 'just', 'do', 'not', 'that', 'to', 'to', 'you']\n","Stopwords were removed for Row 52 in file Ses05M_impro08.csv.\n","Original Tokens (Row 53): ['absolutely', 'it', 'is', 'a', 'new', 'service', 'we', 'are', 'offering']\n","Updated Tokens (Row 53): ['absolutely', 'new', 'service', 'offering']\n","Stopwords Removed (Row 53): ['it', 'is', 'a', 'we', 'are']\n","Stopwords were removed for Row 53 in file Ses05M_impro08.csv.\n","Original Tokens (Row 54): ['uh', 'huh', 'uh', 'huh', 'we', 'want', 'you', 'to', 'be', 'happy', 'you', 'our', 'customer', 'you', 'the', 'most', 'important', 'thing', 'okay']\n","Updated Tokens (Row 54): ['uh', 'huh', 'uh', 'huh', 'want', 'happy', 'customer', 'important', 'thing', 'okay']\n","Stopwords Removed (Row 54): ['we', 'you', 'to', 'be', 'you', 'our', 'you', 'the', 'most']\n","Stopwords were removed for Row 54 in file Ses05M_impro08.csv.\n","Original Tokens (Row 55): ['great', 'well', 'that', 'makes', 'me', 'very', 'happy', 'that', 'makes', 'us', 'all', 'happy', 'here', 'at', 'd.s.l', 'extreme', 'is', 'there', 'anything', 'else', 'i', 'can', 'help', 'you', 'with']\n","Updated Tokens (Row 55): ['great', 'well', 'makes', 'happy', 'makes', 'us', 'happy', 'd.s.l', 'extreme', 'anything', 'else', 'help']\n","Stopwords Removed (Row 55): ['that', 'me', 'very', 'that', 'all', 'here', 'at', 'is', 'there', 'i', 'can', 'you', 'with']\n","Stopwords were removed for Row 55 in file Ses05M_impro08.csv.\n","Original Tokens (Row 56): ['all', 'right', 'you', 'have', 'a', 'wonderful', 'day', 'call', 'us', 'anytime']\n","Updated Tokens (Row 56): ['right', 'wonderful', 'day', 'call', 'us', 'anytime']\n","Stopwords Removed (Row 56): ['all', 'you', 'have', 'a']\n","Stopwords were removed for Row 56 in file Ses05M_impro08.csv.\n","Original Tokens (Row 57): ['all', 'right', 'bye', 'bye']\n","Updated Tokens (Row 57): ['right', 'bye', 'bye']\n","Stopwords Removed (Row 57): ['all']\n","Stopwords were removed for Row 57 in file Ses05M_impro08.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_impro08.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_impro08.csv\n","\n","Processing File: Ses05M_script01_1.csv\n","Original Tokens (Row 0): ['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'should', 'tell', 'him', 'before', 'he', 'sees', 'it']\n","Updated Tokens (Row 0): ['going', 'say', 'maybe', 'tell', 'sees']\n","Stopwords Removed (Row 0): ['what', 'is', 'he', 'to', 'we', 'should', 'him', 'before', 'he', 'it']\n","Stopwords were removed for Row 0 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 1): ['when', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed', 'how', 'could', 'he', 'have', 'seen', 'it']\n","Updated Tokens (Row 1): ['first', 'one', 'still', 'bed', 'could', 'seen']\n","Stopwords Removed (Row 1): ['when', 'i', 'was', 'the', 'up', 'he', 'was', 'in', 'how', 'he', 'have', 'it']\n","Stopwords were removed for Row 1 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 2): ['when']\n","Updated Tokens (Row 2): []\n","Stopwords Removed (Row 2): ['when']\n","Stopwords were removed for Row 2 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 3): ['what', 'was', 'he', 'doing', 'out', 'here', 'at', 'four', 'in', 'the', 'morning']\n","Updated Tokens (Row 3): ['four', 'morning']\n","Stopwords Removed (Row 3): ['what', 'was', 'he', 'doing', 'out', 'here', 'at', 'in', 'the']\n","Stopwords were removed for Row 3 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 4): ['did', 'you', 'talk', 'to', 'him']\n","Updated Tokens (Row 4): ['talk']\n","Stopwords Removed (Row 4): ['did', 'you', 'to', 'him']\n","Stopwords were removed for Row 4 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 5): ['he', 'cried', 'hard']\n","Updated Tokens (Row 5): ['cried', 'hard']\n","Stopwords Removed (Row 5): ['he']\n","Stopwords were removed for Row 5 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 6): ['what', 'was', 'he', 'doing', 'out', 'there', 'at', 'that', 'hour', 'he', 'is', 'getting', 'just', 'like', 'after', 'larry', 'died', 'walking', 'around', 'at', 'night', 'he', 'dreams']\n","Updated Tokens (Row 6): ['hour', 'getting', 'like', 'larry', 'died', 'walking', 'around', 'night', 'dreams']\n","Stopwords Removed (Row 6): ['what', 'was', 'he', 'doing', 'out', 'there', 'at', 'that', 'he', 'is', 'just', 'after', 'at', 'he']\n","Stopwords were removed for Row 6 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 7): ['what', 'is', 'the', 'meaning', 'of', 'that']\n","Updated Tokens (Row 7): ['meaning']\n","Stopwords Removed (Row 7): ['what', 'is', 'the', 'of', 'that']\n","Stopwords were removed for Row 7 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 8): ['what']\n","Updated Tokens (Row 8): []\n","Stopwords Removed (Row 8): ['what']\n","Stopwords were removed for Row 8 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 9): ['what', 'do', 'you', 'mean', 'dishonest']\n","Updated Tokens (Row 9): ['mean', 'dishonest']\n","Stopwords Removed (Row 9): ['what', 'do', 'you']\n","Stopwords were removed for Row 9 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 10): ['what', 'do', 'you', 'want', 'to', 'do', 'argue', 'with', 'him']\n","Updated Tokens (Row 10): ['want', 'argue']\n","Stopwords Removed (Row 10): ['what', 'do', 'you', 'to', 'do', 'with', 'him']\n","Stopwords were removed for Row 10 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 11): ['you', 'can', 'not', 'say', 'that', 'to', 'him']\n","Updated Tokens (Row 11): ['say']\n","Stopwords Removed (Row 11): ['you', 'can', 'not', 'that', 'to', 'him']\n","Stopwords were removed for Row 11 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 12): ['how', 'are', 'you', 'gon', 'na', 'prove', 'it', 'can', 'you', 'prove', 'it']\n","Updated Tokens (Row 12): ['gon', 'na', 'prove', 'prove']\n","Stopwords Removed (Row 12): ['how', 'are', 'you', 'it', 'can', 'you', 'it']\n","Stopwords were removed for Row 12 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 13): ['to', 'you', 'it', 'is', 'and', 'to', 'me', 'but', 'not', 'to', 'him', 'now', 'you', 'can', 'talk', 'yourself', 'until', 'you', 'blue', 'in', 'the', 'face', 'chris', 'but', 'there', 'no', 'body', 'and', 'there', 'no', 'grave', 'so', 'where', 'are', 'you']\n","Updated Tokens (Row 13): ['talk', 'blue', 'face', 'chris', 'body', 'grave']\n","Stopwords Removed (Row 13): ['to', 'you', 'it', 'is', 'and', 'to', 'me', 'but', 'not', 'to', 'him', 'now', 'you', 'can', 'yourself', 'until', 'you', 'in', 'the', 'but', 'there', 'no', 'and', 'there', 'no', 'so', 'where', 'are', 'you']\n","Stopwords were removed for Row 13 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 14): ['the', 'trouble', 'is', 'the', 'god', 'damn', 'newspapers', 'i', 'mean', 'every', 'every', 'week', 'a', 'kid', 'turns', 'up', 'missing', 'like', 'longer', 'than', 'larry']\n","Updated Tokens (Row 14): ['trouble', 'god', 'damn', 'newspapers', 'mean', 'every', 'every', 'week', 'kid', 'turns', 'missing', 'like', 'longer', 'larry']\n","Stopwords Removed (Row 14): ['the', 'is', 'the', 'i', 'a', 'up', 'than']\n","Stopwords were removed for Row 14 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 15): ['why']\n","Updated Tokens (Row 15): []\n","Stopwords Removed (Row 15): ['why']\n","Stopwords were removed for Row 15 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 16): ['well', 'i', 'have', 'an', 'idea', 'but', 'what', 'is', 'the', 'story']\n","Updated Tokens (Row 16): ['well', 'idea', 'story']\n","Stopwords Removed (Row 16): ['i', 'have', 'an', 'but', 'what', 'is', 'the']\n","Stopwords were removed for Row 16 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 17): ['well', 'that', 'is', 'your', 'business', 'chris']\n","Updated Tokens (Row 17): ['well', 'business', 'chris']\n","Stopwords Removed (Row 17): ['that', 'is', 'your']\n","Stopwords were removed for Row 17 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 18): ['well', 'what', 'do', 'you', 'want', 'me', 'to', 'do', 'you', 'old', 'enough', 'to', 'make', 'to', 'know', 'your', 'own', 'mind']\n","Updated Tokens (Row 18): ['well', 'want', 'old', 'enough', 'make', 'know', 'mind']\n","Stopwords Removed (Row 18): ['what', 'do', 'you', 'me', 'to', 'do', 'you', 'to', 'to', 'your', 'own']\n","Stopwords were removed for Row 18 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 19): ['well', 'you', 'want', 'to', 'make', 'sure', 'that', 'your', 'father', 'is', 'not']\n","Updated Tokens (Row 19): ['well', 'want', 'make', 'sure', 'father']\n","Stopwords Removed (Row 19): ['you', 'to', 'that', 'your', 'is', 'not']\n","Stopwords were removed for Row 19 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 20): ['i', 'just', 'saying']\n","Updated Tokens (Row 20): ['saying']\n","Stopwords Removed (Row 20): ['i', 'just']\n","Stopwords were removed for Row 20 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 21): ['i', 'ignore', 'what', 'i', 'got', 'to', 'ignore', 'i', 'mean', 'the', 'girl', 'is', 'larry', 'girl']\n","Updated Tokens (Row 21): ['ignore', 'got', 'ignore', 'mean', 'girl', 'larry', 'girl']\n","Stopwords Removed (Row 21): ['i', 'what', 'i', 'to', 'i', 'the', 'is']\n","Stopwords were removed for Row 21 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 22): ['from', 'your', 'father', 'point', 'of', 'view', 'he', 'is', 'not', 'dead', 'and', 'she', 'is', 'still', 'his', 'girl', 'now', 'you', 'can', 'go', 'on', 'from', 'there', 'if', 'you', 'know', 'where', 'to', 'go', 'chris', 'but', 'i', 'do', 'not', 'know', 'so', 'what', 'can', 'i', 'do', 'for', 'you']\n","Updated Tokens (Row 22): ['father', 'point', 'view', 'dead', 'still', 'girl', 'go', 'know', 'go', 'chris', 'know']\n","Stopwords Removed (Row 22): ['from', 'your', 'of', 'he', 'is', 'not', 'and', 'she', 'is', 'his', 'now', 'you', 'can', 'on', 'from', 'there', 'if', 'you', 'where', 'to', 'but', 'i', 'do', 'not', 'so', 'what', 'can', 'i', 'do', 'for', 'you']\n","Stopwords were removed for Row 22 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 23): ['well', 'you', 'a', 'considerate', 'fella', 'there', 'nothing', 'wrong', 'in', 'that']\n","Updated Tokens (Row 23): ['well', 'considerate', 'fella', 'nothing', 'wrong']\n","Stopwords Removed (Row 23): ['you', 'a', 'there', 'in', 'that']\n","Stopwords were removed for Row 23 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 24): ['have', 'you', 'asked', 'annie', 'yet']\n","Updated Tokens (Row 24): ['asked', 'annie', 'yet']\n","Stopwords Removed (Row 24): ['have', 'you']\n","Stopwords were removed for Row 24 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 25): ['well', 'what', 'if', 'she', 'feels', 'like', 'your', 'father', 'and', 'how', 'do', 'you', 'know', 'she', 'will', 'marry', 'you']\n","Updated Tokens (Row 25): ['well', 'feels', 'like', 'father', 'know', 'marry']\n","Stopwords Removed (Row 25): ['what', 'if', 'she', 'your', 'and', 'how', 'do', 'you', 'she', 'will', 'you']\n","Stopwords were removed for Row 25 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 26): ['well', 'the', 'trouble', 'is', 'you', 'never', 'saw', 'enough', 'women']\n","Updated Tokens (Row 26): ['well', 'trouble', 'never', 'saw', 'enough', 'women']\n","Stopwords Removed (Row 26): ['the', 'is', 'you']\n","Stopwords were removed for Row 26 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 27): ['well', 'i', 'just', 'do', 'not', 'see', 'why', 'it', 'has', 'to', 'be', 'annie']\n","Updated Tokens (Row 27): ['well', 'see', 'annie']\n","Stopwords Removed (Row 27): ['i', 'just', 'do', 'not', 'why', 'it', 'has', 'to', 'be']\n","Stopwords were removed for Row 27 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 28): ['well', 'that', 'is', 'a', 'good', 'reason', 'but', 'that', 'does', 'not', 'mean', 'anything', 'at', 'all', 'i', 'mean', 'you', 'have', 'seen', 'her', 'in', 'five', 'years']\n","Updated Tokens (Row 28): ['well', 'good', 'reason', 'mean', 'anything', 'mean', 'seen', 'five', 'years']\n","Stopwords Removed (Row 28): ['that', 'is', 'a', 'but', 'that', 'does', 'not', 'at', 'all', 'i', 'you', 'have', 'her', 'in']\n","Stopwords were removed for Row 28 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 29): ['no', 'i', 'do', 'not', 'want', 'a', 'look', 'your', 'father', 'thinks', 'he', 'is', 'coming', 'back', 'chris', 'you', 'marry', 'that', 'girl', 'and', 'you', 'pronouncing', 'him', 'dead', 'now', 'what', 'is', 'going', 'to', 'happen', 'to', 'your', 'father', 'do', 'you', 'know', 'because', 'i', 'do', 'not']\n","Updated Tokens (Row 29): ['want', 'look', 'father', 'thinks', 'coming', 'back', 'chris', 'marry', 'girl', 'pronouncing', 'dead', 'going', 'happen', 'father', 'know']\n","Stopwords Removed (Row 29): ['no', 'i', 'do', 'not', 'a', 'your', 'he', 'is', 'you', 'that', 'and', 'you', 'him', 'now', 'what', 'is', 'to', 'to', 'your', 'do', 'you', 'because', 'i', 'do', 'not']\n","Stopwords were removed for Row 29 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 30): ['just', 'give', 'it', 'some', 'more', 'thought']\n","Updated Tokens (Row 30): ['give', 'thought']\n","Stopwords Removed (Row 30): ['just', 'it', 'some', 'more']\n","Stopwords were removed for Row 30 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 31): ['what', 'the', 'hell', 'is', 'this']\n","Updated Tokens (Row 31): ['hell']\n","Stopwords Removed (Row 31): ['what', 'the', 'is', 'this']\n","Stopwords were removed for Row 31 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 32): ['are', 'you', 'crazy']\n","Updated Tokens (Row 32): ['crazy']\n","Stopwords Removed (Row 32): ['are', 'you']\n","Stopwords were removed for Row 32 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 33): ['what', 'you', 'mean', 'tell', 'me', 'something', 'you', 'mean', 'that', 'you', 'would', 'leave', 'the', 'business']\n","Updated Tokens (Row 33): ['mean', 'tell', 'something', 'mean', 'would', 'leave', 'business']\n","Stopwords Removed (Row 33): ['what', 'you', 'me', 'you', 'that', 'you', 'the']\n","Stopwords were removed for Row 33 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 34): ['you', 'can', 'not', 'think', 'like', 'that']\n","Updated Tokens (Row 34): ['think', 'like']\n","Stopwords Removed (Row 34): ['you', 'can', 'not', 'that']\n","Stopwords were removed for Row 34 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 35): ['all', 'right', 'but', 'do', 'not', 'think', 'like', 'that', 'because', 'what', 'the', 'hell', 'did', 'we', 'work', 'for', 'chris', 'i', 'mean', 'this', 'whole', 'thing', 'it', 'is', 'all', 'for', 'you']\n","Updated Tokens (Row 35): ['right', 'think', 'like', 'hell', 'work', 'chris', 'mean', 'whole', 'thing']\n","Stopwords Removed (Row 35): ['all', 'but', 'do', 'not', 'that', 'because', 'what', 'the', 'did', 'we', 'for', 'i', 'this', 'it', 'is', 'all', 'for', 'you']\n","Stopwords were removed for Row 35 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 36): ['just', 'do', 'not', 'think', 'that', 'way', 'do', 'you', 'hear', 'me']\n","Updated Tokens (Row 36): ['think', 'way', 'hear']\n","Stopwords Removed (Row 36): ['just', 'do', 'not', 'that', 'do', 'you', 'me']\n","Stopwords were removed for Row 36 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 37): ['i', 'do', 'not', 'understand', 'you', 'do', 'i']\n","Updated Tokens (Row 37): ['understand']\n","Stopwords Removed (Row 37): ['i', 'do', 'not', 'you', 'do', 'i']\n","Stopwords were removed for Row 37 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 38): ['yeah', 'i', 'can', 'see', 'that']\n","Updated Tokens (Row 38): ['yeah', 'see']\n","Stopwords Removed (Row 38): ['i', 'can', 'that']\n","Stopwords were removed for Row 38 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 39): ['he', 'saw', 'it']\n","Updated Tokens (Row 39): ['saw']\n","Stopwords Removed (Row 39): ['he', 'it']\n","Stopwords were removed for Row 39 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 40): ['he', 'was', 'out', 'here', 'when', 'it', 'broke']\n","Updated Tokens (Row 40): ['broke']\n","Stopwords Removed (Row 40): ['he', 'was', 'out', 'here', 'when', 'it']\n","Stopwords were removed for Row 40 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 41): ['i', 'do', 'not', 'know', 'like', 'four', \"o'clock\", 'this', 'morning', 'i', 'heard', 'a', 'crack', 'and', 'i', 'woke', 'up', 'and', 'i', 'looked', 'out', 'the', 'window', 'and', 'he', 'was', 'standing', 'right', 'there', 'when', 'it', 'broke']\n","Updated Tokens (Row 41): ['know', 'like', 'four', \"o'clock\", 'morning', 'heard', 'crack', 'woke', 'looked', 'window', 'standing', 'right', 'broke']\n","Stopwords Removed (Row 41): ['i', 'do', 'not', 'this', 'i', 'a', 'and', 'i', 'up', 'and', 'i', 'out', 'the', 'and', 'he', 'was', 'there', 'when', 'it']\n","Stopwords were removed for Row 41 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 42): ['i', 'do', 'not', 'know', 'but', 'after', 'it', 'broke', 'he', 'ran', 'back', 'inside', 'and', 'started', 'crying', 'in', 'the', 'kitchen']\n","Updated Tokens (Row 42): ['know', 'broke', 'ran', 'back', 'inside', 'started', 'crying', 'kitchen']\n","Stopwords Removed (Row 42): ['i', 'do', 'not', 'but', 'after', 'it', 'he', 'and', 'in', 'the']\n","Stopwords were removed for Row 42 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 43): ['no', 'i', 'figured', 'it', 'was', 'best', 'to', 'leave', 'him', 'alone']\n","Updated Tokens (Row 43): ['figured', 'best', 'leave', 'alone']\n","Stopwords Removed (Row 43): ['no', 'i', 'it', 'was', 'to', 'him']\n","Stopwords were removed for Row 43 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 44): ['i', 'could', 'hear', 'him', 'right', 'through', 'the', 'floor', 'in', 'my', 'room']\n","Updated Tokens (Row 44): ['could', 'hear', 'right', 'floor', 'room']\n","Stopwords Removed (Row 44): ['i', 'him', 'through', 'the', 'in', 'my']\n","Stopwords were removed for Row 44 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 45): ['i', 'guess', 'he', 'is']\n","Updated Tokens (Row 45): ['guess']\n","Stopwords Removed (Row 45): ['i', 'he', 'is']\n","Stopwords were removed for Row 45 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 46): ['i', 'do', 'not', 'know', 'the', 'meaning', 'of', 'it', 'but', 'you', 'know', 'one', 'thing', 'mom', 'we', 'made', 'a', 'terrible', 'mistake', 'with', 'dad']\n","Updated Tokens (Row 46): ['know', 'meaning', 'know', 'one', 'thing', 'mom', 'made', 'terrible', 'mistake', 'dad']\n","Stopwords Removed (Row 46): ['i', 'do', 'not', 'the', 'of', 'it', 'but', 'you', 'we', 'a', 'with']\n","Stopwords were removed for Row 46 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 47): ['being', 'dishonest', 'with', 'him', 'it', 'is', 'the', 'kind', 'of', 'thing', 'that', 'pays', 'off', 'and', 'now', 'it', 'is', 'paying', 'off']\n","Updated Tokens (Row 47): ['dishonest', 'kind', 'thing', 'pays', 'paying']\n","Stopwords Removed (Row 47): ['being', 'with', 'him', 'it', 'is', 'the', 'of', 'that', 'off', 'and', 'now', 'it', 'is', 'off']\n","Stopwords were removed for Row 47 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 48): ['you', 'know', 'that', 'larry', 'not', 'coming', 'back', 'and', 'i', 'know', 'it', 'so', 'why', 'do', 'we', 'go', 'on', 'letting', 'him', 'think', 'that', 'we', 'believe', 'with', 'him']\n","Updated Tokens (Row 48): ['know', 'larry', 'coming', 'back', 'know', 'go', 'letting', 'think', 'believe']\n","Stopwords Removed (Row 48): ['you', 'that', 'not', 'and', 'i', 'it', 'so', 'why', 'do', 'we', 'on', 'him', 'that', 'we', 'with', 'him']\n","Stopwords were removed for Row 48 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 49): ['i', 'do', 'not', 'want', 'to', 'argue', 'with', 'him', 'but', 'it', 'is', 'time', 'he', 'knows', 'that', 'nobody', 'else', 'thinks', 'that', 'larry', 'alive', 'anymore']\n","Updated Tokens (Row 49): ['want', 'argue', 'time', 'knows', 'nobody', 'else', 'thinks', 'larry', 'alive', 'anymore']\n","Stopwords Removed (Row 49): ['i', 'do', 'not', 'to', 'with', 'him', 'but', 'it', 'is', 'he', 'that', 'that']\n","Stopwords were removed for Row 49 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 50): ['why', 'should', 'he', 'dream', 'about', 'him', 'walking', 'around', 'looking', 'for', 'him', 'at', 'night', 'do', 'we', 'contradict', 'him', 'do', 'we', 'say', 'straight', 'out', 'that', 'we', 'do', 'not', 'have', 'any', 'hope', 'anymore', 'that', 'we', 'have', 'had', 'any', 'hope', 'for', 'years', 'now']\n","Updated Tokens (Row 50): ['dream', 'walking', 'around', 'looking', 'night', 'contradict', 'say', 'straight', 'hope', 'anymore', 'hope', 'years']\n","Stopwords Removed (Row 50): ['why', 'should', 'he', 'about', 'him', 'for', 'him', 'at', 'do', 'we', 'him', 'do', 'we', 'out', 'that', 'we', 'do', 'not', 'have', 'any', 'that', 'we', 'have', 'had', 'any', 'for', 'now']\n","Stopwords were removed for Row 50 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 51): ['we', 'have', 'to', 'say', 'it', 'to', 'him']\n","Updated Tokens (Row 51): ['say']\n","Stopwords Removed (Row 51): ['we', 'have', 'to', 'it', 'to', 'him']\n","Stopwords were removed for Row 51 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 52): ['for', 'gods', 'sake', 'three', 'years', 'nobody', 'comes', 'back', 'after', 'three', 'years', 'that', 'is', 'insane']\n","Updated Tokens (Row 52): ['gods', 'sake', 'three', 'years', 'nobody', 'comes', 'back', 'three', 'years', 'insane']\n","Stopwords Removed (Row 52): ['for', 'after', 'that', 'is']\n","Stopwords were removed for Row 52 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 53): ['sit', 'down', 'mom', 'i', 'want', 'to', 'talk', 'to', 'you']\n","Updated Tokens (Row 53): ['sit', 'mom', 'want', 'talk']\n","Stopwords Removed (Row 53): ['down', 'i', 'to', 'to', 'you']\n","Stopwords were removed for Row 53 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 54): ['all', 'right', 'all', 'right', 'mom', 'just', 'listen', 'you', 'know', 'why', 'i', 'invited', 'annie', 'her', 'do', 'not', 'you']\n","Updated Tokens (Row 54): ['right', 'right', 'mom', 'listen', 'know', 'invited', 'annie']\n","Stopwords Removed (Row 54): ['all', 'all', 'just', 'you', 'why', 'i', 'her', 'do', 'not', 'you']\n","Stopwords were removed for Row 54 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 55): ['you', 'know']\n","Updated Tokens (Row 55): ['know']\n","Stopwords Removed (Row 55): ['you']\n","Stopwords were removed for Row 55 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 56): ['i', 'going', 'to', 'ask', 'her', 'to', 'marry', 'me']\n","Updated Tokens (Row 56): ['going', 'ask', 'marry']\n","Stopwords Removed (Row 56): ['i', 'to', 'her', 'to', 'me']\n","Stopwords were removed for Row 56 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 57): ['it', 'is', 'not', 'just', 'my', 'business']\n","Updated Tokens (Row 57): ['business']\n","Stopwords Removed (Row 57): ['it', 'is', 'not', 'just', 'my']\n","Stopwords were removed for Row 57 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 58): ['so', 'it', 'is', 'okay', 'then', 'i', 'should', 'just', 'go', 'ahead', 'and', 'do', 'it']\n","Updated Tokens (Row 58): ['okay', 'go', 'ahead']\n","Stopwords Removed (Row 58): ['so', 'it', 'is', 'then', 'i', 'should', 'just', 'and', 'do', 'it']\n","Stopwords were removed for Row 58 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 59): ['oh', 'so', 'it', 'is', 'not', 'just', 'my', 'business']\n","Updated Tokens (Row 59): ['oh', 'business']\n","Stopwords Removed (Row 59): ['so', 'it', 'is', 'not', 'just', 'my']\n","Stopwords were removed for Row 59 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 60): ['you', 'infuriate', 'me', 'sometimes', 'do', 'you', 'know', 'that', 'god']\n","Updated Tokens (Row 60): ['infuriate', 'sometimes', 'know', 'god']\n","Stopwords Removed (Row 60): ['you', 'me', 'do', 'you', 'that']\n","Stopwords were removed for Row 60 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 61): ['is', 'not', 'it', 'your', 'business', 'too', 'if', 'dad', 'if', 'i', 'tell', 'dad', 'and', 'he', 'throws', 'a', 'fit', 'about', 'it', 'i', 'mean', 'you', 'have', 'such', 'a', 'talent', 'for', 'ignoring', 'things']\n","Updated Tokens (Row 61): ['business', 'dad', 'tell', 'dad', 'throws', 'fit', 'mean', 'talent', 'ignoring', 'things']\n","Stopwords Removed (Row 61): ['is', 'not', 'it', 'your', 'too', 'if', 'if', 'i', 'and', 'he', 'a', 'about', 'it', 'i', 'you', 'have', 'such', 'a', 'for']\n","Stopwords were removed for Row 61 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 62): ['she', 'is', 'not', 'larry', 'girl']\n","Updated Tokens (Row 62): ['larry', 'girl']\n","Stopwords Removed (Row 62): ['she', 'is', 'not']\n","Stopwords were removed for Row 62 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 63): ['i', 'do', 'not', 'know', 'why', 'it', 'is', 'but', 'everytime', 'i', 'reach', 'out', 'for', 'something', 'that', 'i', 'want', 'i', 'have', 'to', 'pull', 'back', 'because', 'i', 'might', 'hurt', 'somebody', 'else', 'my', 'whole', 'bloody', 'life', 'time', 'after', 'time', 'after', 'time']\n","Updated Tokens (Row 63): ['know', 'everytime', 'reach', 'something', 'want', 'pull', 'back', 'might', 'hurt', 'somebody', 'else', 'whole', 'bloody', 'life', 'time', 'time', 'time']\n","Stopwords Removed (Row 63): ['i', 'do', 'not', 'why', 'it', 'is', 'but', 'i', 'out', 'for', 'that', 'i', 'i', 'have', 'to', 'because', 'i', 'my', 'after', 'after']\n","Stopwords were removed for Row 63 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 64): ['to', 'hell', 'with', 'that']\n","Updated Tokens (Row 64): ['hell']\n","Stopwords Removed (Row 64): ['to', 'with', 'that']\n","Stopwords were removed for Row 64 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 65): ['i', 'wanted', 'to', 'get', 'this', 'taken', 'care', 'of', 'first']\n","Updated Tokens (Row 65): ['wanted', 'get', 'taken', 'care', 'first']\n","Stopwords Removed (Row 65): ['i', 'to', 'this', 'of']\n","Stopwords were removed for Row 65 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 66): ['well', 'if', 'that', 'is', 'the', 'case', 'then', 'that', 'is', 'the', 'end', 'of', 'it', 'but', 'from', 'her', 'letters', 'it', 'sounds', 'like', 'she', 'has', 'forgotten', 'him', 'i', 'find', 'out', 'and', 'then', 'we', 'thrash', 'it', 'out', 'with', 'dad', 'all', 'right', 'mom', 'do', 'not', 'avoid', 'me']\n","Updated Tokens (Row 66): ['well', 'case', 'end', 'letters', 'sounds', 'like', 'forgotten', 'find', 'thrash', 'dad', 'right', 'mom', 'avoid']\n","Stopwords Removed (Row 66): ['if', 'that', 'is', 'the', 'then', 'that', 'is', 'the', 'of', 'it', 'but', 'from', 'her', 'it', 'she', 'has', 'him', 'i', 'out', 'and', 'then', 'we', 'it', 'out', 'with', 'all', 'do', 'not', 'me']\n","Stopwords were removed for Row 66 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 67): ['so', 'what', 'i', 'not', 'fast', 'with', 'women']\n","Updated Tokens (Row 67): ['fast', 'women']\n","Stopwords Removed (Row 67): ['so', 'what', 'i', 'not', 'with']\n","Stopwords were removed for Row 67 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 68): ['because', 'it', 'is']\n","Updated Tokens (Row 68): []\n","Stopwords Removed (Row 68): ['because', 'it', 'is']\n","Stopwords were removed for Row 68 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 69): ['i', 'know', 'her', 'best', 'all', 'right', 'i', 'do', 'not', 'know', 'i', 'grew', 'up', 'next', 'to', 'her', 'when', 'i', 'think', 'of', 'somebody', 'for', 'my', 'wife', 'these', 'days', 'i', 'think', 'of', 'annie', 'what', 'do', 'you', 'want', 'a', 'diagram']\n","Updated Tokens (Row 69): ['know', 'best', 'right', 'know', 'grew', 'next', 'think', 'somebody', 'wife', 'days', 'think', 'annie', 'want', 'diagram']\n","Stopwords Removed (Row 69): ['i', 'her', 'all', 'i', 'do', 'not', 'i', 'up', 'to', 'her', 'when', 'i', 'of', 'for', 'my', 'these', 'i', 'of', 'what', 'do', 'you', 'a']\n","Stopwords were removed for Row 69 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 70): ['all', 'right', 'then', 'mom']\n","Updated Tokens (Row 70): ['right', 'mom']\n","Stopwords Removed (Row 70): ['all', 'then']\n","Stopwords were removed for Row 70 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 71): ['i', 'given', 'it', 'three', 'years', 'of', 'thought', 'i', 'hoped', 'that', 'if', 'i', 'waited', 'dad', 'would', 'have', 'forgotten', 'about', 'it', 'by', 'now', 'and', 'we', 'could', 'have', 'like', 'a', 'normal', 'wedding', 'and', 'everybody', 'happy']\n","Updated Tokens (Row 71): ['given', 'three', 'years', 'thought', 'hoped', 'waited', 'dad', 'would', 'forgotten', 'could', 'like', 'normal', 'wedding', 'everybody', 'happy']\n","Stopwords Removed (Row 71): ['i', 'it', 'of', 'i', 'that', 'if', 'i', 'have', 'about', 'it', 'by', 'now', 'and', 'we', 'have', 'a', 'and']\n","Stopwords were removed for Row 71 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 72): ['but', 'if', 'that', 'can', 'not', 'happen', 'i', 'just', 'have', 'to', 'get', 'out']\n","Updated Tokens (Row 72): ['happen', 'get']\n","Stopwords Removed (Row 72): ['but', 'if', 'that', 'can', 'not', 'i', 'just', 'have', 'to', 'out']\n","Stopwords were removed for Row 72 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 73): ['i', 'get', 'out', 'i', 'go', 'get', 'married', 'and', 'live', 'someplace', 'else', 'i', 'do', 'not', 'know', 'maybe', 'new', 'york']\n","Updated Tokens (Row 73): ['get', 'go', 'get', 'married', 'live', 'someplace', 'else', 'know', 'maybe', 'new', 'york']\n","Stopwords Removed (Row 73): ['i', 'out', 'i', 'and', 'i', 'do', 'not']\n","Stopwords were removed for Row 73 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 74): ['i', 'have', 'been', 'a', 'good', 'son', 'for', 'too', 'long', 'a', 'good', 'sucker', 'i', 'through', 'with', 'it']\n","Updated Tokens (Row 74): ['good', 'son', 'long', 'good', 'sucker']\n","Stopwords Removed (Row 74): ['i', 'have', 'been', 'a', 'for', 'too', 'a', 'i', 'through', 'with', 'it']\n","Stopwords were removed for Row 74 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 75): ['yes', 'on', 'this', 'i', 'would']\n","Updated Tokens (Row 75): ['yes', 'would']\n","Stopwords Removed (Row 75): ['on', 'this', 'i']\n","Stopwords were removed for Row 75 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 76): ['well', 'you', 'help', 'me', 'stay', 'here']\n","Updated Tokens (Row 76): ['well', 'help', 'stay']\n","Stopwords Removed (Row 76): ['you', 'me', 'here']\n","Stopwords were removed for Row 76 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 77): ['i', 'know', 'that', 'mom', 'just', 'you', 'help', 'me', 'stay', 'here']\n","Updated Tokens (Row 77): ['know', 'mom', 'help', 'stay']\n","Stopwords Removed (Row 77): ['i', 'that', 'just', 'you', 'me', 'here']\n","Stopwords were removed for Row 77 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 78): ['i', 'am', 'thinking', 'that', 'way']\n","Updated Tokens (Row 78): ['thinking', 'way']\n","Stopwords Removed (Row 78): ['i', 'am', 'that']\n","Stopwords were removed for Row 78 in file Ses05M_script01_1.csv.\n","Original Tokens (Row 79): ['no', 'you', 'do', 'not', 'i', 'a', 'pretty', 'tough', 'guy']\n","Updated Tokens (Row 79): ['pretty', 'tough', 'guy']\n","Stopwords Removed (Row 79): ['no', 'you', 'do', 'not', 'i', 'a']\n","Stopwords were removed for Row 79 in file Ses05M_script01_1.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script01_1.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script01_1.csv\n","\n","Processing File: Ses05M_script01_1b.csv\n","Original Tokens (Row 0): ['what', 'is', 'he', 'going', 'to', 'say', 'maybe', 'we', 'ought', 'to', 'tell', 'him', 'before', 'he', 'sees', 'it']\n","Updated Tokens (Row 0): ['going', 'say', 'maybe', 'ought', 'tell', 'sees']\n","Stopwords Removed (Row 0): ['what', 'is', 'he', 'to', 'we', 'to', 'him', 'before', 'he', 'it']\n","Stopwords were removed for Row 0 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 1): ['what', 'do', 'you', 'mean', 'i', 'was', 'the', 'first', 'one', 'up', 'he', 'was', 'still', 'in', 'bed']\n","Updated Tokens (Row 1): ['mean', 'first', 'one', 'still', 'bed']\n","Stopwords Removed (Row 1): ['what', 'do', 'you', 'i', 'was', 'the', 'up', 'he', 'was', 'in']\n","Stopwords were removed for Row 1 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 2): ['when']\n","Updated Tokens (Row 2): []\n","Stopwords Removed (Row 2): ['when']\n","Stopwords were removed for Row 2 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 3): ['what', 'was', 'he', 'doing', 'out', 'here', 'four', 'in', 'the', 'morning']\n","Updated Tokens (Row 3): ['four', 'morning']\n","Stopwords Removed (Row 3): ['what', 'was', 'he', 'doing', 'out', 'here', 'in', 'the']\n","Stopwords were removed for Row 3 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 4): ['did', 'you', 'talk', 'to', 'him']\n","Updated Tokens (Row 4): ['talk']\n","Stopwords Removed (Row 4): ['did', 'you', 'to', 'him']\n","Stopwords were removed for Row 4 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 5): ['he', 'is', 'dreaming', 'about', 'him', 'again', 'he', 'is', 'getting', 'just', 'like', 'after', 'larry', 'died', 'what', 'is', 'the', 'meaning', 'of', 'that']\n","Updated Tokens (Row 5): ['dreaming', 'getting', 'like', 'larry', 'died', 'meaning']\n","Stopwords Removed (Row 5): ['he', 'is', 'about', 'him', 'again', 'he', 'is', 'just', 'after', 'what', 'is', 'the', 'of', 'that']\n","Stopwords were removed for Row 5 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 6): ['what']\n","Updated Tokens (Row 6): []\n","Stopwords Removed (Row 6): ['what']\n","Stopwords were removed for Row 6 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 7): ['what', 'do', 'you', 'mean', 'dishonest']\n","Updated Tokens (Row 7): ['mean', 'dishonest']\n","Stopwords Removed (Row 7): ['what', 'do', 'you']\n","Stopwords were removed for Row 7 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 8): ['what', 'are', 'you', 'gon', 'na', 'do', 'argue', 'with', 'him']\n","Updated Tokens (Row 8): ['gon', 'na', 'argue']\n","Stopwords Removed (Row 8): ['what', 'are', 'you', 'do', 'with', 'him']\n","Stopwords were removed for Row 8 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 9): ['well', 'how', 'are', 'you', 'gon', 'na', 'prove', 'it', 'can', 'you', 'prove', 'it']\n","Updated Tokens (Row 9): ['well', 'gon', 'na', 'prove', 'prove']\n","Stopwords Removed (Row 9): ['how', 'are', 'you', 'it', 'can', 'you', 'it']\n","Stopwords were removed for Row 9 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 10): ['to', 'you', 'it', 'is', 'and', 'to', 'me', 'but', 'not', 'to', 'him']\n","Updated Tokens (Row 10): []\n","Stopwords Removed (Row 10): ['to', 'you', 'it', 'is', 'and', 'to', 'me', 'but', 'not', 'to', 'him']\n","Stopwords were removed for Row 10 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 11): ['you', 'can', 'talk', 'yourself', 'blue', 'in', 'the', 'face', 'but', 'there', 'no', 'body', 'and', 'there', 'no', 'grave', 'so', 'where', 'are', 'you']\n","Updated Tokens (Row 11): ['talk', 'blue', 'face', 'body', 'grave']\n","Stopwords Removed (Row 11): ['you', 'can', 'yourself', 'in', 'the', 'but', 'there', 'no', 'and', 'there', 'no', 'so', 'where', 'are', 'you']\n","Stopwords were removed for Row 11 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 12): ['the', 'trouble', 'is', 'the', 'god', 'damn', 'newspapers', 'i', 'mean', 'ea', 'each', 'week', 'a', 'new', 'boy', 'turns', 'up', 'out', 'of', 'nowhere', 'so', 'the', 'next', 'one', 'is', 'gon', 'na', 'be', 'larry', 'so', 'you']\n","Updated Tokens (Row 12): ['trouble', 'god', 'damn', 'newspapers', 'mean', 'ea', 'week', 'new', 'boy', 'turns', 'nowhere', 'next', 'one', 'gon', 'na', 'larry']\n","Stopwords Removed (Row 12): ['the', 'is', 'the', 'i', 'each', 'a', 'up', 'out', 'of', 'so', 'the', 'is', 'be', 'so', 'you']\n","Stopwords were removed for Row 12 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 13): ['why']\n","Updated Tokens (Row 13): []\n","Stopwords Removed (Row 13): ['why']\n","Stopwords were removed for Row 13 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 14): ['well', 'i', 'got', 'an', 'idea', 'but', 'what', 'is', 'the', 'story']\n","Updated Tokens (Row 14): ['well', 'got', 'idea', 'story']\n","Stopwords Removed (Row 14): ['i', 'an', 'but', 'what', 'is', 'the']\n","Stopwords were removed for Row 14 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 15): ['well', 'that', 'is', 'your', 'business', 'chris']\n","Updated Tokens (Row 15): ['well', 'business', 'chris']\n","Stopwords Removed (Row 15): ['that', 'is', 'your']\n","Stopwords were removed for Row 15 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 16): ['what', 'do', 'you', 'want', 'me', 'to', 'do', 'i', 'mean', 'you', 'old', 'enough', 'to', 'know', 'your', 'own', 'mind']\n","Updated Tokens (Row 16): ['want', 'mean', 'old', 'enough', 'know', 'mind']\n","Stopwords Removed (Row 16): ['what', 'do', 'you', 'me', 'to', 'do', 'i', 'you', 'to', 'your', 'own']\n","Stopwords were removed for Row 16 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 17): ['well', 'you', 'want', 'to', 'make', 'sure', 'that', 'your', 'father', 'is', 'not', 'gon', 'na']\n","Updated Tokens (Row 17): ['well', 'want', 'make', 'sure', 'father', 'gon', 'na']\n","Stopwords Removed (Row 17): ['you', 'to', 'that', 'your', 'is', 'not']\n","Stopwords were removed for Row 17 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 18): ['i', 'ignore', 'what', 'i', 'got', 'to', 'ignore', 'i', 'mean', 'the', 'girl', 'is', 'larry', 'girl']\n","Updated Tokens (Row 18): ['ignore', 'got', 'ignore', 'mean', 'girl', 'larry', 'girl']\n","Stopwords Removed (Row 18): ['i', 'what', 'i', 'to', 'i', 'the', 'is']\n","Stopwords were removed for Row 18 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 19): ['as', 'far', 'as', 'your', 'father', 'is', 'concerned', 'he', 'is', 'not', 'dead', 'and', 'she', 'is', 'still', 'his', 'girl']\n","Updated Tokens (Row 19): ['far', 'father', 'concerned', 'dead', 'still', 'girl']\n","Stopwords Removed (Row 19): ['as', 'as', 'your', 'is', 'he', 'is', 'not', 'and', 'she', 'is', 'his']\n","Stopwords were removed for Row 19 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 20): ['now', 'you', 'can', 'go', 'on', 'with', 'this', 'if', 'you', 'know', 'where', 'to', 'go', 'but', 'i', 'do', 'not', 'know', 'where', 'to', 'go']\n","Updated Tokens (Row 20): ['go', 'know', 'go', 'know', 'go']\n","Stopwords Removed (Row 20): ['now', 'you', 'can', 'on', 'with', 'this', 'if', 'you', 'where', 'to', 'but', 'i', 'do', 'not', 'where', 'to']\n","Stopwords were removed for Row 20 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 21): ['well', 'you', 'a', 'considerate', 'fella', 'there', 'nothing', 'wrong', 'with', 'that']\n","Updated Tokens (Row 21): ['well', 'considerate', 'fella', 'nothing', 'wrong']\n","Stopwords Removed (Row 21): ['you', 'a', 'there', 'with', 'that']\n","Stopwords were removed for Row 21 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 22): ['have', 'you', 'asked', 'annie', 'yet']\n","Updated Tokens (Row 22): ['asked', 'annie', 'yet']\n","Stopwords Removed (Row 22): ['have', 'you']\n","Stopwords were removed for Row 22 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 23): ['well', 'how', 'do', 'you', 'know', 'she', 'marry', 'you', 'maybe', 'she', 'feels', 'like', 'your', 'father', 'does']\n","Updated Tokens (Row 23): ['well', 'know', 'marry', 'maybe', 'feels', 'like', 'father']\n","Stopwords Removed (Row 23): ['how', 'do', 'you', 'she', 'you', 'she', 'your', 'does']\n","Stopwords were removed for Row 23 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 24): ['the', 'trouble', 'is', 'you', 'do', 'not', 'see', 'enough', 'women', 'you', 'never', 'did']\n","Updated Tokens (Row 24): ['trouble', 'see', 'enough', 'women', 'never']\n","Stopwords Removed (Row 24): ['the', 'is', 'you', 'do', 'not', 'you', 'did']\n","Stopwords were removed for Row 24 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 25): ['i', 'just', 'do', 'not', 'see', 'why', 'it', 'has', 'to', 'be', 'annie']\n","Updated Tokens (Row 25): ['see', 'annie']\n","Stopwords Removed (Row 25): ['i', 'just', 'do', 'not', 'why', 'it', 'has', 'to', 'be']\n","Stopwords were removed for Row 25 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 26): ['well', 'that', 'is', 'a', 'good', 'reason', 'but', 'it', 'do', 'not', 'mean', 'a', 'thing', 'i', 'mean', 'you', 'have', 'seen', 'her', 'since', 'you', 'went', 'to', 'war', 'it', 'is', 'been', 'five', 'years']\n","Updated Tokens (Row 26): ['well', 'good', 'reason', 'mean', 'thing', 'mean', 'seen', 'since', 'went', 'war', 'five', 'years']\n","Stopwords Removed (Row 26): ['that', 'is', 'a', 'but', 'it', 'do', 'not', 'a', 'i', 'you', 'have', 'her', 'you', 'to', 'it', 'is', 'been']\n","Stopwords were removed for Row 26 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 27): ['no', 'i', 'do', 'not', 'want', 'a', 'your', 'father', 'thinks', 'he', 'is', 'coming', 'back', 'chris', 'if', 'you', 'marry', 'that', 'girl', 'you', 'pronouncing', 'him', 'dead']\n","Updated Tokens (Row 27): ['want', 'father', 'thinks', 'coming', 'back', 'chris', 'marry', 'girl', 'pronouncing', 'dead']\n","Stopwords Removed (Row 27): ['no', 'i', 'do', 'not', 'a', 'your', 'he', 'is', 'if', 'you', 'that', 'you', 'him']\n","Stopwords were removed for Row 27 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 28): ['now', 'what', 'is', 'going', 'to', 'happen', 'to', 'your', 'father', 'do', 'you', 'know', 'i', 'do', 'not']\n","Updated Tokens (Row 28): ['going', 'happen', 'father', 'know']\n","Stopwords Removed (Row 28): ['now', 'what', 'is', 'to', 'to', 'your', 'do', 'you', 'i', 'do', 'not']\n","Stopwords were removed for Row 28 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 29): ['just', 'give', 'it', 'some', 'more', 'thought']\n","Updated Tokens (Row 29): ['give', 'thought']\n","Stopwords Removed (Row 29): ['just', 'it', 'some', 'more']\n","Stopwords were removed for Row 29 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 30): ['what', 'the', 'hell', 'is', 'this']\n","Updated Tokens (Row 30): ['hell']\n","Stopwords Removed (Row 30): ['what', 'the', 'is', 'this']\n","Stopwords were removed for Row 30 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 31): ['are', 'you', 'crazy']\n","Updated Tokens (Row 31): ['crazy']\n","Stopwords Removed (Row 31): ['are', 'you']\n","Stopwords were removed for Row 31 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 32): ['but', 'you', 'have', 'a', 'business', 'here', 'what', 'the', 'hell', 'is', 'this']\n","Updated Tokens (Row 32): ['business', 'hell']\n","Stopwords Removed (Row 32): ['but', 'you', 'have', 'a', 'here', 'what', 'the', 'is', 'this']\n","Stopwords were removed for Row 32 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 33): ['must', 'you', 'be', 'inspired']\n","Updated Tokens (Row 33): ['must', 'inspired']\n","Stopwords Removed (Row 33): ['you', 'be']\n","Stopwords were removed for Row 33 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 34): ['you', 'do', 'not', 'want', 'to', 'think', 'like', 'that']\n","Updated Tokens (Row 34): ['want', 'think', 'like']\n","Stopwords Removed (Row 34): ['you', 'do', 'not', 'to', 'that']\n","Stopwords were removed for Row 34 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 35): ['all', 'right', 'but', 'do', 'not', 'think', 'like', 'that', 'because', 'what', 'the', 'hell', 'did', 'we', 'work', 'for', 'chris', 'all', 'of', 'this', 'all', 'of', 'it', 'it', 'is', 'all', 'just', 'for', 'you']\n","Updated Tokens (Row 35): ['right', 'think', 'like', 'hell', 'work', 'chris']\n","Stopwords Removed (Row 35): ['all', 'but', 'do', 'not', 'that', 'because', 'what', 'the', 'did', 'we', 'for', 'all', 'of', 'this', 'all', 'of', 'it', 'it', 'is', 'all', 'just', 'for', 'you']\n","Stopwords were removed for Row 35 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 36): ['do', 'not', 'think', 'like', 'that', 'do', 'you', 'hear', 'me']\n","Updated Tokens (Row 36): ['think', 'like', 'hear']\n","Stopwords Removed (Row 36): ['do', 'not', 'that', 'do', 'you', 'me']\n","Stopwords were removed for Row 36 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 37): ['i', 'do', 'not', 'understand', 'you', 'do', 'i']\n","Updated Tokens (Row 37): ['understand']\n","Stopwords Removed (Row 37): ['i', 'do', 'not', 'you', 'do', 'i']\n","Stopwords were removed for Row 37 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 38): ['yeah', 'i', 'can', 'see', 'that']\n","Updated Tokens (Row 38): ['yeah', 'see']\n","Stopwords Removed (Row 38): ['i', 'can', 'that']\n","Stopwords were removed for Row 38 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 39): ['he', 'saw', 'it']\n","Updated Tokens (Row 39): ['saw']\n","Stopwords Removed (Row 39): ['he', 'it']\n","Stopwords were removed for Row 39 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 40): ['he', 'was', 'out', 'here', 'when', 'it', 'broke']\n","Updated Tokens (Row 40): ['broke']\n","Stopwords Removed (Row 40): ['he', 'was', 'out', 'here', 'when', 'it']\n","Stopwords were removed for Row 40 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 41): ['about', 'four', 'this', 'morning', 'i', 'heard', 'it', 'crack', 'and', 'i', 'looked', 'out', 'the', 'window', 'and', 'he', 'was', 'standing', 'right', 'there', 'when', 'it', 'cracked']\n","Updated Tokens (Row 41): ['four', 'morning', 'heard', 'crack', 'looked', 'window', 'standing', 'right', 'cracked']\n","Stopwords Removed (Row 41): ['about', 'this', 'i', 'it', 'and', 'i', 'out', 'the', 'and', 'he', 'was', 'there', 'when', 'it']\n","Stopwords were removed for Row 41 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 42): ['i', 'do', 'not', 'know', 'but', 'after', 'he', 'saw', 'it', 'he', 'ran', 'back', 'into', 'the', 'house', 'and', 'started', 'crying', 'in', 'the', 'kitchen']\n","Updated Tokens (Row 42): ['know', 'saw', 'ran', 'back', 'house', 'started', 'crying', 'kitchen']\n","Stopwords Removed (Row 42): ['i', 'do', 'not', 'but', 'after', 'he', 'it', 'he', 'into', 'the', 'and', 'in', 'the']\n","Stopwords were removed for Row 42 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 43): ['no', 'i', 'figured', 'it', 'was', 'best', 'to', 'leave', 'him', 'alone']\n","Updated Tokens (Row 43): ['figured', 'best', 'leave', 'alone']\n","Stopwords Removed (Row 43): ['no', 'i', 'it', 'was', 'to', 'him']\n","Stopwords were removed for Row 43 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 44): ['yes', 'yes', 'he', 'is', 'i', 'do', 'not', 'know', 'the', 'meaning', 'in', 'it', 'but', 'i', 'know', 'one', 'thing', 'mom', 'we', 'made', 'a', 'terrible', 'mistake', 'with', 'dad']\n","Updated Tokens (Row 44): ['yes', 'yes', 'know', 'meaning', 'know', 'one', 'thing', 'mom', 'made', 'terrible', 'mistake', 'dad']\n","Stopwords Removed (Row 44): ['he', 'is', 'i', 'do', 'not', 'the', 'in', 'it', 'but', 'i', 'we', 'a', 'with']\n","Stopwords were removed for Row 44 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 45): ['being', 'dishonest', 'with', 'him', 'it', 'is', 'the', 'kind', 'of', 'thing', 'that', 'pays', 'off', 'and', 'now', 'it', 'is', 'paying', 'off']\n","Updated Tokens (Row 45): ['dishonest', 'kind', 'thing', 'pays', 'paying']\n","Stopwords Removed (Row 45): ['being', 'with', 'him', 'it', 'is', 'the', 'of', 'that', 'off', 'and', 'now', 'it', 'is', 'off']\n","Stopwords were removed for Row 45 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 46): ['you', 'know', 'that', 'larry', 'not', 'coming', 'back', 'and', 'i', 'know', 'it', 'so', 'why', 'do', 'we', 'go', 'on', 'letting', 'him', 'think', 'that', 'we', 'believe', 'with', 'him']\n","Updated Tokens (Row 46): ['know', 'larry', 'coming', 'back', 'know', 'go', 'letting', 'think', 'believe']\n","Stopwords Removed (Row 46): ['you', 'that', 'not', 'and', 'i', 'it', 'so', 'why', 'do', 'we', 'on', 'him', 'that', 'we', 'with', 'him']\n","Stopwords were removed for Row 46 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 47): ['i', 'do', 'not', 'want', 'to', 'argue', 'with', 'him', 'but', 'it', 'is', 'time', 'that', 'he', 'knows', 'that', 'nobody', 'else', 'believes', 'that', 'larry', 'alive', 'i', 'mean']\n","Updated Tokens (Row 47): ['want', 'argue', 'time', 'knows', 'nobody', 'else', 'believes', 'larry', 'alive', 'mean']\n","Stopwords Removed (Row 47): ['i', 'do', 'not', 'to', 'with', 'him', 'but', 'it', 'is', 'that', 'he', 'that', 'that', 'i']\n","Stopwords were removed for Row 47 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 48): ['why', 'should', 'not', 'he', 'dream', 'about', 'him', 'walk', 'the', 'nights', 'waiting', 'for', 'him', 'do', 'we', 'contradict', 'him', 'do', 'we', 'say', 'outright', 'that', 'we', 'do', 'not', 'have', 'any', 'hope', 'anymore', 'that', 'we', 'have', 'had', 'any', 'hope', 'for', 'a', 'long', 'time']\n","Updated Tokens (Row 48): ['dream', 'walk', 'nights', 'waiting', 'contradict', 'say', 'outright', 'hope', 'anymore', 'hope', 'long', 'time']\n","Stopwords Removed (Row 48): ['why', 'should', 'not', 'he', 'about', 'him', 'the', 'for', 'him', 'do', 'we', 'him', 'do', 'we', 'that', 'we', 'do', 'not', 'have', 'any', 'that', 'we', 'have', 'had', 'any', 'for', 'a']\n","Stopwords were removed for Row 48 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 49): ['for', 'gods', 'sake', 'three', 'years', 'nobody', 'comes', 'back', 'after', 'three', 'years', 'it', 'is', 'insane']\n","Updated Tokens (Row 49): ['gods', 'sake', 'three', 'years', 'nobody', 'comes', 'back', 'three', 'years', 'insane']\n","Stopwords Removed (Row 49): ['for', 'after', 'it', 'is']\n","Stopwords were removed for Row 49 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 50): ['sit', 'down', 'mom', 'i', 'want', 'to', 'talk', 'to', 'you']\n","Updated Tokens (Row 50): ['sit', 'mom', 'want', 'talk']\n","Stopwords Removed (Row 50): ['down', 'i', 'to', 'to', 'you']\n","Stopwords were removed for Row 50 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 51): ['all', 'right', 'all', 'right', 'just', 'listen']\n","Updated Tokens (Row 51): ['right', 'right', 'listen']\n","Stopwords Removed (Row 51): ['all', 'all', 'just']\n","Stopwords were removed for Row 51 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 52): ['you', 'know', 'why', 'i', 'invited', 'annie', 'right']\n","Updated Tokens (Row 52): ['know', 'invited', 'annie', 'right']\n","Stopwords Removed (Row 52): ['you', 'why', 'i']\n","Stopwords were removed for Row 52 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 53): ['you', 'know']\n","Updated Tokens (Row 53): ['know']\n","Stopwords Removed (Row 53): ['you']\n","Stopwords were removed for Row 53 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 54): ['i', 'gon', 'na', 'ask', 'her', 'to', 'marry', 'me']\n","Updated Tokens (Row 54): ['gon', 'na', 'ask', 'marry']\n","Stopwords Removed (Row 54): ['i', 'her', 'to', 'me']\n","Stopwords were removed for Row 54 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 55): ['you', 'know', 'it', 'is', 'not', 'just', 'my', 'business']\n","Updated Tokens (Row 55): ['know', 'business']\n","Stopwords Removed (Row 55): ['you', 'it', 'is', 'not', 'just', 'my']\n","Stopwords were removed for Row 55 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 56): ['so', 'it', 'is', 'all', 'right', 'then', 'i', 'should', 'just', 'go', 'ahead', 'with', 'it']\n","Updated Tokens (Row 56): ['right', 'go', 'ahead']\n","Stopwords Removed (Row 56): ['so', 'it', 'is', 'all', 'then', 'i', 'should', 'just', 'with', 'it']\n","Stopwords were removed for Row 56 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 57): ['so', 'it', 'is', 'not', 'just', 'my', 'business', 'you', 'infuriate', 'me', 'sometime', 'you', 'know', 'that']\n","Updated Tokens (Row 57): ['business', 'infuriate', 'sometime', 'know']\n","Stopwords Removed (Row 57): ['so', 'it', 'is', 'not', 'just', 'my', 'you', 'me', 'you', 'that']\n","Stopwords were removed for Row 57 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 58): ['is', 'not', 'it', 'your', 'business', 'too', 'if', 'i', 'tell', 'dad', 'and', 'he', 'throws', 'a', 'fit', 'about', 'it', 'you', 'have', 'such', 'a', 'talent', 'for', 'ignoring', 'things']\n","Updated Tokens (Row 58): ['business', 'tell', 'dad', 'throws', 'fit', 'talent', 'ignoring', 'things']\n","Stopwords Removed (Row 58): ['is', 'not', 'it', 'your', 'too', 'if', 'i', 'and', 'he', 'a', 'about', 'it', 'you', 'have', 'such', 'a', 'for']\n","Stopwords were removed for Row 58 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 59): ['she', 'is', 'not', 'larry', 'girl']\n","Updated Tokens (Row 59): ['larry', 'girl']\n","Stopwords Removed (Row 59): ['she', 'is', 'not']\n","Stopwords were removed for Row 59 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 60): ['i', 'do', 'not', 'know', 'why', 'it', 'is', 'but', 'every', 'time', 'i', 'reach', 'out', 'for', 'something', 'that', 'i', 'want', 'i', 'have', 'to', 'pull', 'back', 'because', 'it', 'might', 'hurt', 'somebody', 'else', 'my', 'whole', 'bloody', 'life', 'time', 'after', 'time', 'after', 'time']\n","Updated Tokens (Row 60): ['know', 'every', 'time', 'reach', 'something', 'want', 'pull', 'back', 'might', 'hurt', 'somebody', 'else', 'whole', 'bloody', 'life', 'time', 'time', 'time']\n","Stopwords Removed (Row 60): ['i', 'do', 'not', 'why', 'it', 'is', 'but', 'i', 'out', 'for', 'that', 'i', 'i', 'have', 'to', 'because', 'it', 'my', 'after', 'after']\n","Stopwords were removed for Row 60 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 61): ['what', 'to', 'hell', 'with', 'that']\n","Updated Tokens (Row 61): ['hell']\n","Stopwords Removed (Row 61): ['what', 'to', 'with', 'that']\n","Stopwords were removed for Row 61 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 62): ['i', 'wanted', 'to', 'get', 'this', 'settled', 'first']\n","Updated Tokens (Row 62): ['wanted', 'get', 'settled', 'first']\n","Stopwords Removed (Row 62): ['i', 'to', 'this']\n","Stopwords were removed for Row 62 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 63): ['well', 'if', 'she', 'does', 'then', 'that', 'is', 'the', 'end', 'of', 'it', 'but', 'from', 'her', 'letters', 'it', 'seems', 'like', 'she', 'is', 'forgotten', 'him']\n","Updated Tokens (Row 63): ['well', 'end', 'letters', 'seems', 'like', 'forgotten']\n","Stopwords Removed (Row 63): ['if', 'she', 'does', 'then', 'that', 'is', 'the', 'of', 'it', 'but', 'from', 'her', 'it', 'she', 'is', 'him']\n","Stopwords were removed for Row 63 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 64): ['i', 'find', 'out', 'and', 'then', 'we', 'thrash', 'it', 'out', 'with', 'dad', 'all', 'right', 'mom', 'do', 'not', 'avoid', 'me']\n","Updated Tokens (Row 64): ['find', 'thrash', 'dad', 'right', 'mom', 'avoid']\n","Stopwords Removed (Row 64): ['i', 'out', 'and', 'then', 'we', 'it', 'out', 'with', 'all', 'do', 'not', 'me']\n","Stopwords were removed for Row 64 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 65): ['so', 'what', 'i', 'not', 'fast', 'with', 'women']\n","Updated Tokens (Row 65): ['fast', 'women']\n","Stopwords Removed (Row 65): ['so', 'what', 'i', 'not', 'with']\n","Stopwords were removed for Row 65 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 66): ['because', 'it', 'is']\n","Updated Tokens (Row 66): []\n","Stopwords Removed (Row 66): ['because', 'it', 'is']\n","Stopwords were removed for Row 66 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 67): ['garbage', 'i', 'do', 'not', 'know', 'it', 'is', 'just']\n","Updated Tokens (Row 67): ['garbage', 'know']\n","Stopwords Removed (Row 67): ['i', 'do', 'not', 'it', 'is', 'just']\n","Stopwords were removed for Row 67 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 68): ['she', 'is', 'who', 'i', 'know', 'best', 'i', 'know', 'her', 'since', 'i', 'was', 'a', 'kid', 'i', 'grew', 'up', 'with', 'her', 'when', 'i', 'think', 'of', 'somebody', 'for', 'my', 'wife', 'these', 'days', 'i', 'i', 'think', 'of', 'annie', 'what', 'do', 'you', 'want', 'a', 'diagram']\n","Updated Tokens (Row 68): ['know', 'best', 'know', 'since', 'kid', 'grew', 'think', 'somebody', 'wife', 'days', 'think', 'annie', 'want', 'diagram']\n","Stopwords Removed (Row 68): ['she', 'is', 'who', 'i', 'i', 'her', 'i', 'was', 'a', 'i', 'up', 'with', 'her', 'when', 'i', 'of', 'for', 'my', 'these', 'i', 'i', 'of', 'what', 'do', 'you', 'a']\n","Stopwords were removed for Row 68 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 69): ['all', 'right', 'then', 'mom']\n","Updated Tokens (Row 69): ['right', 'mom']\n","Stopwords Removed (Row 69): ['all', 'then']\n","Stopwords were removed for Row 69 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 70): ['i', 'given', 'it', 'three', 'years', 'of', 'thought', 'i', 'had', 'hoped', 'if', 'i', 'waited', 'dad', 'would', 'forgotten', 'him', 'by', 'now', 'and', 'we', 'could', 'have', 'a', 'a', 'regular', 'wedding', 'and', 'everybody', 'happy']\n","Updated Tokens (Row 70): ['given', 'three', 'years', 'thought', 'hoped', 'waited', 'dad', 'would', 'forgotten', 'could', 'regular', 'wedding', 'everybody', 'happy']\n","Stopwords Removed (Row 70): ['i', 'it', 'of', 'i', 'had', 'if', 'i', 'him', 'by', 'now', 'and', 'we', 'have', 'a', 'a', 'and']\n","Stopwords were removed for Row 70 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 71): ['but', 'if', 'that', 'can', 'not', 'happen', 'then', 'i', 'just', 'get', 'out']\n","Updated Tokens (Row 71): ['happen', 'get']\n","Stopwords Removed (Row 71): ['but', 'if', 'that', 'can', 'not', 'then', 'i', 'just', 'out']\n","Stopwords were removed for Row 71 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 72): ['i', 'get', 'out', 'i', 'go', 'get', 'married', 'someplace', 'else', 'i', 'live', 'someplace', 'else', 'maybe', 'new', 'york']\n","Updated Tokens (Row 72): ['get', 'go', 'get', 'married', 'someplace', 'else', 'live', 'someplace', 'else', 'maybe', 'new', 'york']\n","Stopwords Removed (Row 72): ['i', 'out', 'i', 'i']\n","Stopwords were removed for Row 72 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 73): ['i', 'been', 'a', 'good', 'son', 'for', 'too', 'long', 'a', 'good', 'sucker', 'i', 'through', 'with', 'it']\n","Updated Tokens (Row 73): ['good', 'son', 'long', 'good', 'sucker']\n","Stopwords Removed (Row 73): ['i', 'been', 'a', 'for', 'too', 'a', 'i', 'through', 'with', 'it']\n","Stopwords were removed for Row 73 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 74): ['the', 'business', 'the', 'business', 'does', 'not', 'inspire', 'me']\n","Updated Tokens (Row 74): ['business', 'business', 'inspire']\n","Stopwords Removed (Row 74): ['the', 'the', 'does', 'not', 'me']\n","Stopwords were removed for Row 74 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 75): ['yeah', 'i', 'like', 'one', 'hour', 'a', 'day', 'if', 'i', 'have', 'to', 'grub', 'for', 'money', 'all', 'day', 'long', 'i', 'like', 'to', 'go', 'home', 'to', 'something', 'beautiful', 'i', 'like', 'a', 'family', 'i', 'like', 'some', 'kids']\n","Updated Tokens (Row 75): ['yeah', 'like', 'one', 'hour', 'day', 'grub', 'money', 'day', 'long', 'like', 'go', 'home', 'something', 'beautiful', 'like', 'family', 'like', 'kids']\n","Stopwords Removed (Row 75): ['i', 'a', 'if', 'i', 'have', 'to', 'for', 'all', 'i', 'to', 'to', 'i', 'a', 'i', 'some']\n","Stopwords were removed for Row 75 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 76): ['i', 'like', 'to', 'build', 'something', 'that', 'is', 'my', 'own', 'and', 'annie', 'is', 'in', 'the', 'center', 'of', 'that', 'now', 'where', 'do', 'i', 'find', 'it']\n","Updated Tokens (Row 76): ['like', 'build', 'something', 'annie', 'center', 'find']\n","Stopwords Removed (Row 76): ['i', 'to', 'that', 'is', 'my', 'own', 'and', 'is', 'in', 'the', 'of', 'that', 'now', 'where', 'do', 'i', 'it']\n","Stopwords were removed for Row 76 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 77): ['well', 'you', 'help', 'me', 'stay', 'here']\n","Updated Tokens (Row 77): ['well', 'help', 'stay']\n","Stopwords Removed (Row 77): ['you', 'me', 'here']\n","Stopwords were removed for Row 77 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 78): ['i', 'know', 'that', 'mom', 'just', 'you', 'help', 'me', 'stay', 'here']\n","Updated Tokens (Row 78): ['know', 'mom', 'help', 'stay']\n","Stopwords Removed (Row 78): ['i', 'that', 'just', 'you', 'me', 'here']\n","Stopwords were removed for Row 78 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 79): ['well', 'i', 'am', 'thinking', 'like', 'that']\n","Updated Tokens (Row 79): ['well', 'thinking', 'like']\n","Stopwords Removed (Row 79): ['i', 'am', 'that']\n","Stopwords were removed for Row 79 in file Ses05M_script01_1b.csv.\n","Original Tokens (Row 80): ['no', 'you', 'do', 'not', 'i', 'a', 'pretty', 'tough', 'guy']\n","Updated Tokens (Row 80): ['pretty', 'tough', 'guy']\n","Stopwords Removed (Row 80): ['no', 'you', 'do', 'not', 'i', 'a']\n","Stopwords were removed for Row 80 in file Ses05M_script01_1b.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script01_1b.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script01_1b.csv\n","\n","Processing File: Ses05M_script01_2.csv\n","Original Tokens (Row 0): ['why', 'did', 'you', 'invite', 'her', 'here']\n","Updated Tokens (Row 0): ['invite']\n","Stopwords Removed (Row 0): ['why', 'did', 'you', 'her', 'here']\n","Stopwords were removed for Row 0 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 1): ['she', 'is', 'been', 'in', 'new', 'york', 'three', 'and', 'a', 'half', 'years', 'why', 'all', 'of', 'a', 'sudden']\n","Updated Tokens (Row 1): ['new', 'york', 'three', 'half', 'years', 'sudden']\n","Stopwords Removed (Row 1): ['she', 'is', 'been', 'in', 'and', 'a', 'why', 'all', 'of', 'a']\n","Stopwords were removed for Row 1 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 2): ['nobody', 'comes', 'seven', 'hundred', 'miles', 'just', 'to', 'see']\n","Updated Tokens (Row 2): ['nobody', 'comes', 'seven', 'hundred', 'miles', 'see']\n","Stopwords Removed (Row 2): ['just', 'to']\n","Stopwords were removed for Row 2 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 3): ['he', 'is', 'not', 'going', 'to', 'marry', 'her']\n","Updated Tokens (Row 3): ['going', 'marry']\n","Stopwords Removed (Row 3): ['he', 'is', 'not', 'to', 'her']\n","Stopwords were removed for Row 3 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 4): ['he', 'is', 'got', 'that', 'about', 'it']\n","Updated Tokens (Row 4): ['got']\n","Stopwords Removed (Row 4): ['he', 'is', 'that', 'about', 'it']\n","Stopwords were removed for Row 4 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 5): ['what', 'is', 'going', 'on', 'here', 'joe']\n","Updated Tokens (Row 5): ['going', 'joe']\n","Stopwords Removed (Row 5): ['what', 'is', 'on', 'here']\n","Stopwords were removed for Row 5 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 6): ['no', 'she', 'is', 'not', 'his', 'girl', 'joe', 'she', 'knows', 'she', 'is', 'not']\n","Updated Tokens (Row 6): ['girl', 'joe', 'knows']\n","Stopwords Removed (Row 6): ['no', 'she', 'is', 'not', 'his', 'she', 'she', 'is', 'not']\n","Stopwords were removed for Row 6 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 7): ['then', 'why', 'is', 'she', 'still', 'single', 'i', 'mean', 'new', 'york', 'is', 'full', 'of', 'men', 'why', 'is', 'not', 'she', 'married', 'probably', 'a', 'hundred', 'people', 'told', 'her', 'she', 'is', 'foolish', 'but', 'she', 'is', 'waited']\n","Updated Tokens (Row 7): ['still', 'single', 'mean', 'new', 'york', 'full', 'men', 'married', 'probably', 'hundred', 'people', 'told', 'foolish', 'waited']\n","Stopwords Removed (Row 7): ['then', 'why', 'is', 'she', 'i', 'is', 'of', 'why', 'is', 'not', 'she', 'a', 'her', 'she', 'is', 'but', 'she', 'is']\n","Stopwords were removed for Row 7 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 8): ['because', 'she', 'knows', 'what', 'i', 'know', 'that', 'is', 'why', 'she', 'is', 'faithful', 'as', 'a', 'rock', 'in', 'my', 'worst', 'moments', 'i', 'think', 'of', 'her', 'waiting', 'and', 'i', 'know', 'again', 'that', 'i', 'right']\n","Updated Tokens (Row 8): ['knows', 'know', 'faithful', 'rock', 'worst', 'moments', 'think', 'waiting', 'know', 'right']\n","Stopwords Removed (Row 8): ['because', 'she', 'what', 'i', 'that', 'is', 'why', 'she', 'is', 'as', 'a', 'in', 'my', 'i', 'of', 'her', 'and', 'i', 'again', 'that', 'i']\n","Stopwords were removed for Row 8 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 9): ['nobody', 'in', 'this', 'house', 'dares', 'takes', 'her', 'faith', 'away', 'joe', 'strangers', 'might', 'but', 'not', 'his', 'father', 'not', 'his', 'brother']\n","Updated Tokens (Row 9): ['nobody', 'house', 'dares', 'takes', 'faith', 'away', 'joe', 'strangers', 'might', 'father', 'brother']\n","Stopwords Removed (Row 9): ['in', 'this', 'her', 'but', 'not', 'his', 'not', 'his']\n","Stopwords were removed for Row 9 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 10): ['i', 'want', 'you', 'to', 'pretend', 'like', 'he', 'is', 'coming', 'back', 'both', 'of', 'you', 'do', 'not', 'think', 'i', 'have', 'noticed', 'you', 'and', 'chris', 'since', 'she', 'is', 'gotten', 'here', 'i', 'do', 'not', 'want', 'any', 'nonsense']\n","Updated Tokens (Row 10): ['want', 'pretend', 'like', 'coming', 'back', 'think', 'noticed', 'chris', 'since', 'gotten', 'want', 'nonsense']\n","Stopwords Removed (Row 10): ['i', 'you', 'to', 'he', 'is', 'both', 'of', 'you', 'do', 'not', 'i', 'have', 'you', 'and', 'she', 'is', 'here', 'i', 'do', 'not', 'any']\n","Stopwords were removed for Row 10 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 11): ['no', 'because', 'if', 'she', 'he', 'is', 'not', 'coming', 'back', 'then', 'i', 'kill', 'myself', 'laugh', 'laugh', 'at', 'me']\n","Updated Tokens (Row 11): ['coming', 'back', 'kill', 'laugh', 'laugh']\n","Stopwords Removed (Row 11): ['no', 'because', 'if', 'she', 'he', 'is', 'not', 'then', 'i', 'myself', 'at', 'me']\n","Stopwords were removed for Row 11 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 12): ['but', 'why', 'did', 'that', 'happen', 'the', 'very', 'night', 'she', 'came', 'back', 'she', 'goes', 'to', 'sleep', 'in', 'his', 'bed', 'and', 'his', 'memorial', 'breaks', 'in', 'pieces', 'look', 'at', 'it']\n","Updated Tokens (Row 12): ['happen', 'night', 'came', 'back', 'goes', 'sleep', 'bed', 'memorial', 'breaks', 'pieces', 'look']\n","Stopwords Removed (Row 12): ['but', 'why', 'did', 'that', 'the', 'very', 'she', 'she', 'to', 'in', 'his', 'and', 'his', 'in', 'at', 'it']\n","Stopwords were removed for Row 12 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 13): ['believe', 'with', 'me', 'joe', 'i', 'can', 'not', 'stand', 'alone']\n","Updated Tokens (Row 13): ['believe', 'joe', 'stand', 'alone']\n","Stopwords Removed (Row 13): ['with', 'me', 'i', 'can', 'not']\n","Stopwords were removed for Row 13 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 14): ['only', 'last', 'week', 'a', 'man', 'turned', 'up', 'in', 'detroit', 'missing', 'longer', 'than', 'larry', 'you', 'read', 'it', 'yourself']\n","Updated Tokens (Row 14): ['last', 'week', 'man', 'turned', 'detroit', 'missing', 'longer', 'larry', 'read']\n","Stopwords Removed (Row 14): ['only', 'a', 'up', 'in', 'than', 'you', 'it', 'yourself']\n","Stopwords were removed for Row 14 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 15): ['you', 'above', 'all', 'have', 'got', 'to', 'believe']\n","Updated Tokens (Row 15): ['got', 'believe']\n","Stopwords Removed (Row 15): ['you', 'above', 'all', 'have', 'to']\n","Stopwords were removed for Row 15 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 16): ['just', 'do', 'not', 'stop', 'believing']\n","Updated Tokens (Row 16): ['stop', 'believing']\n","Stopwords Removed (Row 16): ['just', 'do', 'not']\n","Stopwords were removed for Row 16 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 17): ['i', 'can', 'not', 'help', 'it']\n","Updated Tokens (Row 17): ['help']\n","Stopwords Removed (Row 17): ['i', 'can', 'not', 'it']\n","Stopwords were removed for Row 17 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 18): ['why', 'does', 'that', 'bother', 'you']\n","Updated Tokens (Row 18): ['bother']\n","Stopwords Removed (Row 18): ['why', 'does', 'that', 'you']\n","Stopwords were removed for Row 18 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 19): ['well', 'maybe', 'maybe', 'he', 'just', 'wanted', 'to', 'see', 'her', 'again']\n","Updated Tokens (Row 19): ['well', 'maybe', 'maybe', 'wanted', 'see']\n","Stopwords Removed (Row 19): ['he', 'just', 'to', 'her', 'again']\n","Stopwords were removed for Row 19 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 20): ['what', 'are', 'you', 'talking', 'about', 'he', 'grew', 'up', 'next', 'to', 'the', 'girl', 'his', 'whole', 'life', 'why', 'would', 'not', 'he', 'want', 'to', 'see', 'her', 'again', 'do', 'not', 'look', 'at', 'me', 'like', 'that', 'he', 'has', 'told', 'me', 'anything', 'he', 'did', 'not', 'told', 'you']\n","Updated Tokens (Row 20): ['talking', 'grew', 'next', 'girl', 'whole', 'life', 'would', 'want', 'see', 'look', 'like', 'told', 'anything', 'told']\n","Stopwords Removed (Row 20): ['what', 'are', 'you', 'about', 'he', 'up', 'to', 'the', 'his', 'why', 'not', 'he', 'to', 'her', 'again', 'do', 'not', 'at', 'me', 'that', 'he', 'has', 'me', 'he', 'did', 'not', 'you']\n","Stopwords were removed for Row 20 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 21): ['why', 'do', 'you', 'think', 'he', 'is', 'even', 'thinking', 'that']\n","Updated Tokens (Row 21): ['think', 'even', 'thinking']\n","Stopwords Removed (Row 21): ['why', 'do', 'you', 'he', 'is', 'that']\n","Stopwords were removed for Row 21 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 22): ['well', 'so', 'what']\n","Updated Tokens (Row 22): ['well']\n","Stopwords Removed (Row 22): ['so', 'what']\n","Stopwords were removed for Row 22 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 23): ['now', 'listen']\n","Updated Tokens (Row 23): ['listen']\n","Stopwords Removed (Row 23): ['now']\n","Stopwords were removed for Row 23 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 24): ['you', 'do', 'not', 'know', 'you', 'can', 'not', 'read', 'her', 'mind']\n","Updated Tokens (Row 24): ['know', 'read', 'mind']\n","Stopwords Removed (Row 24): ['you', 'do', 'not', 'you', 'can', 'not', 'her']\n","Stopwords were removed for Row 24 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 25): ['how', 'do', 'you', 'know', 'why', 'she', 'is', 'waited']\n","Updated Tokens (Row 25): ['know', 'waited']\n","Stopwords Removed (Row 25): ['how', 'do', 'you', 'why', 'she', 'is']\n","Stopwords were removed for Row 25 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 26): ['look', 'it', 'is', 'a', 'beautiful', 'day', 'outside', 'why', 'are', 'we', 'arguing']\n","Updated Tokens (Row 26): ['look', 'beautiful', 'day', 'outside', 'arguing']\n","Stopwords Removed (Row 26): ['it', 'is', 'a', 'why', 'are', 'we']\n","Stopwords were removed for Row 26 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 27): ['well', 'what', 'do', 'you', 'want', 'me', 'to', 'do', 'about', 'it', 'what', 'do', 'you', 'want']\n","Updated Tokens (Row 27): ['well', 'want', 'want']\n","Stopwords Removed (Row 27): ['what', 'do', 'you', 'me', 'to', 'do', 'about', 'it', 'what', 'do', 'you']\n","Stopwords were removed for Row 27 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 28): ['but', 'kate']\n","Updated Tokens (Row 28): ['kate']\n","Stopwords Removed (Row 28): ['but']\n","Stopwords were removed for Row 28 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 29): ['calm', 'yourself']\n","Updated Tokens (Row 29): ['calm']\n","Stopwords Removed (Row 29): ['yourself']\n","Stopwords were removed for Row 29 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 30): ['calm', 'yourself']\n","Updated Tokens (Row 30): ['calm']\n","Stopwords Removed (Row 30): ['yourself']\n","Stopwords were removed for Row 30 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 31): ['all', 'right', 'all', 'right']\n","Updated Tokens (Row 31): ['right', 'right']\n","Stopwords Removed (Row 31): ['all', 'all']\n","Stopwords were removed for Row 31 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 32): ['what', 'do', 'you', 'mean', 'me', 'above', 'all']\n","Updated Tokens (Row 32): ['mean']\n","Stopwords Removed (Row 32): ['what', 'do', 'you', 'me', 'above', 'all']\n","Stopwords were removed for Row 32 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 33): ['what', 'is', 'that', 'suppose', 'to', 'mean', 'me', 'above', 'all', 'look', 'at', 'you', 'you', 'shaking']\n","Updated Tokens (Row 33): ['suppose', 'mean', 'look', 'shaking']\n","Stopwords Removed (Row 33): ['what', 'is', 'that', 'to', 'me', 'above', 'all', 'at', 'you', 'you']\n","Stopwords were removed for Row 33 in file Ses05M_script01_2.csv.\n","Original Tokens (Row 34): ['what', 'have', 'i', 'got', 'to', 'hide', 'kate', 'what', 'the', 'hell', 'is', 'the', 'matter', 'with', 'you']\n","Updated Tokens (Row 34): ['got', 'hide', 'kate', 'hell', 'matter']\n","Stopwords Removed (Row 34): ['what', 'have', 'i', 'to', 'what', 'the', 'is', 'the', 'with', 'you']\n","Stopwords were removed for Row 34 in file Ses05M_script01_2.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script01_2.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script01_2.csv\n","\n","Processing File: Ses05M_script01_3.csv\n","Original Tokens (Row 0): ['you', 'the', 'only', 'one', 'i', 'know', 'who', 'loves', 'his', 'parents']\n","Updated Tokens (Row 0): ['one', 'know', 'loves', 'parents']\n","Stopwords Removed (Row 0): ['you', 'the', 'only', 'i', 'who', 'his']\n","Stopwords were removed for Row 0 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 1): ['it', 'is', 'all', 'right', 'it', 'is', 'a', 'good', 'thing', 'it', 'is', 'lovely', 'here', 'the', 'air', 'is', 'sweet']\n","Updated Tokens (Row 1): ['right', 'good', 'thing', 'lovely', 'air', 'sweet']\n","Stopwords Removed (Row 1): ['it', 'is', 'all', 'it', 'is', 'a', 'it', 'is', 'here', 'the', 'is']\n","Stopwords were removed for Row 1 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 2): ['no', 'but', 'i', 'not', 'going', 'to', 'stay']\n","Updated Tokens (Row 2): ['going', 'stay']\n","Stopwords Removed (Row 2): ['no', 'but', 'i', 'not', 'to']\n","Stopwords were removed for Row 2 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 3): ['well', 'your', 'mother', 'first', 'of', 'all', 'pretty', 'much', 'told', 'me', 'to', 'leave']\n","Updated Tokens (Row 3): ['well', 'mother', 'first', 'pretty', 'much', 'told', 'leave']\n","Stopwords Removed (Row 3): ['your', 'of', 'all', 'me', 'to']\n","Stopwords were removed for Row 3 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 4): ['you', 'saw', 'that', 'and', 'well', 'you', 'have', 'been']\n","Updated Tokens (Row 4): ['saw', 'well']\n","Stopwords Removed (Row 4): ['you', 'that', 'and', 'you', 'have', 'been']\n","Stopwords were removed for Row 4 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 5): ['you', 'have', 'been', 'sort', 'of', 'embarrassed', 'since', 'i', 'got', 'here']\n","Updated Tokens (Row 5): ['sort', 'embarrassed', 'since', 'got']\n","Stopwords Removed (Row 5): ['you', 'have', 'been', 'of', 'i', 'here']\n","Stopwords were removed for Row 5 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 6): ['i', 'figured', 'they', 'would', 'your', 'mother', 'at', 'least']\n","Updated Tokens (Row 6): ['figured', 'would', 'mother', 'least']\n","Stopwords Removed (Row 6): ['i', 'they', 'your', 'at']\n","Stopwords were removed for Row 6 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 7): ['well', 'from', 'her', 'perspective', 'i', 'mean', 'why', 'else', 'would', 'i', 'come', 'here']\n","Updated Tokens (Row 7): ['well', 'perspective', 'mean', 'else', 'would', 'come']\n","Stopwords Removed (Row 7): ['from', 'her', 'i', 'why', 'i', 'here']\n","Stopwords were removed for Row 7 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 8): ['yes', 'that', 'is', 'why', 'i', 'came']\n","Updated Tokens (Row 8): ['yes', 'came']\n","Stopwords Removed (Row 8): ['that', 'is', 'why', 'i']\n","Stopwords were removed for Row 8 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 9): ['oh', 'chris', 'i', 'been', 'ready', 'for', 'a', 'long', 'time']\n","Updated Tokens (Row 9): ['oh', 'chris', 'ready', 'long', 'time']\n","Stopwords Removed (Row 9): ['i', 'been', 'for', 'a']\n","Stopwords were removed for Row 9 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 10): ['i', 'almost', 'got', 'married', 'two', 'years', 'ago']\n","Updated Tokens (Row 10): ['almost', 'got', 'married', 'two', 'years', 'ago']\n","Stopwords Removed (Row 10): ['i']\n","Stopwords were removed for Row 10 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 11): ['you', 'started', 'to', 'write', 'me']\n","Updated Tokens (Row 11): ['started', 'write']\n","Stopwords Removed (Row 11): ['you', 'to', 'me']\n","Stopwords were removed for Row 11 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 12): ['everyday', 'since']\n","Updated Tokens (Row 12): ['everyday', 'since']\n","Stopwords Removed (Row 12): []\n","No stopwords removed for Row 12 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 13): ['well', 'i', 'mean', 'until', 'then', 'you', 'never', 'wrote', 'and', 'when', 'you', 'did', 'what', 'did', 'you', 'say', 'i', 'mean', 'you', 'sure', 'can', 'be', 'ambiguous']\n","Updated Tokens (Row 13): ['well', 'mean', 'never', 'wrote', 'say', 'mean', 'sure', 'ambiguous']\n","Stopwords Removed (Row 13): ['i', 'until', 'then', 'you', 'and', 'when', 'you', 'did', 'what', 'did', 'you', 'i', 'you', 'can', 'be']\n","Stopwords were removed for Row 13 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 14): ['i', 'never', 'forgive', 'you', 'why', 'did', 'you', 'wait', 'so', 'long', 'all', 'this', 'time', 'i', 'sat', 'around', 'wondering', 'if', 'i', 'was', 'crazy', 'for', 'thinking', 'of', 'you']\n","Updated Tokens (Row 14): ['never', 'forgive', 'wait', 'long', 'time', 'sat', 'around', 'wondering', 'crazy', 'thinking']\n","Stopwords Removed (Row 14): ['i', 'you', 'why', 'did', 'you', 'so', 'all', 'this', 'i', 'if', 'i', 'was', 'for', 'of', 'you']\n","Stopwords were removed for Row 14 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 15): ['not', 'like', 'that', 'you', 'not']\n","Updated Tokens (Row 15): ['like']\n","Stopwords Removed (Row 15): ['not', 'that', 'you', 'not']\n","Stopwords were removed for Row 15 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 16): ['like', 'larry', 'brother', 'do', 'it', 'like', 'you', 'chris', 'what', 'is', 'the', 'matter']\n","Updated Tokens (Row 16): ['like', 'larry', 'brother', 'like', 'chris', 'matter']\n","Stopwords Removed (Row 16): ['do', 'it', 'you', 'what', 'is', 'the']\n","Stopwords were removed for Row 16 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 17): ['no', 'chris', 'what', 'is', 'it', 'is', 'it', 'your', 'mother']\n","Updated Tokens (Row 17): ['chris', 'mother']\n","Stopwords Removed (Row 17): ['no', 'what', 'is', 'it', 'is', 'it', 'your']\n","Stopwords were removed for Row 17 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 18): ['you', 'have', 'to', 'tell', 'me']\n","Updated Tokens (Row 18): ['tell']\n","Stopwords Removed (Row 18): ['you', 'have', 'to', 'me']\n","Stopwords were removed for Row 18 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 19): ['even', 'in', 'your', 'letters', 'there', 'was', 'something', 'ashamed']\n","Updated Tokens (Row 19): ['even', 'letters', 'something', 'ashamed']\n","Stopwords Removed (Row 19): ['in', 'your', 'there', 'was']\n","Stopwords were removed for Row 19 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 20): ['you', 'have', 'to', 'tell', 'me']\n","Updated Tokens (Row 20): ['tell']\n","Stopwords Removed (Row 20): ['you', 'have', 'to', 'me']\n","Stopwords were removed for Row 20 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 21): ['it', 'would', 'not', 'work', 'like', 'this']\n","Updated Tokens (Row 21): ['would', 'work', 'like']\n","Stopwords Removed (Row 21): ['it', 'not', 'this']\n","Stopwords were removed for Row 21 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 22): ['yeah', 'sure']\n","Updated Tokens (Row 22): ['yeah', 'sure']\n","Stopwords Removed (Row 22): []\n","No stopwords removed for Row 22 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 23): ['how', 'many']\n","Updated Tokens (Row 23): ['many']\n","Stopwords Removed (Row 23): ['how']\n","Stopwords were removed for Row 23 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 24): ['do', 'you', 'still', 'feel', 'like', 'that']\n","Updated Tokens (Row 24): ['still', 'feel', 'like']\n","Stopwords Removed (Row 24): ['do', 'you', 'that']\n","Stopwords were removed for Row 24 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 25): ['because', 'you', 'can', 'not', 'feel', 'like', 'that', 'anymore', 'chris', 'because', 'everything', 'you', 'have', 'you', 'have', 'a', 'right', 'to', 'me', 'included']\n","Updated Tokens (Row 25): ['feel', 'like', 'anymore', 'chris', 'everything', 'right', 'included']\n","Stopwords Removed (Row 25): ['because', 'you', 'can', 'not', 'that', 'because', 'you', 'have', 'you', 'have', 'a', 'to', 'me']\n","Stopwords were removed for Row 25 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 26): ['and', 'you', 'father', 'he', 'put', 'hundreds', 'of', 'planes', 'in', 'the', 'air', 'and', 'you', 'should', 'be', 'proud', 'a', 'man', 'should', 'be', 'paid', 'for', 'that']\n","Updated Tokens (Row 26): ['father', 'put', 'hundreds', 'planes', 'air', 'proud', 'man', 'paid']\n","Stopwords Removed (Row 26): ['and', 'you', 'he', 'of', 'in', 'the', 'and', 'you', 'should', 'be', 'a', 'should', 'be', 'for', 'that']\n","Stopwords were removed for Row 26 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 27): ['laughter', 'what', 'will', 'i', 'do', 'with', 'a', 'fortune']\n","Updated Tokens (Row 27): ['laughter', 'fortune']\n","Stopwords Removed (Row 27): ['what', 'will', 'i', 'do', 'with', 'a']\n","Stopwords were removed for Row 27 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 28): ['i', 'know', 'it', 'is', 'going', 'out', 'of', 'style', 'is', 'not', 'it']\n","Updated Tokens (Row 28): ['know', 'going', 'style']\n","Stopwords Removed (Row 28): ['i', 'it', 'is', 'out', 'of', 'is', 'not', 'it']\n","Stopwords were removed for Row 28 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 29): ['so', 'you', 'not', 'sorry', 'i', 'came']\n","Updated Tokens (Row 29): ['sorry', 'came']\n","Stopwords Removed (Row 29): ['so', 'you', 'not', 'i']\n","Stopwords were removed for Row 29 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 30): ['why']\n","Updated Tokens (Row 30): []\n","Stopwords Removed (Row 30): ['why']\n","Stopwords were removed for Row 30 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 31): ['well']\n","Updated Tokens (Row 31): ['well']\n","Stopwords Removed (Row 31): []\n","No stopwords removed for Row 31 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 32): ['what']\n","Updated Tokens (Row 32): []\n","Stopwords Removed (Row 32): ['what']\n","Stopwords were removed for Row 32 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 33): ['well', 'i', 'planned', 'on', 'kind', 'of', 'sneaking', 'up', 'on', 'you', 'in', 'a', 'period', 'of', 'a', 'week', 'or', 'so', 'but', 'they', 'all', 'take', 'it', 'for', 'granted', 'that', 'we', 'set']\n","Updated Tokens (Row 33): ['well', 'planned', 'kind', 'sneaking', 'period', 'week', 'take', 'granted', 'set']\n","Stopwords Removed (Row 33): ['i', 'on', 'of', 'up', 'on', 'you', 'in', 'a', 'of', 'a', 'or', 'so', 'but', 'they', 'all', 'it', 'for', 'that', 'we']\n","Stopwords were removed for Row 33 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 34): ['how', 'did', 'you', 'know']\n","Updated Tokens (Row 34): ['know']\n","Stopwords Removed (Row 34): ['how', 'did', 'you']\n","Stopwords were removed for Row 34 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 35): ['well', 'so', 'would', 'you', 'want', 'to', 'i', 'mean', 'i', 'guess', 'you', 'know', 'that', 'is', 'why', 'i', 'asked', 'you', 'to', 'come']\n","Updated Tokens (Row 35): ['well', 'would', 'want', 'mean', 'guess', 'know', 'asked', 'come']\n","Stopwords Removed (Row 35): ['so', 'you', 'to', 'i', 'i', 'you', 'that', 'is', 'why', 'i', 'you', 'to']\n","Stopwords were removed for Row 35 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 36): ['annie', 'i', 'love', 'you', 'i', 'love', 'you', 'a', 'great', 'deal', 'i', 'love', 'you', '-i']\n","Updated Tokens (Row 36): ['annie', 'love', 'love', 'great', 'deal', 'love', '-i']\n","Stopwords Removed (Row 36): ['i', 'you', 'i', 'you', 'a', 'i', 'you']\n","Stopwords were removed for Row 36 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 37): ['i', 'do', 'not', 'know', 'what', 'to', 'say', 'i', 'have', 'no', 'imagination', 'that', 'is', 'all', 'i', 'have', 'to', 'say', 'to', 'you', 'god', 'i', 'embarrassing', 'you', 'i-i', 'did', 'not', 'want', 'to', 'do', 'this', 'here', 'i', 'wanted', 'to', 'do', 'it', 'someplace', 'different', 'someplace', 'where', 'we', 'could', 'be', 'new', 'to', 'each', 'other']\n","Updated Tokens (Row 37): ['know', 'say', 'imagination', 'say', 'god', 'embarrassing', 'i-i', 'want', 'wanted', 'someplace', 'different', 'someplace', 'could', 'new']\n","Stopwords Removed (Row 37): ['i', 'do', 'not', 'what', 'to', 'i', 'have', 'no', 'that', 'is', 'all', 'i', 'have', 'to', 'to', 'you', 'i', 'you', 'did', 'not', 'to', 'do', 'this', 'here', 'i', 'to', 'do', 'it', 'where', 'we', 'be', 'to', 'each', 'other']\n","Stopwords were removed for Row 37 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 38): ['you', 'feel', 'it', 'is', 'wrong', 'here', 'do', 'not', 'you', 'this', 'yard', 'this', 'chair', 'i', 'want', 'you', 'to', 'be', 'ready', 'for', 'me', 'annie', 'i', 'do', 'not', 'want', 'to', 'win', 'you', 'away', 'from', 'anything']\n","Updated Tokens (Row 38): ['feel', 'wrong', 'yard', 'chair', 'want', 'ready', 'annie', 'want', 'win', 'away', 'anything']\n","Stopwords Removed (Row 38): ['you', 'it', 'is', 'here', 'do', 'not', 'you', 'this', 'this', 'i', 'you', 'to', 'be', 'for', 'me', 'i', 'do', 'not', 'to', 'you', 'from']\n","Stopwords were removed for Row 38 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 39): ['so', 'he', 'is', 'gone', 'forever', 'then', 'you', 'sure']\n","Updated Tokens (Row 39): ['gone', 'forever', 'sure']\n","Stopwords Removed (Row 39): ['so', 'he', 'is', 'then', 'you']\n","Stopwords were removed for Row 39 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 40): ['why', 'did', 'not', 'you']\n","Updated Tokens (Row 40): []\n","Stopwords Removed (Row 40): ['why', 'did', 'not', 'you']\n","Stopwords were removed for Row 40 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 41): ['you', 'felt', 'something', 'that', 'far', 'back']\n","Updated Tokens (Row 41): ['felt', 'something', 'far', 'back']\n","Stopwords Removed (Row 41): ['you', 'that']\n","Stopwords were removed for Row 41 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 42): ['annie', 'why', 'did', 'not', 'you', 'call', 'me', 'or', 'tell', 'me']\n","Updated Tokens (Row 42): ['annie', 'call', 'tell']\n","Stopwords Removed (Row 42): ['why', 'did', 'not', 'you', 'me', 'or', 'me']\n","Stopwords were removed for Row 42 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 43): ['give', 'me', 'a', 'kiss', 'annie', 'give', 'me', 'a']\n","Updated Tokens (Row 43): ['give', 'kiss', 'annie', 'give']\n","Stopwords Removed (Row 43): ['me', 'a', 'me', 'a']\n","Stopwords were removed for Row 43 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 44): ['oh', 'god', 'i', 'kissed', 'annie', 'i', 'kissed', 'annie', 'i', 'can', 'not', 'how', 'long', 'have', 'i', 'waited', 'to', 'do', 'that']\n","Updated Tokens (Row 44): ['oh', 'god', 'kissed', 'annie', 'kissed', 'annie', 'long', 'waited']\n","Stopwords Removed (Row 44): ['i', 'i', 'i', 'can', 'not', 'how', 'have', 'i', 'to', 'do', 'that']\n","Stopwords were removed for Row 44 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 45): ['oh', 'annie', 'we', 'gon', 'na', 'live', 'now', 'i', 'going', 'to', 'make', 'you', 'so', 'happy']\n","Updated Tokens (Row 45): ['oh', 'annie', 'gon', 'na', 'live', 'going', 'make', 'happy']\n","Stopwords Removed (Row 45): ['we', 'now', 'i', 'to', 'you', 'so']\n","Stopwords were removed for Row 45 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 46): ['i', 'kissed', 'you']\n","Updated Tokens (Row 46): ['kissed']\n","Stopwords Removed (Row 46): ['i', 'you']\n","Stopwords were removed for Row 46 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 47): ['lets', 'go', 'for', 'a', 'ride', 'i', 'i', 'want', 'to', 'be', 'alone', 'with', 'you']\n","Updated Tokens (Row 47): ['lets', 'go', 'ride', 'want', 'alone']\n","Stopwords Removed (Row 47): ['for', 'a', 'i', 'i', 'to', 'be', 'with', 'you']\n","Stopwords were removed for Row 47 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 48): ['no', 'nothing', 'like', 'that']\n","Updated Tokens (Row 48): ['nothing', 'like']\n","Stopwords Removed (Row 48): ['no', 'that']\n","Stopwords were removed for Row 48 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 49): ['yeah', 'i', 'suppose', 'i', 'have', 'been', 'but', 'it', 'is', 'going', 'for', 'me']\n","Updated Tokens (Row 49): ['yeah', 'suppose', 'going']\n","Stopwords Removed (Row 49): ['i', 'i', 'have', 'been', 'but', 'it', 'is', 'for', 'me']\n","Stopwords were removed for Row 49 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 50): ['i', 'do', 'not', 'i', 'do', 'not', 'know', 'where', 'to', 'start']\n","Updated Tokens (Row 50): ['know', 'start']\n","Stopwords Removed (Row 50): ['i', 'do', 'not', 'i', 'do', 'not', 'where', 'to']\n","Stopwords were removed for Row 50 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 51): ['it', 'is', 'so', 'mixed', 'up', 'with', 'so', 'many', 'other', 'things']\n","Updated Tokens (Row 51): ['mixed', 'many', 'things']\n","Stopwords Removed (Row 51): ['it', 'is', 'so', 'up', 'with', 'so', 'other']\n","Stopwords were removed for Row 51 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 52): ['you', 'remember', 'when', 'i', 'was', 'overseas', 'i', 'was', 'in', 'command', 'of', 'a', 'company']\n","Updated Tokens (Row 52): ['remember', 'overseas', 'command', 'company']\n","Stopwords Removed (Row 52): ['you', 'when', 'i', 'was', 'i', 'was', 'in', 'of', 'a']\n","Stopwords were removed for Row 52 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 53): ['i', 'lost', 'them']\n","Updated Tokens (Row 53): ['lost']\n","Stopwords Removed (Row 53): ['i', 'them']\n","Stopwords were removed for Row 53 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 54): ['just', 'about', 'all']\n","Updated Tokens (Row 54): []\n","Stopwords Removed (Row 54): ['just', 'about', 'all']\n","Stopwords were removed for Row 54 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 55): ['it', 'takes', 'time', 'to', 'toss', 'something', 'like', 'that', 'off', 'i', 'mean', 'because', 'they', 'were', 'just', 'men']\n","Updated Tokens (Row 55): ['takes', 'time', 'toss', 'something', 'like', 'mean', 'men']\n","Stopwords Removed (Row 55): ['it', 'to', 'that', 'off', 'i', 'because', 'they', 'were', 'just']\n","Stopwords were removed for Row 55 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 56): ['for', 'instance', 'there', 'was', 'this', 'time', 'and', 'it', 'had', 'been', 'raining', 'for', 'several', 'days', 'and', 'this', 'kid', 'came', 'up', 'to', 'me', 'and', 'he', 'gave', 'me', 'his', 'last', 'pair', 'of', 'dry', 'socks', 'just', 'put', 'them', 'in', 'my', 'pocket']\n","Updated Tokens (Row 56): ['instance', 'time', 'raining', 'several', 'days', 'kid', 'came', 'gave', 'last', 'pair', 'dry', 'socks', 'put', 'pocket']\n","Stopwords Removed (Row 56): ['for', 'there', 'was', 'this', 'and', 'it', 'had', 'been', 'for', 'and', 'this', 'up', 'to', 'me', 'and', 'he', 'me', 'his', 'of', 'just', 'them', 'in', 'my']\n","Stopwords were removed for Row 56 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 57): ['i', 'know', 'it', 'is', 'it', 'is', 'just', 'a', 'little', 'thing', 'but', 'that', 'is', 'just', 'the', 'kind', 'of', 'guys', 'i', 'had', 'they', 'did', 'not', 'die', 'they', 'killed', 'themselves', 'for', 'each', 'other']\n","Updated Tokens (Row 57): ['know', 'little', 'thing', 'kind', 'guys', 'die', 'killed']\n","Stopwords Removed (Row 57): ['i', 'it', 'is', 'it', 'is', 'just', 'a', 'but', 'that', 'is', 'just', 'the', 'of', 'i', 'had', 'they', 'did', 'not', 'they', 'themselves', 'for', 'each', 'other']\n","Stopwords were removed for Row 57 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 58): ['i', 'mean', 'that', 'exactly', 'anymore', 'selfish', 'just', 'a', 'little', 'bit', 'more', 'selfish', 'and', 'they', 'would', 'have', 'been', 'here', 'today', 'and', 'it', 'gave', 'me', 'an', 'idea', 'as', 'i', 'was', 'watching', 'them', 'all', 'go', 'down']\n","Updated Tokens (Row 58): ['mean', 'exactly', 'anymore', 'selfish', 'little', 'bit', 'selfish', 'would', 'today', 'gave', 'idea', 'watching', 'go']\n","Stopwords Removed (Row 58): ['i', 'that', 'just', 'a', 'more', 'and', 'they', 'have', 'been', 'here', 'and', 'it', 'me', 'an', 'as', 'i', 'was', 'them', 'all', 'down']\n","Stopwords were removed for Row 58 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 59): ['everything', 'was', 'being', 'destroyed', 'see', 'but', 'i', 'felt', 'like', 'something', 'new', 'was', 'being', 'created', 'at', 'the', 'same', 'time', 'like', 'it', 'kind', 'of', 'responsibility', 'you', 'know', 'man', 'to', 'man', 'do', 'you', 'understand', 'what', 'i', 'saying']\n","Updated Tokens (Row 59): ['everything', 'destroyed', 'see', 'felt', 'like', 'something', 'new', 'created', 'time', 'like', 'kind', 'responsibility', 'know', 'man', 'man', 'understand', 'saying']\n","Stopwords Removed (Row 59): ['was', 'being', 'but', 'i', 'was', 'being', 'at', 'the', 'same', 'it', 'of', 'you', 'to', 'do', 'you', 'what', 'i']\n","Stopwords were removed for Row 59 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 60): ['and', 'and', 'to', 'see', 'that', 'again', 'to', 'to', 'bring', 'that', 'back', 'on', 'the', 'earth', 'again', 'like', 'like', 'a', 'monument', 'that', 'that', 'would', 'stand', 'behind', 'these', 'men', 'and', 'and', 'and', 'it', 'would', 'make', 'a', 'difference', 'to', 'them']\n","Updated Tokens (Row 60): ['see', 'bring', 'back', 'earth', 'like', 'like', 'monument', 'would', 'stand', 'behind', 'men', 'would', 'make', 'difference']\n","Stopwords Removed (Row 60): ['and', 'and', 'to', 'that', 'again', 'to', 'to', 'that', 'on', 'the', 'again', 'a', 'that', 'that', 'these', 'and', 'and', 'and', 'it', 'a', 'to', 'them']\n","Stopwords were removed for Row 60 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 61): ['it', 'was', 'and', 'then', 'i', 'went', 'home', 'and', 'it', 'was', 'incredible', 'it', 'did', 'not', 'have', 'any', 'meaning', 'there']\n","Updated Tokens (Row 61): ['went', 'home', 'incredible', 'meaning']\n","Stopwords Removed (Row 61): ['it', 'was', 'and', 'then', 'i', 'and', 'it', 'was', 'it', 'did', 'not', 'have', 'any', 'there']\n","Stopwords were removed for Row 61 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 62): ['i', 'mean', 'the', 'whole', 'thing', 'was', 'like', 'some', 'kind', 'of', 'bus', 'accident', 'to', 'them']\n","Updated Tokens (Row 62): ['mean', 'whole', 'thing', 'like', 'kind', 'bus', 'accident']\n","Stopwords Removed (Row 62): ['i', 'the', 'was', 'some', 'of', 'to', 'them']\n","Stopwords were removed for Row 62 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 63): ['so', 'i', 'went', 'back', 'to', 'work', 'for', 'my', 'dad', 'and', 'that', 'whole', 'rat', 'race', 'again']\n","Updated Tokens (Row 63): ['went', 'back', 'work', 'dad', 'whole', 'rat', 'race']\n","Stopwords Removed (Row 63): ['so', 'i', 'to', 'for', 'my', 'and', 'that', 'again']\n","Stopwords were removed for Row 63 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 64): ['i', 'felt', 'what', 'you', 'said', 'ashamed', 'somehow', 'because', 'nobody', 'had', 'changed', 'at', 'all']\n","Updated Tokens (Row 64): ['felt', 'said', 'ashamed', 'somehow', 'nobody', 'changed']\n","Stopwords Removed (Row 64): ['i', 'what', 'you', 'because', 'had', 'at', 'all']\n","Stopwords were removed for Row 64 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 65): ['it', 'seemed', 'to', 'make', 'suckers', 'out', 'of', 'so', 'many', 'guys', 'and', 'i-i', 'felt', 'wrong', 'to', 'be', 'alive', 'to', 'to', 'open', 'that', 'bank', 'book', 'to', 'to', 'drive', 'that', 'car', 'the', 'new', 'car', 'and', 'look', 'at', 'that', 'new', 'refrigerator', 'i', 'mean']\n","Updated Tokens (Row 65): ['seemed', 'make', 'suckers', 'many', 'guys', 'i-i', 'felt', 'wrong', 'alive', 'open', 'bank', 'book', 'drive', 'car', 'new', 'car', 'look', 'new', 'refrigerator', 'mean']\n","Stopwords Removed (Row 65): ['it', 'to', 'out', 'of', 'so', 'and', 'to', 'be', 'to', 'to', 'that', 'to', 'to', 'that', 'the', 'and', 'at', 'that', 'i']\n","Stopwords were removed for Row 65 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 66): ['you', 'can', 'take', 'those', 'things', 'out', 'of', 'the', 'war', 'but', 'if', 'you', 'gon', 'na', 'drive', 'that', 'car', 'you', 'have', 'got', 'to', 'know', 'that', 'that', 'came', 'from', 'the', 'love', 'a', 'man', 'can', 'have', 'from', 'a', 'man', 'and', 'you', 'have', 'got', 'to', 'be', 'a', 'little', 'bit', 'better', 'because', 'of', 'that', 'because', 'if', 'you', 'not', 'then', 'it', 'is', 'all', 'just', 'loot', 'and', 'there', 'blood', 'on', 'it', 'and', 'i', 'did', 'not', 'want', 'any', 'of', 'it']\n","Updated Tokens (Row 66): ['take', 'things', 'war', 'gon', 'na', 'drive', 'car', 'got', 'know', 'came', 'love', 'man', 'man', 'got', 'little', 'bit', 'better', 'loot', 'blood', 'want']\n","Stopwords Removed (Row 66): ['you', 'can', 'those', 'out', 'of', 'the', 'but', 'if', 'you', 'that', 'you', 'have', 'to', 'that', 'that', 'from', 'the', 'a', 'can', 'have', 'from', 'a', 'and', 'you', 'have', 'to', 'be', 'a', 'because', 'of', 'that', 'because', 'if', 'you', 'not', 'then', 'it', 'is', 'all', 'just', 'and', 'there', 'on', 'it', 'and', 'i', 'did', 'not', 'any', 'of', 'it']\n","Stopwords were removed for Row 66 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 67): ['and', 'i', 'guess', 'that', 'included', 'you']\n","Updated Tokens (Row 67): ['guess', 'included']\n","Stopwords Removed (Row 67): ['and', 'i', 'that', 'you']\n","Stopwords were removed for Row 67 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 68): ['i', 'want', 'you', 'now', 'annie']\n","Updated Tokens (Row 68): ['want', 'annie']\n","Stopwords Removed (Row 68): ['i', 'you', 'now']\n","Stopwords were removed for Row 68 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 69): ['oh', 'annie']\n","Updated Tokens (Row 69): ['oh', 'annie']\n","Stopwords Removed (Row 69): []\n","No stopwords removed for Row 69 in file Ses05M_script01_3.csv.\n","Original Tokens (Row 70): ['annie', 'i', 'am', 'going', 'to', 'make', 'you', 'a', 'fortune']\n","Updated Tokens (Row 70): ['annie', 'going', 'make', 'fortune']\n","Stopwords Removed (Row 70): ['i', 'am', 'to', 'you', 'a']\n","Stopwords were removed for Row 70 in file Ses05M_script01_3.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script01_3.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script01_3.csv\n","\n","Processing File: Ses05M_script02_2.csv\n","Original Tokens (Row 0): ['about', 'what']\n","Updated Tokens (Row 0): []\n","Stopwords Removed (Row 0): ['about', 'what']\n","Stopwords were removed for Row 0 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 1): ['it', 'is', 'ridiculous']\n","Updated Tokens (Row 1): ['ridiculous']\n","Stopwords Removed (Row 1): ['it', 'is']\n","Stopwords were removed for Row 1 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 2): ['it', 'is', 'p.r', 'somebody', 'sold', 'you', 'a', 'bill', 'of', 'goods', 'that', 'this', 'magical', 'thing', 'would', 'be', 'happening', 'on', 'the', 'beach']\n","Updated Tokens (Row 2): ['p.r', 'somebody', 'sold', 'bill', 'goods', 'magical', 'thing', 'would', 'happening', 'beach']\n","Stopwords Removed (Row 2): ['it', 'is', 'you', 'a', 'of', 'that', 'this', 'be', 'on', 'the']\n","Stopwords were removed for Row 2 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 3): ['sure', 'everybody', 'is', 'told', 'the', 'same', 'thing', 'it', 'keeps', 'us', 'all', 'excited', 'it', 'keeps', 'us', 'all', 'coming', 'back', 'for', 'more', 'it', 'keeps', 'us', 'thinking', 'that', 'life', 'is', 'gon', 'na', 'start', 'now', 'any', 'minute', 'if', 'we', 'can', 'just', 'find', 'the', 'right', 'spot', 'and', 'get', 'in', 'on', 'the', 'action']\n","Updated Tokens (Row 3): ['sure', 'everybody', 'told', 'thing', 'keeps', 'us', 'excited', 'keeps', 'us', 'coming', 'back', 'keeps', 'us', 'thinking', 'life', 'gon', 'na', 'start', 'minute', 'find', 'right', 'spot', 'get', 'action']\n","Stopwords Removed (Row 3): ['is', 'the', 'same', 'it', 'all', 'it', 'all', 'for', 'more', 'it', 'that', 'is', 'now', 'any', 'if', 'we', 'can', 'just', 'the', 'and', 'in', 'on', 'the']\n","Stopwords were removed for Row 3 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 4): ['i', 'sorry', 'it', 'is', 'just', 'it', 'is', 'it', 'is', 'just', 'fish', 'to', 'me']\n","Updated Tokens (Row 4): ['sorry', 'fish']\n","Stopwords Removed (Row 4): ['i', 'it', 'is', 'just', 'it', 'is', 'it', 'is', 'just', 'to', 'me']\n","Stopwords were removed for Row 4 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 5): ['god', 'damn', 'it', 'augie', 'seriously', 'you', 'always', 'ask', 'me', 'that', 'why', 'do', 'you', 'ask', 'me', 'that', 'i', 'hate', 'it', 'it', 'is', 'so', 'insulting']\n","Updated Tokens (Row 5): ['god', 'damn', 'augie', 'seriously', 'always', 'ask', 'ask', 'hate', 'insulting']\n","Stopwords Removed (Row 5): ['it', 'you', 'me', 'that', 'why', 'do', 'you', 'me', 'that', 'i', 'it', 'it', 'is', 'so']\n","Stopwords were removed for Row 5 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 6): ['i', 'just', 'we', 'just', 'have', 'different', 'ideas', 'of', 'what', 'this', 'night', 'is', 'suppose', 'to', 'look', 'like']\n","Updated Tokens (Row 6): ['different', 'ideas', 'night', 'suppose', 'look', 'like']\n","Stopwords Removed (Row 6): ['i', 'just', 'we', 'just', 'have', 'of', 'what', 'this', 'is', 'to']\n","Stopwords were removed for Row 6 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 7): ['for', 'god', 'sake', 'augie', 'it', 'grow', 'up', 'we', 'not', 'going', 'to', 'see', 'the', 'grunion']\n","Updated Tokens (Row 7): ['god', 'sake', 'augie', 'grow', 'going', 'see', 'grunion']\n","Stopwords Removed (Row 7): ['for', 'it', 'up', 'we', 'not', 'to', 'the']\n","Stopwords were removed for Row 7 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 8): ['we', 'we', 'do', 'not', 'ever', 'have', 'we', 'ever']\n","Updated Tokens (Row 8): ['ever', 'ever']\n","Stopwords Removed (Row 8): ['we', 'we', 'do', 'not', 'have', 'we']\n","Stopwords were removed for Row 8 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 9): ['twice', 'is', 'every', 'time', 'we', 'have', 'tried', 'that', 'is', 'ever']\n","Updated Tokens (Row 9): ['twice', 'every', 'time', 'tried', 'ever']\n","Stopwords Removed (Row 9): ['is', 'we', 'have', 'that', 'is']\n","Stopwords were removed for Row 9 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 10): ['no', 'we', 'will', 'not', 'it', 'is', 'like', 'waiting', 'up', 'for', 'santa', 'clause', 'or', 'something', 'i', 'feel', 'like', 'as', 'though', 'my', 'whole', 'life', 'is', 'going', 'to', 'be', 'standing', 'on', 'the', 'beach', 'waiting', 'with', 'my', 'eyes', 'opened', 'expectantly', 'my', 'hands', 'clasped', 'neatly', 'in', 'front', 'of', 'me', 'waiting', 'for', 'fish', 'to', 'show', 'up', 'and', 'the', 'fish', 'will', 'not', 'show', 'up']\n","Updated Tokens (Row 10): ['like', 'waiting', 'santa', 'clause', 'something', 'feel', 'like', 'though', 'whole', 'life', 'going', 'standing', 'beach', 'waiting', 'eyes', 'opened', 'expectantly', 'hands', 'clasped', 'neatly', 'front', 'waiting', 'fish', 'show', 'fish', 'show']\n","Stopwords Removed (Row 10): ['no', 'we', 'will', 'not', 'it', 'is', 'up', 'for', 'or', 'i', 'as', 'my', 'is', 'to', 'be', 'on', 'the', 'with', 'my', 'my', 'in', 'of', 'me', 'for', 'to', 'up', 'and', 'the', 'will', 'not', 'up']\n","Stopwords were removed for Row 10 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 11): ['you', 'do', 'not', 'understand', 'anything', 'i', 'am', 'saying']\n","Updated Tokens (Row 11): ['understand', 'anything', 'saying']\n","Stopwords Removed (Row 11): ['you', 'do', 'not', 'i', 'am']\n","Stopwords were removed for Row 11 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 12): ['i', 'did', 'want', 'to', 'see', 'it', 'i', 'always', 'want', 'to', 'see', 'it', 'i', 'just', 'i', 'keep', 'thinking', 'this', 'will', 'be', 'the', 'time', 'and', 'it', 'never', 'is']\n","Updated Tokens (Row 12): ['want', 'see', 'always', 'want', 'see', 'keep', 'thinking', 'time', 'never']\n","Stopwords Removed (Row 12): ['i', 'did', 'to', 'it', 'i', 'to', 'it', 'i', 'just', 'i', 'this', 'will', 'be', 'the', 'and', 'it', 'is']\n","Stopwords were removed for Row 12 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 13): ['do', 'you', 'remember', 'the', 'first', 'time', 'that', 'we', 'came', 'to', 'see', 'the', 'grunion', 'it', 'was', 'about', 'four', 'years', 'ago', 'right', 'after', 'we', 'got', 'married', 'we', 'thought', 'i', 'was', 'pregnant', 'we', 'had', 'a', 'bottle', 'of', 'champagne', 'and', 'no', 'glasses', 'you', 'asked', 'me', 'to', 'dance', 'we', 'took', 'off', 'our', 'shoes', 'and', 'while', 'we', 'were', 'dancing', 'you', 'said', 'the', 'most', 'intimate', 'things', 'to', 'me', 'right', 'in', 'my', 'ear', 'so', 'i', 'could', 'feel', 'them', 'as', 'much', 'as', 'hear', 'them']\n","Updated Tokens (Row 13): ['remember', 'first', 'time', 'came', 'see', 'grunion', 'four', 'years', 'ago', 'right', 'got', 'married', 'thought', 'pregnant', 'bottle', 'champagne', 'glasses', 'asked', 'dance', 'took', 'shoes', 'dancing', 'said', 'intimate', 'things', 'right', 'ear', 'could', 'feel', 'much', 'hear']\n","Stopwords Removed (Row 13): ['do', 'you', 'the', 'that', 'we', 'to', 'the', 'it', 'was', 'about', 'after', 'we', 'we', 'i', 'was', 'we', 'had', 'a', 'of', 'and', 'no', 'you', 'me', 'to', 'we', 'off', 'our', 'and', 'while', 'we', 'were', 'you', 'the', 'most', 'to', 'me', 'in', 'my', 'so', 'i', 'them', 'as', 'as', 'them']\n","Stopwords were removed for Row 13 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 14): ['and', 'i', 'remember', 'thinking', 'to', 'myself', 'finally', 'i', 'am', 'as', 'happy', 'as', 'i', 'am', 'supposed', 'to', 'be']\n","Updated Tokens (Row 14): ['remember', 'thinking', 'finally', 'happy', 'supposed']\n","Stopwords Removed (Row 14): ['and', 'i', 'to', 'myself', 'i', 'am', 'as', 'as', 'i', 'am', 'to', 'be']\n","Stopwords were removed for Row 14 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 15): ['dancing', 'barefoot', 'in', 'the', 'sand', 'drinking', 'champagne', 'out', 'of', 'the', 'bottle']\n","Updated Tokens (Row 15): ['dancing', 'barefoot', 'sand', 'drinking', 'champagne', 'bottle']\n","Stopwords Removed (Row 15): ['in', 'the', 'out', 'of', 'the']\n","Stopwords were removed for Row 15 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 16): ['i', 'would', 'rather', 'not', 'remember', 'some', 'things', 'i', 'rather', 'not', 'hope', 'for', 'something']\n","Updated Tokens (Row 16): ['would', 'rather', 'remember', 'things', 'rather', 'hope', 'something']\n","Stopwords Removed (Row 16): ['i', 'not', 'some', 'i', 'not', 'for']\n","Stopwords were removed for Row 16 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 17): ['no']\n","Updated Tokens (Row 17): []\n","Stopwords Removed (Row 17): ['no']\n","Stopwords were removed for Row 17 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 18): ['no']\n","Updated Tokens (Row 18): []\n","Stopwords Removed (Row 18): ['no']\n","Stopwords were removed for Row 18 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 19): ['no']\n","Updated Tokens (Row 19): []\n","Stopwords Removed (Row 19): ['no']\n","Stopwords were removed for Row 19 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 20): ['laughter', 'no']\n","Updated Tokens (Row 20): ['laughter']\n","Stopwords Removed (Row 20): ['no']\n","Stopwords were removed for Row 20 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 21): ['no']\n","Updated Tokens (Row 21): []\n","Stopwords Removed (Row 21): ['no']\n","Stopwords were removed for Row 21 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 22): ['no']\n","Updated Tokens (Row 22): []\n","Stopwords Removed (Row 22): ['no']\n","Stopwords were removed for Row 22 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 23): ['i', 'just', 'want', 'i', 'just', 'want', 'things', 'to', 'turn', 'out', 'the', 'way', 'they', 'are', 'supposed', 'to']\n","Updated Tokens (Row 23): ['want', 'want', 'things', 'turn', 'way', 'supposed']\n","Stopwords Removed (Row 23): ['i', 'just', 'i', 'just', 'to', 'out', 'the', 'they', 'are', 'to']\n","Stopwords were removed for Row 23 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 24): ['this', 'what', 'is', 'this', 'this', 'is', 'not', 'even', 'anything']\n","Updated Tokens (Row 24): ['even', 'anything']\n","Stopwords Removed (Row 24): ['this', 'what', 'is', 'this', 'this', 'is', 'not']\n","Stopwords were removed for Row 24 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 25): ['sure', 'this', 'is', 'standing', 'on', 'the', 'beach', 'this', 'is', 'waiting', 'this', 'is', 'fighting']\n","Updated Tokens (Row 25): ['sure', 'standing', 'beach', 'waiting', 'fighting']\n","Stopwords Removed (Row 25): ['this', 'is', 'on', 'the', 'this', 'is', 'this', 'is']\n","Stopwords were removed for Row 25 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 26): ['but', 'this', 'is', 'not', 'at', 'all', 'what', 'i', 'wanted', 'it', 'to', 'be']\n","Updated Tokens (Row 26): ['wanted']\n","Stopwords Removed (Row 26): ['but', 'this', 'is', 'not', 'at', 'all', 'what', 'i', 'it', 'to', 'be']\n","Stopwords were removed for Row 26 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 27): ['this', 'is', 'just', 'this', 'i', 'mean', 'it', 'is', 'a', 'lot', 'and', 'everything', 'but', 'it', 'is', 'not', 'you', 'know', 'something', 'else', 'am', 'i', 'making', 'any', 'sense']\n","Updated Tokens (Row 27): ['mean', 'lot', 'everything', 'know', 'something', 'else', 'making', 'sense']\n","Stopwords Removed (Row 27): ['this', 'is', 'just', 'this', 'i', 'it', 'is', 'a', 'and', 'but', 'it', 'is', 'not', 'you', 'am', 'i', 'any']\n","Stopwords were removed for Row 27 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 28): ['i', 'know', 'that', 'augie', 'i', 'do', 'i', 'know', 'that', 'and', 'and', 'i', 'know', 'that', 'this', 'meant', 'a', 'lot', 'to', 'you', 'and', 'and', 'it', 'is', 'special', 'you', 'know', 'with', 'the', 'sand', 'and', 'the', 'moon', 'but']\n","Updated Tokens (Row 28): ['know', 'augie', 'know', 'know', 'meant', 'lot', 'special', 'know', 'sand', 'moon']\n","Stopwords Removed (Row 28): ['i', 'that', 'i', 'do', 'i', 'that', 'and', 'and', 'i', 'that', 'this', 'a', 'to', 'you', 'and', 'and', 'it', 'is', 'you', 'with', 'the', 'and', 'the', 'but']\n","Stopwords were removed for Row 28 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 29): ['but', 'i', 'just', 'could', 'help', 'thinking', 'about', 'being', 'somewhere', 'else']\n","Updated Tokens (Row 29): ['could', 'help', 'thinking', 'somewhere', 'else']\n","Stopwords Removed (Row 29): ['but', 'i', 'just', 'about', 'being']\n","Stopwords were removed for Row 29 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 30): ['i', 'did', 'not', 'say', 'that']\n","Updated Tokens (Row 30): ['say']\n","Stopwords Removed (Row 30): ['i', 'did', 'not', 'that']\n","Stopwords were removed for Row 30 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 31): ['for', 'heavens', 'sake', 'augie', 'whatever', 'i', 'am', 'doing', 'i', 'rather', 'it', 'be', 'with', 'you']\n","Updated Tokens (Row 31): ['heavens', 'sake', 'augie', 'whatever', 'rather']\n","Stopwords Removed (Row 31): ['for', 'i', 'am', 'doing', 'i', 'it', 'be', 'with', 'you']\n","Stopwords were removed for Row 31 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 32): ['yes', 'do', 'not', 'you', 'know', 'that', 'i', 'mean', 'you', 'probably', 'the', 'one', 'you', 'wishes', 'you', 'were', 'with', 'somebody', 'else', 'somebody', 'who', 'did', 'not', 'take', 'everything', 'so', 'hard', 'and', 'who', 'knew', 'how', 'to', 'enjoy', 'herself']\n","Updated Tokens (Row 32): ['yes', 'know', 'mean', 'probably', 'one', 'wishes', 'somebody', 'else', 'somebody', 'take', 'everything', 'hard', 'knew', 'enjoy']\n","Stopwords Removed (Row 32): ['do', 'not', 'you', 'that', 'i', 'you', 'the', 'you', 'you', 'were', 'with', 'who', 'did', 'not', 'so', 'and', 'who', 'how', 'to', 'herself']\n","Stopwords were removed for Row 32 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 33): ['okay', 'well', 'we', 'in', 'the', 'wrong', 'spot', 'but', 'we', 'with', 'the', 'right', 'person']\n","Updated Tokens (Row 33): ['okay', 'well', 'wrong', 'spot', 'right', 'person']\n","Stopwords Removed (Row 33): ['we', 'in', 'the', 'but', 'we', 'with', 'the']\n","Stopwords were removed for Row 33 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 34): ['yes', 'i', 'did', 'notice', 'that', 'it', 'does', 'look', 'really', 'beautiful', 'over', 'the', 'water', 'big', 'old', 'white', 'moon']\n","Updated Tokens (Row 34): ['yes', 'notice', 'look', 'really', 'beautiful', 'water', 'big', 'old', 'white', 'moon']\n","Stopwords Removed (Row 34): ['i', 'did', 'that', 'it', 'does', 'over', 'the']\n","Stopwords were removed for Row 34 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 35): ['augie', 'you', 'brought', 'refreshments']\n","Updated Tokens (Row 35): ['augie', 'brought', 'refreshments']\n","Stopwords Removed (Row 35): ['you']\n","Stopwords were removed for Row 35 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 36): ['well', 'then', 'we', 'do', 'not', 'need', 'glasses']\n","Updated Tokens (Row 36): ['well', 'need', 'glasses']\n","Stopwords Removed (Row 36): ['then', 'we', 'do', 'not']\n","Stopwords were removed for Row 36 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 37): ['no', 'i', 'beginning', 'to', 'think', 'you', 'might', 'be', 'right', 'i', 'think', 'this', 'might', 'be', 'the', 'spot', 'after', 'all', 'augie', 'i', 'sorry']\n","Updated Tokens (Row 37): ['beginning', 'think', 'might', 'right', 'think', 'might', 'spot', 'augie', 'sorry']\n","Stopwords Removed (Row 37): ['no', 'i', 'to', 'you', 'be', 'i', 'this', 'be', 'the', 'after', 'all', 'i']\n","Stopwords were removed for Row 37 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 38): ['or', 'not']\n","Updated Tokens (Row 38): []\n","Stopwords Removed (Row 38): ['or', 'not']\n","Stopwords were removed for Row 38 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 39): ['well', 'so', 'what', 'do', 'you', 'think']\n","Updated Tokens (Row 39): ['well', 'think']\n","Stopwords Removed (Row 39): ['so', 'what', 'do', 'you']\n","Stopwords were removed for Row 39 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 40): ['what', 'i', 'was', 'just', 'saying']\n","Updated Tokens (Row 40): ['saying']\n","Stopwords Removed (Row 40): ['what', 'i', 'was', 'just']\n","Stopwords were removed for Row 40 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 41): ['it', 'certainly', 'is', 'not', 'it', 'is', 'slightly', 'exaggerated', 'scientific', 'fact']\n","Updated Tokens (Row 41): ['certainly', 'slightly', 'exaggerated', 'scientific', 'fact']\n","Stopwords Removed (Row 41): ['it', 'is', 'not', 'it', 'is']\n","Stopwords were removed for Row 41 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 42): ['i', 'not', 'the', 'only', 'one', 'look', 'at', 'all', 'these', 'people']\n","Updated Tokens (Row 42): ['one', 'look', 'people']\n","Stopwords Removed (Row 42): ['i', 'not', 'the', 'only', 'at', 'all', 'these']\n","Stopwords were removed for Row 42 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 43): ['are', 'we', 'talking', 'about', 'the', 'same', 'thing']\n","Updated Tokens (Row 43): ['talking', 'thing']\n","Stopwords Removed (Row 43): ['are', 'we', 'about', 'the', 'same']\n","Stopwords were removed for Row 43 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 44): ['uh', 'carla', 'can', 'i', 'ask', 'you', 'a', 'question', 'no', 'do', 'not', 'get', 'upset', 'but', 'are', 'you', 'having', 'your', 'period']\n","Updated Tokens (Row 44): ['uh', 'carla', 'ask', 'question', 'get', 'upset', 'period']\n","Stopwords Removed (Row 44): ['can', 'i', 'you', 'a', 'no', 'do', 'not', 'but', 'are', 'you', 'having', 'your']\n","Stopwords were removed for Row 44 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 45): ['what', 'is', 'bugging', 'you', 'then']\n","Updated Tokens (Row 45): ['bugging']\n","Stopwords Removed (Row 45): ['what', 'is', 'you', 'then']\n","Stopwords were removed for Row 45 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 46): ['it', 'is', 'not', 'that', 'complicated', 'we', 'come', 'down', 'here', 'the', 'grunions', 'arrive', 'they', 'do', 'their', 'little', 'fish', 'thing', 'we', 'say', 'ooh', 'awe', 'look', 'at', 'the', 'little', 'fish', 'and', 'then', 'they', 'go', 'home', 'and', 'we', 'go', 'home']\n","Updated Tokens (Row 46): ['complicated', 'come', 'grunions', 'arrive', 'little', 'fish', 'thing', 'say', 'ooh', 'awe', 'look', 'little', 'fish', 'go', 'home', 'go', 'home']\n","Stopwords Removed (Row 46): ['it', 'is', 'not', 'that', 'we', 'down', 'here', 'the', 'they', 'do', 'their', 'we', 'at', 'the', 'and', 'then', 'they', 'and', 'we']\n","Stopwords were removed for Row 46 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 47): ['why', 'not']\n","Updated Tokens (Row 47): []\n","Stopwords Removed (Row 47): ['why', 'not']\n","Stopwords were removed for Row 47 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 48): ['we', 'have', 'missed', 'them', 'twice', 'that', 'is', 'hardly', 'ever']\n","Updated Tokens (Row 48): ['missed', 'twice', 'hardly', 'ever']\n","Stopwords Removed (Row 48): ['we', 'have', 'them', 'that', 'is']\n","Stopwords were removed for Row 48 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 49): ['well', 'we', 'see', 'them', 'this', 'year']\n","Updated Tokens (Row 49): ['well', 'see', 'year']\n","Stopwords Removed (Row 49): ['we', 'them', 'this']\n","Stopwords were removed for Row 49 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 50): ['okey', 'they', 'are', 'just', 'fish', 'it', 'is', 'nothing', 'to', 'get', 'traumatized', 'over']\n","Updated Tokens (Row 50): ['okey', 'fish', 'nothing', 'get', 'traumatized']\n","Stopwords Removed (Row 50): ['they', 'are', 'just', 'it', 'is', 'to', 'over']\n","Stopwords were removed for Row 50 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 51): ['no', 'of', 'course', 'not']\n","Updated Tokens (Row 51): ['course']\n","Stopwords Removed (Row 51): ['no', 'of', 'not']\n","Stopwords were removed for Row 51 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 52): ['i', 'trying', 'to', 'work', 'this', 'backwards', 'but', 'i', 'can', 'not', 'seem', 'to', 'pinpoint', 'the', 'time', 'where', 'everything', 'went', 'wrong', 'here', 'okay', 'so']\n","Updated Tokens (Row 52): ['trying', 'work', 'backwards', 'seem', 'pinpoint', 'time', 'everything', 'went', 'wrong', 'okay']\n","Stopwords Removed (Row 52): ['i', 'to', 'this', 'but', 'i', 'can', 'not', 'to', 'the', 'where', 'here', 'so']\n","Stopwords were removed for Row 52 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 53): ['you', 'were', 'fine', 'on', 'the', 'phone', 'call', 'with', 'marge', 'eating', 'dinner', 'was', 'fine', 'talking', 'uh', 'washing', 'the', 'dishes', 'no', 'problem', 'all', 'right', 'so', 'i', 'taking', 'a', 'shower', 'you', 'watching', 'tv', 'the', 'news', 'and', 'you', 'say', 'the', 'grunions', 'are', 'running', 'tonight', 'and', 'i', 'say', 'great', 'let', 'go', 'i', 'feeling', 'lucky', 'and', 'so', 'all', 'right', 'and', 'i', 'putting', 'on', 'my', 'coat', 'i', 'putting', 'out', 'the', 'animals', 'i', 'pulling', 'the', 'car', 'out', 'of', 'the', 'garage']\n","Updated Tokens (Row 53): ['fine', 'phone', 'call', 'marge', 'eating', 'dinner', 'fine', 'talking', 'uh', 'washing', 'dishes', 'problem', 'right', 'taking', 'shower', 'watching', 'tv', 'news', 'say', 'grunions', 'running', 'tonight', 'say', 'great', 'let', 'go', 'feeling', 'lucky', 'right', 'putting', 'coat', 'putting', 'animals', 'pulling', 'car', 'garage']\n","Stopwords Removed (Row 53): ['you', 'were', 'on', 'the', 'with', 'was', 'the', 'no', 'all', 'so', 'i', 'a', 'you', 'the', 'and', 'you', 'the', 'are', 'and', 'i', 'i', 'and', 'so', 'all', 'and', 'i', 'on', 'my', 'i', 'out', 'the', 'i', 'the', 'out', 'of', 'the']\n","Stopwords were removed for Row 53 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 54): ['wait', 'a', 'minute', 'i', 'got', 'it']\n","Updated Tokens (Row 54): ['wait', 'minute', 'got']\n","Stopwords Removed (Row 54): ['a', 'i', 'it']\n","Stopwords were removed for Row 54 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 55): ['it', 'was', 'in', 'the', 'car', 'right', 'when', 'we', 'were', 'passing', 'knickerbocker', 'liquor', 'locker', 'you', 'said', 'let', 'stop', 'and', 'get', 'champagne', 'and', 'i', 'said', 'that', 'times', 'a', 'wasting', 'or', 'something', 'like', 'that', 'right', 'you', 'wanted', 'it', 'to', 'be', 'like', 'it', 'was', 'before', 'right']\n","Updated Tokens (Row 55): ['car', 'right', 'passing', 'knickerbocker', 'liquor', 'locker', 'said', 'let', 'stop', 'get', 'champagne', 'said', 'times', 'wasting', 'something', 'like', 'right', 'wanted', 'like', 'right']\n","Stopwords Removed (Row 55): ['it', 'was', 'in', 'the', 'when', 'we', 'were', 'you', 'and', 'and', 'i', 'that', 'a', 'or', 'that', 'you', 'it', 'to', 'be', 'it', 'was', 'before']\n","Stopwords were removed for Row 55 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 56): ['okay', 'all', 'right', 'no', 'problem', 'i', 'totally', 'understand', 'okey', 'um', 'listen', 'do', 'you', 'want', 'to', 'dance']\n","Updated Tokens (Row 56): ['okay', 'right', 'problem', 'totally', 'understand', 'okey', 'um', 'listen', 'want', 'dance']\n","Stopwords Removed (Row 56): ['all', 'no', 'i', 'do', 'you', 'to']\n","Stopwords were removed for Row 56 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 57): ['do', 'you', 'want', 'me', 'to', 'go', 'get', 'some', 'champagne']\n","Updated Tokens (Row 57): ['want', 'go', 'get', 'champagne']\n","Stopwords Removed (Row 57): ['do', 'you', 'me', 'to', 'some']\n","Stopwords were removed for Row 57 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 58): ['take', 'off', 'our', 'shoes']\n","Updated Tokens (Row 58): ['take', 'shoes']\n","Stopwords Removed (Row 58): ['off', 'our']\n","Stopwords were removed for Row 58 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 59): ['what', 'you', 'want', 'me', 'to', 'blow', 'in', 'your', 'ear']\n","Updated Tokens (Row 59): ['want', 'blow', 'ear']\n","Stopwords Removed (Row 59): ['what', 'you', 'me', 'to', 'in', 'your']\n","Stopwords were removed for Row 59 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 60): ['do', 'you', 'want', 'to', 'get', 'married', 'again', 'what', 'what', 'do', 'you', 'want', 'a', 'divorce']\n","Updated Tokens (Row 60): ['want', 'get', 'married', 'want', 'divorce']\n","Stopwords Removed (Row 60): ['do', 'you', 'to', 'again', 'what', 'what', 'do', 'you', 'a']\n","Stopwords were removed for Row 60 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 61): ['a', 'vacation']\n","Updated Tokens (Row 61): ['vacation']\n","Stopwords Removed (Row 61): ['a']\n","Stopwords were removed for Row 61 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 62): ['a', 'poodle', 'a', 'backrub', 'a', 'spa', 'a', 'suicide', 'pack', 'what', 'carla', 'what', 'the', 'hell', 'do', 'you', 'want']\n","Updated Tokens (Row 62): ['poodle', 'backrub', 'spa', 'suicide', 'pack', 'carla', 'hell', 'want']\n","Stopwords Removed (Row 62): ['a', 'a', 'a', 'a', 'what', 'what', 'the', 'do', 'you']\n","Stopwords were removed for Row 62 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 63): ['well', 'welcome', 'to', 'the', 'human', 'race', 'do', 'you', 'think', 'this', 'is', 'what', 'i', 'had', 'planned', 'do', 'you', 'think', 'that', 'when', 'i', 'proposed', 'that', 'i', 'had', 'this', 'great', 'fantasy', 'going', 'that', 'four', 'years', 'down', 'the', 'road', 'we', 'would', 'end', 'up', 'arguing', 'on', 'the', 'beach', 'over', 'some', 'fish']\n","Updated Tokens (Row 63): ['well', 'welcome', 'human', 'race', 'think', 'planned', 'think', 'proposed', 'great', 'fantasy', 'going', 'four', 'years', 'road', 'would', 'end', 'arguing', 'beach', 'fish']\n","Stopwords Removed (Row 63): ['to', 'the', 'do', 'you', 'this', 'is', 'what', 'i', 'had', 'do', 'you', 'that', 'when', 'i', 'that', 'i', 'had', 'this', 'that', 'down', 'the', 'we', 'up', 'on', 'the', 'over', 'some']\n","Stopwords were removed for Row 63 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 64): ['do', 'you', 'think', 'that', 'i', 'thought', 'there', 'would', 'be', 'times', 'when', 'you', 'would', 'look', 'at', 'me', 'like', 'i', 'was', 'used', 'kleenex', 'or', 'i', 'would', 'look', 'at', 'you', 'and', 'think', 'good', 'god', 'when', 'the', 'next', 'flight', 'to', 'alaska', 'no', 'no', 'i', 'just', 'like', 'you', 'i', 'thought', 'it', 'would', 'all', 'be', 'like', 'peaches', 'and', 'roses', 'and', 'sand', 'in', 'our', 'toes', 'and', 'wind', 'in', 'our', 'hair', 'and', 'the', 'fish', 'would', 'always', 'come', 'and', 'the', 'bills', 'would', 'magically', 'pay', 'themselves', 'and', 'we', 'have', 'three', 'fat', 'rosy', 'kids', 'but', 'ha', 'ha', 'baby', 'the', 'jokes', 'on', 'us']\n","Updated Tokens (Row 64): ['think', 'thought', 'would', 'times', 'would', 'look', 'like', 'used', 'kleenex', 'would', 'look', 'think', 'good', 'god', 'next', 'flight', 'alaska', 'like', 'thought', 'would', 'like', 'peaches', 'roses', 'sand', 'toes', 'wind', 'hair', 'fish', 'would', 'always', 'come', 'bills', 'would', 'magically', 'pay', 'three', 'fat', 'rosy', 'kids', 'ha', 'ha', 'baby', 'jokes', 'us']\n","Stopwords Removed (Row 64): ['do', 'you', 'that', 'i', 'there', 'be', 'when', 'you', 'at', 'me', 'i', 'was', 'or', 'i', 'at', 'you', 'and', 'when', 'the', 'to', 'no', 'no', 'i', 'just', 'you', 'i', 'it', 'all', 'be', 'and', 'and', 'in', 'our', 'and', 'in', 'our', 'and', 'the', 'and', 'the', 'themselves', 'and', 'we', 'have', 'but', 'the', 'on']\n","Stopwords were removed for Row 64 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 65): ['because', 'you', 'know', 'what', 'you', 'get', 'carla', 'you', 'know', 'what', 'you', 'get', 'this']\n","Updated Tokens (Row 65): ['know', 'get', 'carla', 'know', 'get']\n","Stopwords Removed (Row 65): ['because', 'you', 'what', 'you', 'you', 'what', 'you', 'this']\n","Stopwords were removed for Row 65 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 66): ['yes', 'it', 'is']\n","Updated Tokens (Row 66): ['yes']\n","Stopwords Removed (Row 66): ['it', 'is']\n","Stopwords were removed for Row 66 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 67): ['right']\n","Updated Tokens (Row 67): ['right']\n","Stopwords Removed (Row 67): []\n","No stopwords removed for Row 67 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 68): ['now', 'i', 'know', 'me', 'either']\n","Updated Tokens (Row 68): ['know', 'either']\n","Stopwords Removed (Row 68): ['now', 'i', 'me']\n","Stopwords were removed for Row 68 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 69): ['i', 'trying', 'the', 'best', 'i', 'can']\n","Updated Tokens (Row 69): ['trying', 'best']\n","Stopwords Removed (Row 69): ['i', 'the', 'i', 'can']\n","Stopwords were removed for Row 69 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 70): ['maybe', 'if', 'you', 'with', 'somebody', 'else', 'too']\n","Updated Tokens (Row 70): ['maybe', 'somebody', 'else']\n","Stopwords Removed (Row 70): ['if', 'you', 'with', 'too']\n","Stopwords were removed for Row 70 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 71): ['no', 'i', 'know', 'but', 'i', 'know', 'i', 'do', 'not', 'make', 'you', 'happy']\n","Updated Tokens (Row 71): ['know', 'know', 'make', 'happy']\n","Stopwords Removed (Row 71): ['no', 'i', 'but', 'i', 'i', 'do', 'not', 'you']\n","Stopwords were removed for Row 71 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 72): ['really']\n","Updated Tokens (Row 72): ['really']\n","Stopwords Removed (Row 72): []\n","No stopwords removed for Row 72 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 73): ['actually', 'now', 'that', 'you', 'mention', 'it', 'no', 'i', 'do', 'not']\n","Updated Tokens (Row 73): ['actually', 'mention']\n","Stopwords Removed (Row 73): ['now', 'that', 'you', 'it', 'no', 'i', 'do', 'not']\n","Stopwords were removed for Row 73 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 74): ['i', 'do', 'not', 'know', 'i', 'think', 'this', 'is', 'a', 'pretty', 'good', 'spot', 'i', 'mean', 'look', 'at', 'the', 'view', 'of', 'the', 'moon', 'from', 'here']\n","Updated Tokens (Row 74): ['know', 'think', 'pretty', 'good', 'spot', 'mean', 'look', 'view', 'moon']\n","Stopwords Removed (Row 74): ['i', 'do', 'not', 'i', 'this', 'is', 'a', 'i', 'at', 'the', 'of', 'the', 'from', 'here']\n","Stopwords were removed for Row 74 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 75): ['oh', 'well', 'look', 'what', 'we', 'have', 'got', 'here']\n","Updated Tokens (Row 75): ['oh', 'well', 'look', 'got']\n","Stopwords Removed (Row 75): ['what', 'we', 'have', 'here']\n","Stopwords were removed for Row 75 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 76): ['well', 'it', 'is', 'not', 'champagne']\n","Updated Tokens (Row 76): ['well', 'champagne']\n","Stopwords Removed (Row 76): ['it', 'is', 'not']\n","Stopwords were removed for Row 76 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 77): ['are', 'you', 'still', 'cold', 'still', 'want', 'to', 'go', 'home']\n","Updated Tokens (Row 77): ['still', 'cold', 'still', 'want', 'go', 'home']\n","Stopwords Removed (Row 77): ['are', 'you', 'to']\n","Stopwords were removed for Row 77 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 78): ['shh', 'if', 'we', 'really', 'quiet', 'the', 'fish', 'might', 'come']\n","Updated Tokens (Row 78): ['shh', 'really', 'quiet', 'fish', 'might', 'come']\n","Stopwords Removed (Row 78): ['if', 'we', 'the']\n","Stopwords were removed for Row 78 in file Ses05M_script02_2.csv.\n","Original Tokens (Row 79): ['or', 'not']\n","Updated Tokens (Row 79): []\n","Stopwords Removed (Row 79): ['or', 'not']\n","Stopwords were removed for Row 79 in file Ses05M_script02_2.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script02_2.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script02_2.csv\n","\n","Processing File: Ses05M_script02_1.csv\n","Original Tokens (Row 0): ['fine']\n","Updated Tokens (Row 0): ['fine']\n","Stopwords Removed (Row 0): []\n","No stopwords removed for Row 0 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 1): ['what', 'flashlight']\n","Updated Tokens (Row 1): ['flashlight']\n","Stopwords Removed (Row 1): ['what']\n","Stopwords were removed for Row 1 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 2): ['you', 'mean', 'our', 'flashlight']\n","Updated Tokens (Row 2): ['mean', 'flashlight']\n","Stopwords Removed (Row 2): ['you', 'our']\n","Stopwords were removed for Row 2 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 3): ['i', 'mean', 'you', 'kept', 'saying', 'my', 'flashlight', 'the', 'flashlight', 'like', 'it', 'was', 'only', 'somehow', 'yours', 'how', 'is', 'that', 'supposed', 'to', 'make', 'me', 'feel']\n","Updated Tokens (Row 3): ['mean', 'kept', 'saying', 'flashlight', 'flashlight', 'like', 'somehow', 'supposed', 'make', 'feel']\n","Stopwords Removed (Row 3): ['i', 'you', 'my', 'the', 'it', 'was', 'only', 'yours', 'how', 'is', 'that', 'to', 'me']\n","Stopwords were removed for Row 3 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 4): ['yes']\n","Updated Tokens (Row 4): ['yes']\n","Stopwords Removed (Row 4): []\n","No stopwords removed for Row 4 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 5): ['i', 'cold']\n","Updated Tokens (Row 5): ['cold']\n","Stopwords Removed (Row 5): ['i']\n","Stopwords were removed for Row 5 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 6): ['it', 'is', 'after', 'eleven', 'let', 'just', 'go', 'home']\n","Updated Tokens (Row 6): ['eleven', 'let', 'go', 'home']\n","Stopwords Removed (Row 6): ['it', 'is', 'after', 'just']\n","Stopwords were removed for Row 6 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 7): ['there', 'is', 'no', 'point', 'in', 'coming', 'out', 'here']\n","Updated Tokens (Row 7): ['point', 'coming']\n","Stopwords Removed (Row 7): ['there', 'is', 'no', 'in', 'out', 'here']\n","Stopwords were removed for Row 7 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 8): ['that', 'is', 'my', 'point']\n","Updated Tokens (Row 8): ['point']\n","Stopwords Removed (Row 8): ['that', 'is', 'my']\n","Stopwords were removed for Row 8 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 9): ['so', 'let', 'go']\n","Updated Tokens (Row 9): ['let', 'go']\n","Stopwords Removed (Row 9): ['so']\n","Stopwords were removed for Row 9 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 10): ['not', 'particularly']\n","Updated Tokens (Row 10): ['particularly']\n","Stopwords Removed (Row 10): ['not']\n","Stopwords were removed for Row 10 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 11): ['i', 'just', 'do', 'not']\n","Updated Tokens (Row 11): []\n","Stopwords Removed (Row 11): ['i', 'just', 'do', 'not']\n","Stopwords were removed for Row 11 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 12): ['it', 'is', 'stupid']\n","Updated Tokens (Row 12): ['stupid']\n","Stopwords Removed (Row 12): ['it', 'is']\n","Stopwords were removed for Row 12 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 13): ['pass', 'what', 'up', 'it', 'is', 'it', 'is', 'just', 'little', 'fish', 'and', 'they', 'swim', 'up', 'on', 'the', 'beach', 'and', 'they', 'flop', 'around', 'and', 'they', 'swim', 'away', 'and', 'then', 'they', 'die']\n","Updated Tokens (Row 13): ['pass', 'little', 'fish', 'swim', 'beach', 'flop', 'around', 'swim', 'away', 'die']\n","Stopwords Removed (Row 13): ['what', 'up', 'it', 'is', 'it', 'is', 'just', 'and', 'they', 'up', 'on', 'the', 'and', 'they', 'and', 'they', 'and', 'then', 'they']\n","Stopwords were removed for Row 13 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 14): ['what', 'are', 'you', 'so', 'excited', 'about', 'this', 'is', 'not', 'rocket', 'science', 'this', 'is', 'just', 'fish', 'fish', 'nobody', 'even', 'eats']\n","Updated Tokens (Row 14): ['excited', 'rocket', 'science', 'fish', 'fish', 'nobody', 'even', 'eats']\n","Stopwords Removed (Row 14): ['what', 'are', 'you', 'so', 'about', 'this', 'is', 'not', 'this', 'is', 'just']\n","Stopwords were removed for Row 14 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 15): ['augie']\n","Updated Tokens (Row 15): ['augie']\n","Stopwords Removed (Row 15): []\n","No stopwords removed for Row 15 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 16): ['i', 'just', 'not']\n","Updated Tokens (Row 16): []\n","Stopwords Removed (Row 16): ['i', 'just', 'not']\n","Stopwords were removed for Row 16 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 17): ['yes']\n","Updated Tokens (Row 17): ['yes']\n","Stopwords Removed (Row 17): []\n","No stopwords removed for Row 17 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 18): ['well', 'if', 'you', 'also', 'remember', 'last', 'year', 'our', 'shoes', 'got', 'wet', 'i', 'got', 'sand', 'in', 'my', 'panties', 'we', 'had', 'a', 'big', 'argument', 'you', 'had', 'a', 'sore', 'throat', 'and', 'we', 'did', 'not', 'see', 'the', 'grunion']\n","Updated Tokens (Row 18): ['well', 'also', 'remember', 'last', 'year', 'shoes', 'got', 'wet', 'got', 'sand', 'panties', 'big', 'argument', 'sore', 'throat', 'see', 'grunion']\n","Stopwords Removed (Row 18): ['if', 'you', 'our', 'i', 'in', 'my', 'we', 'had', 'a', 'you', 'had', 'a', 'and', 'we', 'did', 'not', 'the']\n","Stopwords were removed for Row 18 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 19): ['we', 'did', 'not', 'see', 'them', 'the', 'first', 'time', 'either']\n","Updated Tokens (Row 19): ['see', 'first', 'time', 'either']\n","Stopwords Removed (Row 19): ['we', 'did', 'not', 'them', 'the']\n","Stopwords were removed for Row 19 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 20): ['that', 'is', 'the', 'wind']\n","Updated Tokens (Row 20): ['wind']\n","Stopwords Removed (Row 20): ['that', 'is', 'the']\n","Stopwords were removed for Row 20 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 21): ['what', 'time', 'is', 'it', 'they', 'are', 'supposed', 'to', 'run', 'around', 'midnight', 'oh', 'this', 'is', 'great', 'is', 'not', 'it', 'look', 'at', 'the', 'night', 'we', 'have', 'got', 'here', 'it', 'could', 'be', 'better', 'actually', 'i', 'wanted', 'to', 'go', 'a', 'little', 'further', 'up', 'the', 'coast', 'you', 'know', 'to', 'get', 'away', 'from', 'all', 'the', 'lights', 'and', 'the', 'people', 'i', 'was', 'afraid', 'we', 'might', 'miss', 'it', 'though', 'so', 'how', 'are', 'you', 'doing']\n","Updated Tokens (Row 21): ['time', 'supposed', 'run', 'around', 'midnight', 'oh', 'great', 'look', 'night', 'got', 'could', 'better', 'actually', 'wanted', 'go', 'little', 'coast', 'know', 'get', 'away', 'lights', 'people', 'afraid', 'might', 'miss', 'though']\n","Stopwords Removed (Row 21): ['what', 'is', 'it', 'they', 'are', 'to', 'this', 'is', 'is', 'not', 'it', 'at', 'the', 'we', 'have', 'here', 'it', 'be', 'i', 'to', 'a', 'further', 'up', 'the', 'you', 'to', 'from', 'all', 'the', 'and', 'the', 'i', 'was', 'we', 'it', 'so', 'how', 'are', 'you', 'doing']\n","Stopwords were removed for Row 21 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 22): ['what', 'is', 'that', 'is', 'that', 'wait', 'is', 'that', 'foam', 'i', 'can', 'not', 'even', 'tell', 'oh', 'actually', 'i', 'guess', 'if', 'i', 'can', 'not', 'tell', 'then', 'it', 'probably', 'is', 'not', 'it', 'is', 'it', 'it', 'will', 'probably', 'be', 'unmistakable', 'do', 'not', 'you', 'think']\n","Updated Tokens (Row 22): ['wait', 'foam', 'even', 'tell', 'oh', 'actually', 'guess', 'tell', 'probably', 'probably', 'unmistakable', 'think']\n","Stopwords Removed (Row 22): ['what', 'is', 'that', 'is', 'that', 'is', 'that', 'i', 'can', 'not', 'i', 'if', 'i', 'can', 'not', 'then', 'it', 'is', 'not', 'it', 'is', 'it', 'it', 'will', 'be', 'do', 'not', 'you']\n","Stopwords were removed for Row 22 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 23): ['this', 'is', 'great', 'how', 'are', 'you', 'doing', 'oh', 'no', 'oh', 'do', 'you', 'know', 'what', 'i', 'did', 'i', 'forgot', 'the', 'flashlight', 'how', 'could', 'i', 'be', 'so', 'stupid', 'i', 'forgot', 'the', 'flashlight']\n","Updated Tokens (Row 23): ['great', 'oh', 'oh', 'know', 'forgot', 'flashlight', 'could', 'stupid', 'forgot', 'flashlight']\n","Stopwords Removed (Row 23): ['this', 'is', 'how', 'are', 'you', 'doing', 'no', 'do', 'you', 'what', 'i', 'did', 'i', 'the', 'how', 'i', 'be', 'so', 'i', 'the']\n","Stopwords were removed for Row 23 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 24): ['the', 'flashlight', 'the', 'silver', 'one', 'there', 'only', 'one', 'is', 'not', 'there', 'stupid']\n","Updated Tokens (Row 24): ['flashlight', 'silver', 'one', 'one', 'stupid']\n","Stopwords Removed (Row 24): ['the', 'the', 'there', 'only', 'is', 'not', 'there']\n","Stopwords were removed for Row 24 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 25): ['well']\n","Updated Tokens (Row 25): ['well']\n","Stopwords Removed (Row 25): []\n","No stopwords removed for Row 25 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 26): ['oh', 'no', 'of', 'course', 'our', 'flashlight', 'me', 'flashlight', 'is', 'to', 'you', 'flashlight', 'naturally']\n","Updated Tokens (Row 26): ['oh', 'course', 'flashlight', 'flashlight', 'flashlight', 'naturally']\n","Stopwords Removed (Row 26): ['no', 'of', 'our', 'me', 'is', 'to', 'you']\n","Stopwords were removed for Row 26 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 27): ['how', 'could', 'we', 'have', 'forgotten', 'it', 'well', 'i', 'hope', 'the', 'moon', 'stays', 'out', 'i', 'wonder', 'do', 'they', 'always', 'run', 'during', 'a', 'full', 'moon', 'i', 'can', 'not', 'remember', 'was', 'the', 'moon', 'full', 'last', 'year', 'do', 'you', 'remember']\n","Updated Tokens (Row 27): ['could', 'forgotten', 'well', 'hope', 'moon', 'stays', 'wonder', 'always', 'run', 'full', 'moon', 'remember', 'moon', 'full', 'last', 'year', 'remember']\n","Stopwords Removed (Row 27): ['how', 'we', 'have', 'it', 'i', 'the', 'out', 'i', 'do', 'they', 'during', 'a', 'i', 'can', 'not', 'was', 'the', 'do', 'you']\n","Stopwords were removed for Row 27 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 28): ['are', 'you', 'cold', 'do', 'you', 'want', 'my', 'jacket', 'we', 'should', 'have', 'brought', 'the', 'blanket', 'our', 'blanket', 'oh', 'this', 'is', 'great', 'i', 'did', 'not', 'even', 'think', 'to', 'bring', 'a', 'six', 'pack', 'oh', 'a', 'six', 'pack', 'would', 'be', 'just', 'the', 'ticket', 'right', 'about', 'now']\n","Updated Tokens (Row 28): ['cold', 'want', 'jacket', 'brought', 'blanket', 'blanket', 'oh', 'great', 'even', 'think', 'bring', 'six', 'pack', 'oh', 'six', 'pack', 'would', 'ticket', 'right']\n","Stopwords Removed (Row 28): ['are', 'you', 'do', 'you', 'my', 'we', 'should', 'have', 'the', 'our', 'this', 'is', 'i', 'did', 'not', 'to', 'a', 'a', 'be', 'just', 'the', 'about', 'now']\n","Stopwords were removed for Row 28 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 29): ['i', 'can', 'not', 'believe', 'i', 'forgot.i', 'like', 'a', 'little', 'kid', 'i', 'surprised', 'i', 'made', 'it', 'out', 'of', 'the', 'house', 'with', 'my', 'fly', 'zipped', 'oh', 'laughter']\n","Updated Tokens (Row 29): ['believe', 'forgot.i', 'like', 'little', 'kid', 'surprised', 'made', 'house', 'fly', 'zipped', 'oh', 'laughter']\n","Stopwords Removed (Row 29): ['i', 'can', 'not', 'i', 'a', 'i', 'i', 'it', 'out', 'of', 'the', 'with', 'my']\n","Stopwords were removed for Row 29 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 30): ['oh', 'i', 'wonder', 'if', 'they', 'can', 'hear', 'me', 'or', 'if', 'they', 'can', 'feel', 'the', 'vibrations', 'when', 'we', 'move', 'around', 'in', 'the', 'sand', 'or', 'something']\n","Updated Tokens (Row 30): ['oh', 'wonder', 'hear', 'feel', 'vibrations', 'move', 'around', 'sand', 'something']\n","Stopwords Removed (Row 30): ['i', 'if', 'they', 'can', 'me', 'or', 'if', 'they', 'can', 'the', 'when', 'we', 'in', 'the', 'or']\n","Stopwords were removed for Row 30 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 31): ['do', 'you', 'want', 'my', 'jacket']\n","Updated Tokens (Row 31): ['want', 'jacket']\n","Stopwords Removed (Row 31): ['do', 'you', 'my']\n","Stopwords were removed for Row 31 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 32): ['are', 'you', 'kidding', 'we', 'just', 'got', 'here', 'we', 'miss', 'it', 'what', 'is', 'the', 'point', 'of', 'coming', 'all', 'the', 'way', 'out', 'here', 'if', 'we', 'just', 'going', 'to', 'turn', 'around', 'and', 'go', 'home']\n","Updated Tokens (Row 32): ['kidding', 'got', 'miss', 'point', 'coming', 'way', 'going', 'turn', 'around', 'go', 'home']\n","Stopwords Removed (Row 32): ['are', 'you', 'we', 'just', 'here', 'we', 'it', 'what', 'is', 'the', 'of', 'all', 'the', 'out', 'here', 'if', 'we', 'just', 'to', 'and']\n","Stopwords were removed for Row 32 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 33): ['right']\n","Updated Tokens (Row 33): ['right']\n","Stopwords Removed (Row 33): []\n","No stopwords removed for Row 33 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 34): ['that', 'is', 'my', 'point', 'too']\n","Updated Tokens (Row 34): ['point']\n","Stopwords Removed (Row 34): ['that', 'is', 'my', 'too']\n","Stopwords were removed for Row 34 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 35): ['oh', 'no', 'no', 'no', 'no', 'that', 'is', 'not', 'my', 'point', 'my', 'point', 'is', 'what', 'is', 'the', 'point', 'coming', 'out', 'here', 'if', 'we', 'just', 'going', 'to', 'leave', 'do', 'not', 'you', 'want', 'to', 'see', 'it']\n","Updated Tokens (Row 35): ['oh', 'point', 'point', 'point', 'coming', 'going', 'leave', 'want', 'see']\n","Stopwords Removed (Row 35): ['no', 'no', 'no', 'no', 'that', 'is', 'not', 'my', 'my', 'is', 'what', 'is', 'the', 'out', 'here', 'if', 'we', 'just', 'to', 'do', 'not', 'you', 'to', 'it']\n","Stopwords were removed for Row 35 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 36): ['why', 'not']\n","Updated Tokens (Row 36): []\n","Stopwords Removed (Row 36): ['why', 'not']\n","Stopwords were removed for Row 36 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 37): ['oh']\n","Updated Tokens (Row 37): ['oh']\n","Stopwords Removed (Row 37): []\n","No stopwords removed for Row 37 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 38): ['honey', 'it', 'is', 'a', 'natural', 'phenomenon', 'i', 'mean', 'this', 'kind', 'of', 'thing', 'only', 'happens', 'once', 'a', 'year', 'it', 'is', 'a', 'great', 'opportunity']\n","Updated Tokens (Row 38): ['honey', 'natural', 'phenomenon', 'mean', 'kind', 'thing', 'happens', 'year', 'great', 'opportunity']\n","Stopwords Removed (Row 38): ['it', 'is', 'a', 'i', 'this', 'of', 'only', 'once', 'a', 'it', 'is', 'a']\n","Stopwords were removed for Row 38 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 39): ['i', 'mean', 'think', 'about', 'people', 'in', 'kansas', 'they', 'have', 'got', 'to', 'get', 'like', 'you', 'know', 'plane', 'tickets', 'and', 'hotel', 'reservations', 'just', 'to', 'see', 'this', 'we', 'just', 'forty', 'minutes', 'away', 'it', 'is', 'just', 'too', 'good', 'of', 'an', 'opportunity', 'to', 'pass', 'up']\n","Updated Tokens (Row 39): ['mean', 'think', 'people', 'kansas', 'got', 'get', 'like', 'know', 'plane', 'tickets', 'hotel', 'reservations', 'see', 'forty', 'minutes', 'away', 'good', 'opportunity', 'pass']\n","Stopwords Removed (Row 39): ['i', 'about', 'in', 'they', 'have', 'to', 'you', 'and', 'just', 'to', 'this', 'we', 'just', 'it', 'is', 'just', 'too', 'of', 'an', 'to', 'up']\n","Stopwords were removed for Row 39 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 40): ['yeah', 'but', 'all', 'that', 'time', 'on', 'the', 'beach', 'is', 'the', 'highlight', 'of', 'their', 'little', 'lives', 'you', 'know']\n","Updated Tokens (Row 40): ['yeah', 'time', 'beach', 'highlight', 'little', 'lives', 'know']\n","Stopwords Removed (Row 40): ['but', 'all', 'that', 'on', 'the', 'is', 'the', 'of', 'their', 'you']\n","Stopwords were removed for Row 40 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 41): ['and', 'all', 'that', 'about', 'flopping', 'around', 'it', 'is', 'like', 'laying', 'eggs', 'or', 'what', 'do', 'you', 'spawning', 'or', 'mating', 'or', 'something', 'like', 'that']\n","Updated Tokens (Row 41): ['flopping', 'around', 'like', 'laying', 'eggs', 'spawning', 'mating', 'something', 'like']\n","Stopwords Removed (Row 41): ['and', 'all', 'that', 'about', 'it', 'is', 'or', 'what', 'do', 'you', 'or', 'or', 'that']\n","Stopwords were removed for Row 41 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 42): ['i', 'mean', 'this', 'is', 'a', 'big', 'night', 'for', 'these', 'guys', 'you', 'know', 'life', 'last', 'orgy']\n","Updated Tokens (Row 42): ['mean', 'big', 'night', 'guys', 'know', 'life', 'last', 'orgy']\n","Stopwords Removed (Row 42): ['i', 'this', 'is', 'a', 'for', 'these', 'you']\n","Stopwords were removed for Row 42 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 43): ['yeah', 'they', 'do']\n","Updated Tokens (Row 43): ['yeah']\n","Stopwords Removed (Row 43): ['they', 'do']\n","Stopwords were removed for Row 43 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 44): ['all', 'right', 'but', 'they', 'are', 'fish', 'that', 'do', 'something', 'no', 'other', 'fish', 'do', 'like', 'the', 'swallows', 'were', 'turning', 'into', 'capistrano', 'or', 'lemmings', 'jumping', 'off', 'the', 'cliffs', 'you', 'know', 'like', 'that', \"there's\", 'there', 'magic', 'here', 'and', 'mystery', 'and', 'a', 'little', 'bit', 'of', 'the', 'unexplainable', 'you', 'know', 'i', 'can', 'not', 'see', 'how', 'you', 'could', 'not', 'be', 'interested']\n","Updated Tokens (Row 44): ['right', 'fish', 'something', 'fish', 'like', 'swallows', 'turning', 'capistrano', 'lemmings', 'jumping', 'cliffs', 'know', 'like', \"there's\", 'magic', 'mystery', 'little', 'bit', 'unexplainable', 'know', 'see', 'could', 'interested']\n","Stopwords Removed (Row 44): ['all', 'but', 'they', 'are', 'that', 'do', 'no', 'other', 'do', 'the', 'were', 'into', 'or', 'off', 'the', 'you', 'that', 'there', 'here', 'and', 'and', 'a', 'of', 'the', 'you', 'i', 'can', 'not', 'how', 'you', 'not', 'be']\n","Stopwords were removed for Row 44 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 45): ['for', 'real']\n","Updated Tokens (Row 45): ['real']\n","Stopwords Removed (Row 45): ['for']\n","Stopwords were removed for Row 45 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 46): ['i', 'do', 'not', 'get', 'it', 'i', 'mean', 'the', 'first', 'time', 'we', 'came', 'you', 'said', 'it', 'was', 'the', 'best', 'night', 'of', 'your', 'life', 'and', 'last', 'year', 'i', 'remember', 'distinctly', 'you', 'were', 'so', 'excited', 'about', 'coming', 'that', 'you', 'stubbed', 'your', 'toe', 'toe', 'pushing', 'me', 'out', 'the', 'door', 'and', 'you', 'did', 'not', 'even', 'notice', 'until', 'you', 'got', 'in', 'the', 'car']\n","Updated Tokens (Row 46): ['get', 'mean', 'first', 'time', 'came', 'said', 'best', 'night', 'life', 'last', 'year', 'remember', 'distinctly', 'excited', 'coming', 'stubbed', 'toe', 'toe', 'pushing', 'door', 'even', 'notice', 'got', 'car']\n","Stopwords Removed (Row 46): ['i', 'do', 'not', 'it', 'i', 'the', 'we', 'you', 'it', 'was', 'the', 'of', 'your', 'and', 'i', 'you', 'were', 'so', 'about', 'that', 'you', 'your', 'me', 'out', 'the', 'and', 'you', 'did', 'not', 'until', 'you', 'in', 'the']\n","Stopwords were removed for Row 46 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 47): ['we', 'were', 'in', 'a', 'good', 'spot']\n","Updated Tokens (Row 47): ['good', 'spot']\n","Stopwords Removed (Row 47): ['we', 'were', 'in', 'a']\n","Stopwords were removed for Row 47 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 48): ['we', 'just', 'were', 'in', 'a', 'good', 'spot', 'this', 'is', 'a', 'much', 'better', 'spot', 'i', 'got', 'a', 'great', 'sense', 'for', 'these', 'things']\n","Updated Tokens (Row 48): ['good', 'spot', 'much', 'better', 'spot', 'got', 'great', 'sense', 'things']\n","Stopwords Removed (Row 48): ['we', 'just', 'were', 'in', 'a', 'this', 'is', 'a', 'i', 'a', 'for', 'these']\n","Stopwords were removed for Row 48 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 49): ['look', 'there', 'what', 'is', 'that', 'is', 'that', 'oh', 'no', 'that', 'is', 'seaweed']\n","Updated Tokens (Row 49): ['look', 'oh', 'seaweed']\n","Stopwords Removed (Row 49): ['there', 'what', 'is', 'that', 'is', 'that', 'no', 'that', 'is']\n","Stopwords were removed for Row 49 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 50): ['oh', 'this', 'is', 'great', 'i', 'would', 'not', 'miss', 'this', 'for', 'the', 'world', 'i', 'mean', 'think', 'about', 'this', 'i', 'know', 'you', 'not', 'interested', 'but', 'just', 'think', 'about', 'this', 'for', 'a', 'second']\n","Updated Tokens (Row 50): ['oh', 'great', 'would', 'miss', 'world', 'mean', 'think', 'know', 'interested', 'think', 'second']\n","Stopwords Removed (Row 50): ['this', 'is', 'i', 'not', 'this', 'for', 'the', 'i', 'about', 'this', 'i', 'you', 'not', 'but', 'just', 'about', 'this', 'for', 'a']\n","Stopwords were removed for Row 50 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 51): ['somewhere', 'out', 'there', 'is', 'a', 'giant', 'mass', 'of', 'silver', 'fish', 'all', 'swimming', 'in', 'this', 'direction', 'they', 'do', 'not', 'know', 'why', 'they', 'are', 'doing', 'it', 'we', 'do', 'not', 'know', 'why', 'they', 'are', 'doing', 'it', 'they', 'did', 'not', 'it', 'was', 'not', 'a', 'decision', 'no', 'one', 'took', 'a', 'vote', 'nobody', 'sent', 'them', 'an', 'invitation', 'or', 'a', 'map', 'or', 'anything', 'like', 'that', 'it', 'was', 'just', 'some', 'internal', 'time', 'release', 'fire', 'cracker', 'that', 'went', 'off', 'and', 'all', 'as', 'one', 'they', 'turned', 'around', 'and', 'formed', 'this', 'giant', 'line', 'as', 'long', 'as', 'the', 'california', 'coastline', 'and', 'they', 'just', 'started', 'swimming', 'they', 'are', 'swimming', 'right', 'now', 'at', 'this', 'very', 'moment', 'and', 'and']\n","Updated Tokens (Row 51): ['somewhere', 'giant', 'mass', 'silver', 'fish', 'swimming', 'direction', 'know', 'know', 'decision', 'one', 'took', 'vote', 'nobody', 'sent', 'invitation', 'map', 'anything', 'like', 'internal', 'time', 'release', 'fire', 'cracker', 'went', 'one', 'turned', 'around', 'formed', 'giant', 'line', 'long', 'california', 'coastline', 'started', 'swimming', 'swimming', 'right', 'moment']\n","Stopwords Removed (Row 51): ['out', 'there', 'is', 'a', 'of', 'all', 'in', 'this', 'they', 'do', 'not', 'why', 'they', 'are', 'doing', 'it', 'we', 'do', 'not', 'why', 'they', 'are', 'doing', 'it', 'they', 'did', 'not', 'it', 'was', 'not', 'a', 'no', 'a', 'them', 'an', 'or', 'a', 'or', 'that', 'it', 'was', 'just', 'some', 'that', 'off', 'and', 'all', 'as', 'they', 'and', 'this', 'as', 'as', 'the', 'and', 'they', 'just', 'they', 'are', 'now', 'at', 'this', 'very', 'and', 'and']\n","Stopwords were removed for Row 51 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 52): ['and', 'it', 'is', 'single', 'mindedness', 'with', 'no', 'mind', 'it', 'is', 'urgency', 'it', 'is', 'pure', 'urge', 'i', 'mean', 'they', 'did', 'not', 'make', 'any', 'decisions', 'they', 'do', 'not', 'ask', 'any', 'questions', 'they', 'do', 'not', 'give', 'it', 'a', 'name']\n","Updated Tokens (Row 52): ['single', 'mindedness', 'mind', 'urgency', 'pure', 'urge', 'mean', 'make', 'decisions', 'ask', 'questions', 'give', 'name']\n","Stopwords Removed (Row 52): ['and', 'it', 'is', 'with', 'no', 'it', 'is', 'it', 'is', 'i', 'they', 'did', 'not', 'any', 'they', 'do', 'not', 'any', 'they', 'do', 'not', 'it', 'a']\n","Stopwords were removed for Row 52 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 53): ['they', 'just', 'all', 'as', 'one', 'turn', 'around', 'and', 'start', 'swimming', 'to', 'this', 'very', 'point', 'where', 'we', 'are', 'standing', 'now', 'for', 'one', 'last', 'celebration', 'of', 'sex', 'and', 'death', 'god', 'it', 'is', 'giving', 'me', 'goosebumps', 'look', 'at', 'all', 'the', 'hairs', 'that', 'are', 'standing', 'up']\n","Updated Tokens (Row 53): ['one', 'turn', 'around', 'start', 'swimming', 'point', 'standing', 'one', 'last', 'celebration', 'sex', 'death', 'god', 'giving', 'goosebumps', 'look', 'hairs', 'standing']\n","Stopwords Removed (Row 53): ['they', 'just', 'all', 'as', 'and', 'to', 'this', 'very', 'where', 'we', 'are', 'now', 'for', 'of', 'and', 'it', 'is', 'me', 'at', 'all', 'the', 'that', 'are', 'up']\n","Stopwords were removed for Row 53 in file Ses05M_script02_1.csv.\n","Original Tokens (Row 54): ['well', 'so', 'what', 'do', 'you', 'think']\n","Updated Tokens (Row 54): ['well', 'think']\n","Stopwords Removed (Row 54): ['so', 'what', 'do', 'you']\n","Stopwords were removed for Row 54 in file Ses05M_script02_1.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script02_1.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script02_1.csv\n","\n","Processing File: Ses05M_script03_1.csv\n","Original Tokens (Row 0): ['do', 'you', 'think', 'it', 'is', 'them']\n","Updated Tokens (Row 0): ['think']\n","Stopwords Removed (Row 0): ['do', 'you', 'it', 'is', 'them']\n","Stopwords were removed for Row 0 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 1): ['what', 'nobody', 'knows', 'we', 'are', 'here', 'except', 'freda', 'and', 'she', 'would', 'not', 'ring', 'up']\n","Updated Tokens (Row 1): ['nobody', 'knows', 'except', 'freda', 'would', 'ring']\n","Stopwords Removed (Row 1): ['what', 'we', 'are', 'here', 'and', 'she', 'not', 'up']\n","Stopwords were removed for Row 1 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 2): ['what', 'do', 'we', 'do']\n","Updated Tokens (Row 2): []\n","Stopwords Removed (Row 2): ['what', 'do', 'we', 'do']\n","Stopwords were removed for Row 2 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 3): ['now', 'and', 'always', 'my', 'sweet']\n","Updated Tokens (Row 3): ['always', 'sweet']\n","Stopwords Removed (Row 3): ['now', 'and', 'my']\n","Stopwords were removed for Row 3 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 4): ['it', 'was', 'bound', 'to', 'happen', 'sooner', 'or', 'later']\n","Updated Tokens (Row 4): ['bound', 'happen', 'sooner', 'later']\n","Stopwords Removed (Row 4): ['it', 'was', 'to', 'or']\n","Stopwords were removed for Row 4 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 5): ['oh', 'it', 'sent', 'shivers', 'up', 'my', 'spine']\n","Updated Tokens (Row 5): ['oh', 'sent', 'shivers', 'spine']\n","Stopwords Removed (Row 5): ['it', 'up', 'my']\n","Stopwords were removed for Row 5 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 6): ['behave', 'exquisitely']\n","Updated Tokens (Row 6): ['behave', 'exquisitely']\n","Stopwords Removed (Row 6): []\n","No stopwords removed for Row 6 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 7): ['i', 'shall', 'probably', 'do', 'a', 'court', 'curtsey']\n","Updated Tokens (Row 7): ['shall', 'probably', 'court', 'curtsey']\n","Stopwords Removed (Row 7): ['i', 'do', 'a']\n","Stopwords were removed for Row 7 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 8): ['what', 'is', 'so', 'horrible', 'is', 'that', 'one', 'can', 'not', 'stay', 'happy']\n","Updated Tokens (Row 8): ['horrible', 'one', 'stay', 'happy']\n","Stopwords Removed (Row 8): ['what', 'is', 'so', 'is', 'that', 'can', 'not']\n","Stopwords were removed for Row 8 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 9): ['well', 'it', 'is', 'true', 'the', 'whole', 'business', 'is', 'a', 'very', 'poor', 'joke']\n","Updated Tokens (Row 9): ['well', 'true', 'whole', 'business', 'poor', 'joke']\n","Stopwords Removed (Row 9): ['it', 'is', 'the', 'is', 'a', 'very']\n","Stopwords were removed for Row 9 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 10): ['meaning', 'just', 'that']\n","Updated Tokens (Row 10): ['meaning']\n","Stopwords Removed (Row 10): ['just', 'that']\n","Stopwords were removed for Row 10 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 11): ['do', 'not', 'laugh', 'at', 'me', 'i', 'serious']\n","Updated Tokens (Row 11): ['laugh', 'serious']\n","Stopwords Removed (Row 11): ['do', 'not', 'at', 'me', 'i']\n","Stopwords were removed for Row 11 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 12): ['who', 'is', 'they']\n","Updated Tokens (Row 12): []\n","Stopwords Removed (Row 12): ['who', 'is', 'they']\n","Stopwords were removed for Row 12 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 13): ['if', 'i', 'laugh', 'at', 'everything', 'then', 'i', 'must', 'laugh', 'at', 'us', 'too']\n","Updated Tokens (Row 13): ['laugh', 'everything', 'must', 'laugh', 'us']\n","Stopwords Removed (Row 13): ['if', 'i', 'at', 'then', 'i', 'at', 'too']\n","Stopwords were removed for Row 13 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 14): ['oh', 'how', 'long', 'will', 'it', 'last', 'this', 'ludicrous', 'overbearing', 'love', 'of', 'ours']\n","Updated Tokens (Row 14): ['oh', 'long', 'last', 'ludicrous', 'overbearing', 'love']\n","Stopwords Removed (Row 14): ['how', 'will', 'it', 'this', 'of', 'ours']\n","Stopwords were removed for Row 14 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 15): ['well', 'will', 'we', 'always', 'bicker', 'and', 'fight']\n","Updated Tokens (Row 15): ['well', 'always', 'bicker', 'fight']\n","Stopwords Removed (Row 15): ['will', 'we', 'and']\n","Stopwords were removed for Row 15 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 16): ['oh', 'dear', 'shall', 'we', 'like', 'that']\n","Updated Tokens (Row 16): ['oh', 'dear', 'shall', 'like']\n","Stopwords Removed (Row 16): ['we', 'that']\n","Stopwords were removed for Row 16 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 17): ['what', 'if', 'one', 'of', 'us', 'dies', 'does', 'the', 'other', 'one', 'laugh', 'then']\n","Updated Tokens (Row 17): ['one', 'us', 'dies', 'one', 'laugh']\n","Stopwords Removed (Row 17): ['what', 'if', 'of', 'does', 'the', 'other', 'then']\n","Stopwords were removed for Row 17 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 18): ['that', 'is', 'rather', 'serious', 'is', 'not', 'it']\n","Updated Tokens (Row 18): ['rather', 'serious']\n","Stopwords Removed (Row 18): ['that', 'is', 'is', 'not', 'it']\n","Stopwords were removed for Row 18 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 19): ['darling', 'i', 'do', 'believe', 'you', 'talking', 'nonsense']\n","Updated Tokens (Row 19): ['darling', 'believe', 'talking', 'nonsense']\n","Stopwords Removed (Row 19): ['i', 'do', 'you']\n","Stopwords were removed for Row 19 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 20): ['elliott', 'worms', 'do', 'not', 'pop']\n","Updated Tokens (Row 20): ['elliott', 'worms', 'pop']\n","Stopwords Removed (Row 20): ['do', 'not']\n","Stopwords were removed for Row 20 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 21): ['uhh', 'thank', 'you', 'darling', 'and', 'the', 'same', 'goes', 'for', 'you', 'except', 'that', 'if', 'i', 'ever', 'see', 'you', 'so', 'much', 'as', 'look', 'at', 'another', 'woman', 'i', 'kill', 'you']\n","Updated Tokens (Row 21): ['uhh', 'thank', 'darling', 'goes', 'except', 'ever', 'see', 'much', 'look', 'another', 'woman', 'kill']\n","Stopwords Removed (Row 21): ['you', 'and', 'the', 'same', 'for', 'you', 'that', 'if', 'i', 'you', 'so', 'as', 'at', 'i', 'you']\n","Stopwords were removed for Row 21 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 22): ['which', 'particular', 'one']\n","Updated Tokens (Row 22): ['particular', 'one']\n","Stopwords Removed (Row 22): ['which']\n","Stopwords were removed for Row 22 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 23): ['awe', 'charles', 'that', 'was', 'his', 'name', 'he', 'did', 'wriggle', 'so', 'beautifully']\n","Updated Tokens (Row 23): ['awe', 'charles', 'name', 'wriggle', 'beautifully']\n","Stopwords Removed (Row 23): ['that', 'was', 'his', 'he', 'did', 'so']\n","Stopwords were removed for Row 23 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 24): ['i', 'know', 'you', 'did', 'you', 'threw', 'it', 'out', 'the', 'window', 'into', 'the', 'canal', 'below', 'i', 'do', 'not', 'think', 'i', 'ever', 'forgive', 'you', 'for', 'that']\n","Updated Tokens (Row 24): ['know', 'threw', 'window', 'canal', 'think', 'ever', 'forgive']\n","Stopwords Removed (Row 24): ['i', 'you', 'did', 'you', 'it', 'out', 'the', 'into', 'the', 'below', 'i', 'do', 'not', 'i', 'you', 'for', 'that']\n","Stopwords were removed for Row 24 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 25): ['it', 'went', 'on', 'intermittently', 'for', 'days']\n","Updated Tokens (Row 25): ['went', 'intermittently', 'days']\n","Stopwords Removed (Row 25): ['it', 'on', 'for']\n","Stopwords were removed for Row 25 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 26): ['oh', 'it', 'burnt', 'my', 'comb', 'and', 'all', 'the', 'towels', 'in', 'the', 'bathroom']\n","Updated Tokens (Row 26): ['oh', 'burnt', 'comb', 'towels', 'bathroom']\n","Stopwords Removed (Row 26): ['it', 'my', 'and', 'all', 'the', 'in', 'the']\n","Stopwords were removed for Row 26 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 27): ['that', 'was', 'the', 'first', 'time', 'you', 'hit', 'me']\n","Updated Tokens (Row 27): ['first', 'time', 'hit']\n","Stopwords Removed (Row 27): ['that', 'was', 'the', 'you', 'me']\n","Stopwords were removed for Row 27 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 28): ['and', 'then', 'the', 'manager', 'came', 'in', 'and', 'saw', 'us', 'all', 'rolling', 'all', 'over', 'the', 'floor', 'biting', 'and', 'scratching', 'one', 'another', 'laughter']\n","Updated Tokens (Row 28): ['manager', 'came', 'saw', 'us', 'rolling', 'floor', 'biting', 'scratching', 'one', 'another', 'laughter']\n","Stopwords Removed (Row 28): ['and', 'then', 'the', 'in', 'and', 'all', 'all', 'over', 'the', 'and']\n","Stopwords were removed for Row 28 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 29): ['how', 'ridiculous', 'utterly', 'ridiculous']\n","Updated Tokens (Row 29): ['ridiculous', 'utterly', 'ridiculous']\n","Stopwords Removed (Row 29): ['how']\n","Stopwords were removed for Row 29 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 30): ['very', 'much', 'sillier']\n","Updated Tokens (Row 30): ['much', 'sillier']\n","Stopwords Removed (Row 30): ['very']\n","Stopwords were removed for Row 30 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 31): ['you', 'knew', 'there', 'was', 'nothing', 'in', 'that']\n","Updated Tokens (Row 31): ['knew', 'nothing']\n","Stopwords Removed (Row 31): ['you', 'there', 'was', 'in', 'that']\n","Stopwords were removed for Row 31 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 32): ['oh', 'good', 'god']\n","Updated Tokens (Row 32): ['oh', 'good', 'god']\n","Stopwords Removed (Row 32): []\n","No stopwords removed for Row 32 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 33): ['i', 'wonder']\n","Updated Tokens (Row 33): ['wonder']\n","Stopwords Removed (Row 33): ['i']\n","Stopwords were removed for Row 33 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 34): ['must', 'be', 'them', 'then']\n","Updated Tokens (Row 34): ['must']\n","Stopwords Removed (Row 34): ['be', 'them', 'then']\n","Stopwords were removed for Row 34 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 35): ['we', 'all', 'right', 'are', 'not', 'we', 'darling', 'whatever', 'happens']\n","Updated Tokens (Row 35): ['right', 'darling', 'whatever', 'happens']\n","Stopwords Removed (Row 35): ['we', 'all', 'are', 'not', 'we']\n","Stopwords were removed for Row 35 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 36): ['i', 'do', 'not', 'care', 'then']\n","Updated Tokens (Row 36): ['care']\n","Stopwords Removed (Row 36): ['i', 'do', 'not', 'then']\n","Stopwords were removed for Row 36 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 37): ['hello', 'hello', 'what', 'wrong', 'number']\n","Updated Tokens (Row 37): ['hello', 'hello', 'wrong', 'number']\n","Stopwords Removed (Row 37): ['what']\n","Stopwords were removed for Row 37 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 38): ['oh', 'what', 'shall', 'we', 'do', 'if', 'they', 'suddenly', 'walk', 'in', 'on', 'us']\n","Updated Tokens (Row 38): ['oh', 'shall', 'suddenly', 'walk', 'us']\n","Stopwords Removed (Row 38): ['what', 'we', 'do', 'if', 'they', 'in', 'on']\n","Stopwords were removed for Row 38 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 39): ['with', 'the', 'worst', 'with', 'the', 'most', 'perfect', 'poise']\n","Updated Tokens (Row 39): ['worst', 'perfect', 'poise']\n","Stopwords Removed (Row 39): ['with', 'the', 'with', 'the', 'most']\n","Stopwords were removed for Row 39 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 40): ['uhh', 'it', 'is', 'amazing', 'how', 'once', 'you', 'feel']\n","Updated Tokens (Row 40): ['uhh', 'amazing', 'feel']\n","Stopwords Removed (Row 40): ['it', 'is', 'how', 'once', 'you']\n","Stopwords were removed for Row 40 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 41): ['things', 'that', 'ought', 'to', 'matter', 'most', 'dreadfully', 'do', 'not', 'matter', 'at', 'all', 'when', 'one', 'happy', 'do', 'they']\n","Updated Tokens (Row 41): ['things', 'ought', 'matter', 'dreadfully', 'matter', 'one', 'happy']\n","Stopwords Removed (Row 41): ['that', 'to', 'most', 'do', 'not', 'at', 'all', 'when', 'do', 'they']\n","Stopwords were removed for Row 41 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 42): ['uhh', 'you', 'must', 'not', 'say', 'that', 'my', 'darling']\n","Updated Tokens (Row 42): ['uhh', 'must', 'say', 'darling']\n","Stopwords Removed (Row 42): ['you', 'not', 'that', 'my']\n","Stopwords were removed for Row 42 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 43): ['being', 'that', 'sacred', 'and', 'wonderful', 'thing', 'love']\n","Updated Tokens (Row 43): ['sacred', 'wonderful', 'thing', 'love']\n","Stopwords Removed (Row 43): ['being', 'that', 'and']\n","Stopwords were removed for Row 43 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 44): ['um', 'what', 'does', 'it', 'all', 'mean', 'that', 'is', 'what', 'i', 'ask', 'myself', 'in', 'my', 'endless', 'quest', 'for', 'ultimate', 'truth', 'dear', 'god', 'what', 'does', 'it', 'all', 'mean']\n","Updated Tokens (Row 44): ['um', 'mean', 'ask', 'endless', 'quest', 'ultimate', 'truth', 'dear', 'god', 'mean']\n","Stopwords Removed (Row 44): ['what', 'does', 'it', 'all', 'that', 'is', 'what', 'i', 'myself', 'in', 'my', 'for', 'what', 'does', 'it', 'all']\n","Stopwords were removed for Row 44 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 45): ['you', 'must', 'not', 'be', 'serious', 'darling', 'that', 'is', 'just', 'what', 'they', 'want']\n","Updated Tokens (Row 45): ['must', 'serious', 'darling', 'want']\n","Stopwords Removed (Row 45): ['you', 'not', 'be', 'that', 'is', 'just', 'what', 'they']\n","Stopwords were removed for Row 45 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 46): ['all', 'the', 'futile', 'mortals', 'who', 'try', 'to', 'make', 'life', 'unbearable', 'laugh', 'at', 'them', 'be', 'flippant', 'laugh', 'at', 'everything', 'all', 'their', 'sacred', 'shibboleths']\n","Updated Tokens (Row 46): ['futile', 'mortals', 'try', 'make', 'life', 'unbearable', 'laugh', 'flippant', 'laugh', 'everything', 'sacred', 'shibboleths']\n","Stopwords Removed (Row 46): ['all', 'the', 'who', 'to', 'at', 'them', 'be', 'at', 'all', 'their']\n","Stopwords were removed for Row 46 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 47): ['uh', 'the', 'being', 'flippant', 'brings', 'out', 'the', 'acid', 'in', 'their', 'damned', 'beauty', 'and', 'light']\n","Updated Tokens (Row 47): ['uh', 'flippant', 'brings', 'acid', 'damned', 'beauty', 'light']\n","Stopwords Removed (Row 47): ['the', 'being', 'out', 'the', 'in', 'their', 'and']\n","Stopwords were removed for Row 47 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 48): ['certainly', 'you', 'must', 'we', 'are', 'figures', 'of', 'fun', 'all', 'right']\n","Updated Tokens (Row 48): ['certainly', 'must', 'figures', 'fun', 'right']\n","Stopwords Removed (Row 48): ['you', 'we', 'are', 'of', 'all']\n","Stopwords were removed for Row 48 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 49): ['garbage', 'who', 'knows']\n","Updated Tokens (Row 49): ['garbage', 'knows']\n","Stopwords Removed (Row 49): ['who']\n","Stopwords were removed for Row 49 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 50): ['no', 'that', 'fire', 'will', 'fade', 'along', 'with', 'our', 'passion']\n","Updated Tokens (Row 50): ['fire', 'fade', 'along', 'passion']\n","Stopwords Removed (Row 50): ['no', 'that', 'will', 'with', 'our']\n","Stopwords were removed for Row 50 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 51): ['well', 'it', 'depends', 'on', 'how', 'well', 'we', 'played']\n","Updated Tokens (Row 51): ['well', 'depends', 'well', 'played']\n","Stopwords Removed (Row 51): ['it', 'on', 'how', 'we']\n","Stopwords were removed for Row 51 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 52): ['yes', 'yes', 'with', 'all', 'his', 'might']\n","Updated Tokens (Row 52): ['yes', 'yes', 'might']\n","Stopwords Removed (Row 52): ['with', 'all', 'his']\n","Stopwords were removed for Row 52 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 53): ['no', 'no', 'that', 'is', 'quit', 'laughable', 'the', 'cutting', 'little', 'mystery', 'all', 'done', 'with', 'mirrors']\n","Updated Tokens (Row 53): ['quit', 'laughable', 'cutting', 'little', 'mystery', 'done', 'mirrors']\n","Stopwords Removed (Row 53): ['no', 'no', 'that', 'is', 'the', 'all', 'with']\n","Stopwords were removed for Row 53 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 54): ['so', 'is', 'everyone', 'else', 'in', 'the', 'long', 'run', 'let', 'be', 'superficial', 'and', 'pity', 'the', 'poor', 'philosophers', 'let', 'blow', 'trumpets', 'and', 'squeakers', 'and', 'enjoy', 'the', 'party', 'as', 'long', 'as', 'we', 'can', 'like', 'little', 'quiet', 'idiotic', 'school', 'children']\n","Updated Tokens (Row 54): ['everyone', 'else', 'long', 'run', 'let', 'superficial', 'pity', 'poor', 'philosophers', 'let', 'blow', 'trumpets', 'squeakers', 'enjoy', 'party', 'long', 'like', 'little', 'quiet', 'idiotic', 'school', 'children']\n","Stopwords Removed (Row 54): ['so', 'is', 'in', 'the', 'be', 'and', 'the', 'and', 'and', 'the', 'as', 'as', 'we', 'can']\n","Stopwords were removed for Row 54 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 55): ['garbage', 'darling', 'kiss', 'me', 'before', 'your', 'body', 'rots', 'and', 'worms', 'start', 'popping', 'in', 'and', 'out', 'of', 'your', 'eye', 'sockets']\n","Updated Tokens (Row 55): ['garbage', 'darling', 'kiss', 'body', 'rots', 'worms', 'start', 'popping', 'eye', 'sockets']\n","Stopwords Removed (Row 55): ['me', 'before', 'your', 'and', 'in', 'and', 'out', 'of', 'your']\n","Stopwords were removed for Row 55 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 56): ['i', 'do', 'not', 'care', 'what', 'you', 'do', 'see', 'you', 'could', 'paint', 'your', 'body', 'bright', 'green', 'and', 'and', 'run', 'naked', 'through', 'the', 'place', 'vendome', 'and', 'run', 'with', 'every', 'man', 'in', 'the', 'world', 'and', 'i', 'sha', 'say', 'a', 'word', 'as', 'long', 'as', 'i', 'know', 'that', 'you', 'love', 'me', 'best']\n","Updated Tokens (Row 56): ['care', 'see', 'could', 'paint', 'body', 'bright', 'green', 'run', 'naked', 'place', 'vendome', 'run', 'every', 'man', 'world', 'sha', 'say', 'word', 'long', 'know', 'love', 'best']\n","Stopwords Removed (Row 56): ['i', 'do', 'not', 'what', 'you', 'do', 'you', 'your', 'and', 'and', 'through', 'the', 'and', 'with', 'in', 'the', 'and', 'i', 'a', 'as', 'as', 'i', 'that', 'you', 'me']\n","Stopwords were removed for Row 56 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 57): ['do', 'you', 'remember', 'that', 'awful', 'scene', 'we', 'had', 'in', 'venice']\n","Updated Tokens (Row 57): ['remember', 'awful', 'scene', 'venice']\n","Stopwords Removed (Row 57): ['do', 'you', 'that', 'we', 'had', 'in']\n","Stopwords were removed for Row 57 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 58): ['the', 'one', 'where', 'you', 'bought', 'that', 'little', 'painted', 'wooden', 'stake', 'and', 'you', 'put', 'it', 'on', 'my', 'bed']\n","Updated Tokens (Row 58): ['one', 'bought', 'little', 'painted', 'wooden', 'stake', 'put', 'bed']\n","Stopwords Removed (Row 58): ['the', 'where', 'you', 'that', 'and', 'you', 'it', 'on', 'my']\n","Stopwords were removed for Row 58 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 59): ['horrible', 'thing', 'i', 'hated', 'it']\n","Updated Tokens (Row 59): ['horrible', 'thing', 'hated']\n","Stopwords Removed (Row 59): ['i', 'it']\n","Stopwords were removed for Row 59 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 60): ['how', 'long', 'did', 'that', 'roue', 'last']\n","Updated Tokens (Row 60): ['long', 'roue', 'last']\n","Stopwords Removed (Row 60): ['how', 'did', 'that']\n","Stopwords were removed for Row 60 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 61): ['oh', 'the', 'worst', 'one', 'was', 'in', 'cannes', 'when', 'your', 'curling', 'iron', 'burnt', 'a', 'hole', 'in', 'my', 'new', 'dressing', 'gown']\n","Updated Tokens (Row 61): ['oh', 'worst', 'one', 'cannes', 'curling', 'iron', 'burnt', 'hole', 'new', 'dressing', 'gown']\n","Stopwords Removed (Row 61): ['the', 'was', 'in', 'when', 'your', 'a', 'in', 'my']\n","Stopwords were removed for Row 61 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 62): ['laughter', 'that', 'was', 'quit', 'a', 'rouser', 'was', 'not', 'it']\n","Updated Tokens (Row 62): ['laughter', 'quit', 'rouser']\n","Stopwords Removed (Row 62): ['that', 'was', 'a', 'was', 'not', 'it']\n","Stopwords were removed for Row 62 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 63): ['oh', 'i', 'did', 'not', 'hit', 'you', 'very', 'hard']\n","Updated Tokens (Row 63): ['oh', 'hit', 'hard']\n","Stopwords Removed (Row 63): ['i', 'did', 'not', 'you', 'very']\n","Stopwords were removed for Row 63 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 64): ['i', 'should', 'never', 'forget', 'his', 'face', 'laughter']\n","Updated Tokens (Row 64): ['never', 'forget', 'face', 'laughter']\n","Stopwords Removed (Row 64): ['i', 'should', 'his']\n","Stopwords were removed for Row 64 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 65): ['we', 'were', 'very', 'much', 'younger', 'then']\n","Updated Tokens (Row 65): ['much', 'younger']\n","Stopwords Removed (Row 65): ['we', 'were', 'very', 'then']\n","Stopwords were removed for Row 65 in file Ses05M_script03_1.csv.\n","Original Tokens (Row 66): ['come', 'to', 'think', 'of', 'it', 'the', 'real', 'cause', 'of', 'that', 'roues', 'was', 'peter', 'burden']\n","Updated Tokens (Row 66): ['come', 'think', 'real', 'cause', 'roues', 'peter', 'burden']\n","Stopwords Removed (Row 66): ['to', 'of', 'it', 'the', 'of', 'that', 'was']\n","Stopwords were removed for Row 66 in file Ses05M_script03_1.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script03_1.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script03_1.csv\n","\n","Processing File: Ses05M_script03_2.csv\n","Original Tokens (Row 0): ['oh', 'you', 'knew', 'there', 'was', 'nothing', 'in', 'that']\n","Updated Tokens (Row 0): ['oh', 'knew', 'nothing']\n","Stopwords Removed (Row 0): ['you', 'there', 'was', 'in', 'that']\n","Stopwords were removed for Row 0 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 1): ['only', 'a', 'trivial', 'little', 'broach']\n","Updated Tokens (Row 1): ['trivial', 'little', 'broach']\n","Stopwords Removed (Row 1): ['only', 'a']\n","Stopwords were removed for Row 1 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 2): ['not', 'at', 'all', 'i', 'quite', 'like', 'it', 'i', 'wear', 'it', 'often']\n","Updated Tokens (Row 2): ['quite', 'like', 'wear', 'often']\n","Stopwords Removed (Row 2): ['not', 'at', 'all', 'i', 'it', 'i', 'it']\n","Stopwords were removed for Row 2 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 3): ['garbage', 'no', 'i', 'did', 'not', 'you', 'worked', 'the', 'whole', 'thing', 'up', 'in', 'your', 'jealous', 'imagination']\n","Updated Tokens (Row 3): ['garbage', 'worked', 'whole', 'thing', 'jealous', 'imagination']\n","Stopwords Removed (Row 3): ['no', 'i', 'did', 'not', 'you', 'the', 'up', 'in', 'your']\n","Stopwords were removed for Row 3 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 4): ['oh', 'maybe', 'a', 'little', 'nothing', 'serious']\n","Updated Tokens (Row 4): ['oh', 'maybe', 'little', 'nothing', 'serious']\n","Stopwords Removed (Row 4): ['a']\n","Stopwords were removed for Row 4 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 5): ['well', 'what', 'of', 'it']\n","Updated Tokens (Row 5): ['well']\n","Stopwords Removed (Row 5): ['what', 'of', 'it']\n","Stopwords were removed for Row 5 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 6): ['well', 'it', 'gave', 'him', 'a', 'lot', 'of', 'pleasure', 'and', 'it', 'did', 'not', 'hurt', 'me']\n","Updated Tokens (Row 6): ['well', 'gave', 'lot', 'pleasure', 'hurt']\n","Stopwords Removed (Row 6): ['it', 'him', 'a', 'of', 'and', 'it', 'did', 'not', 'me']\n","Stopwords were removed for Row 6 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 7): ['well', 'if', 'you', 'had', 'not', 'been', 'so', 'nosey', 'and', 'suspicious', 'you', 'never', 'would', 'have', 'known', 'about', 'it']\n","Updated Tokens (Row 7): ['well', 'nosey', 'suspicious', 'never', 'would', 'known']\n","Stopwords Removed (Row 7): ['if', 'you', 'had', 'not', 'been', 'so', 'and', 'you', 'have', 'about', 'it']\n","Stopwords were removed for Row 7 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 8): ['i', 'getting', 'very', 'bored', 'with', 'this', 'conversation']\n","Updated Tokens (Row 8): ['getting', 'bored', 'conversation']\n","Stopwords Removed (Row 8): ['i', 'very', 'with', 'this']\n","Stopwords were removed for Row 8 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 9): ['no', 'thanks']\n","Updated Tokens (Row 9): ['thanks']\n","Stopwords Removed (Row 9): ['no']\n","Stopwords were removed for Row 9 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 10): ['i', 'do', 'not', 'see', 'why', 'you', 'want', 'it', 'you', 'have', 'already', 'had', 'two', 'glasses']\n","Updated Tokens (Row 10): ['see', 'want', 'already', 'two', 'glasses']\n","Stopwords Removed (Row 10): ['i', 'do', 'not', 'why', 'you', 'it', 'you', 'have', 'had']\n","Stopwords were removed for Row 10 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 11): ['well', 'it', 'seems', 'silly', 'to', 'go', 'on', 'and', 'on', 'with', 'such', 'a', 'thing']\n","Updated Tokens (Row 11): ['well', 'seems', 'silly', 'go', 'thing']\n","Stopwords Removed (Row 11): ['it', 'to', 'on', 'and', 'on', 'with', 'such', 'a']\n","Stopwords were removed for Row 11 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 12): ['it', 'is', 'becoming', 'a', 'habit', 'with', 'you']\n","Updated Tokens (Row 12): ['becoming', 'habit']\n","Stopwords Removed (Row 12): ['it', 'is', 'a', 'with', 'you']\n","Stopwords were removed for Row 12 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 13): ['do', 'not', 'be', 'stupid']\n","Updated Tokens (Row 13): ['stupid']\n","Stopwords Removed (Row 13): ['do', 'not', 'be']\n","Stopwords were removed for Row 13 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 14): ['what']\n","Updated Tokens (Row 14): []\n","Stopwords Removed (Row 14): ['what']\n","Stopwords were removed for Row 14 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 15): ['just', 'making', 'myself', 'fascinating', 'for', 'you']\n","Updated Tokens (Row 15): ['making', 'fascinating']\n","Stopwords Removed (Row 15): ['just', 'myself', 'for', 'you']\n","Stopwords were removed for Row 15 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 16): ['it', 'is', 'a', 'woman', 'is', 'job', 'to', 'allure', 'the', 'man', 'watch', 'me', 'a', 'moment', 'will', 'not', 'you']\n","Updated Tokens (Row 16): ['woman', 'job', 'allure', 'man', 'watch', 'moment']\n","Stopwords Removed (Row 16): ['it', 'is', 'a', 'is', 'to', 'the', 'me', 'a', 'will', 'not', 'you']\n","Stopwords were removed for Row 16 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 17): ['no', 'it', 'is', 'not']\n","Updated Tokens (Row 17): []\n","Stopwords Removed (Row 17): ['no', 'it', 'is', 'not']\n","Stopwords were removed for Row 17 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 18): ['no', 'it', 'it', 'is', 'not', 'be', 'quiet']\n","Updated Tokens (Row 18): ['quiet']\n","Stopwords Removed (Row 18): ['no', 'it', 'it', 'is', 'not', 'be']\n","Stopwords were removed for Row 18 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 19): ['hum', 'it', 'does', 'not', 'seem', 'to', 'have', 'worked', 'such', 'wonders', 'with', 'you']\n","Updated Tokens (Row 19): ['hum', 'seem', 'worked', 'wonders']\n","Stopwords Removed (Row 19): ['it', 'does', 'not', 'to', 'have', 'such', 'with', 'you']\n","Stopwords were removed for Row 19 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 20): ['adders', 'do', 'not', 'snap', 'they', 'sting']\n","Updated Tokens (Row 20): ['adders', 'snap', 'sting']\n","Stopwords Removed (Row 20): ['do', 'not', 'they']\n","Stopwords were removed for Row 20 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 21): ['they', 'sting']\n","Updated Tokens (Row 21): ['sting']\n","Stopwords Removed (Row 21): ['they']\n","Stopwords were removed for Row 21 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 22): ['okay', 'i', 'do', 'not', 'care', 'if', 'they', 'roll', 'about', 'like', 'hoops', 'and', 'bark', 'okay']\n","Updated Tokens (Row 22): ['okay', 'care', 'roll', 'like', 'hoops', 'bark', 'okay']\n","Stopwords Removed (Row 22): ['i', 'do', 'not', 'if', 'they', 'about', 'and']\n","Stopwords were removed for Row 22 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 23): ['yes', 'i', 'did', 'quite', 'a', 'lot']\n","Updated Tokens (Row 23): ['yes', 'quite', 'lot']\n","Stopwords Removed (Row 23): ['i', 'did', 'a']\n","Stopwords were removed for Row 23 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 24): ['laughter', 'mind', 'your', 'own', 'business']\n","Updated Tokens (Row 24): ['laughter', 'mind', 'business']\n","Stopwords Removed (Row 24): ['your', 'own']\n","Stopwords were removed for Row 24 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 25): ['you', 'quite', 'insufferable', 'i', 'do', 'imagine', 'it', 'is', 'because', 'you', 'drunk']\n","Updated Tokens (Row 25): ['quite', 'insufferable', 'imagine', 'drunk']\n","Stopwords Removed (Row 25): ['you', 'i', 'do', 'it', 'is', 'because', 'you']\n","Stopwords were removed for Row 25 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 26): ['you', 'always', 'had', 'a', 'weak', 'head']\n","Updated Tokens (Row 26): ['always', 'weak', 'head']\n","Stopwords Removed (Row 26): ['you', 'had', 'a']\n","Stopwords were removed for Row 26 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 27): ['oh', 'no', 'on', 'the', 'contrary', 'a', 'child', 'of', 'two', 'could', 'get', 'violently', 'drunk', 'on', 'only', 'one', 'glass']\n","Updated Tokens (Row 27): ['oh', 'contrary', 'child', 'two', 'could', 'get', 'violently', 'drunk', 'one', 'glass']\n","Stopwords Removed (Row 27): ['no', 'on', 'the', 'a', 'of', 'on', 'only']\n","Stopwords were removed for Row 27 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 28): ['not', 'would', 'you', 'shut', 'up']\n","Updated Tokens (Row 28): ['would', 'shut']\n","Stopwords Removed (Row 28): ['not', 'you', 'up']\n","Stopwords were removed for Row 28 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 29): ['you', 'not', 'very', 'funny', 'dear', 'you', 'better', 'have', 'some', 'more', 'brandy']\n","Updated Tokens (Row 29): ['funny', 'dear', 'better', 'brandy']\n","Stopwords Removed (Row 29): ['you', 'not', 'very', 'you', 'have', 'some', 'more']\n","Stopwords were removed for Row 29 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 30): ['why']\n","Updated Tokens (Row 30): []\n","Stopwords Removed (Row 30): ['why']\n","Stopwords were removed for Row 30 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 31): ['there', 'are', 'not', 'any', 'people', 'upstairs', 'it', 'is', 'a', 'photography', 'studio']\n","Updated Tokens (Row 31): ['people', 'upstairs', 'photography', 'studio']\n","Stopwords Removed (Row 31): ['there', 'are', 'not', 'any', 'it', 'is', 'a']\n","Stopwords were removed for Row 31 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 32): ['they', 'are', 'away', 'in', 'tunis']\n","Updated Tokens (Row 32): ['away', 'tunis']\n","Stopwords Removed (Row 32): ['they', 'are', 'in']\n","Stopwords were removed for Row 32 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 33): ['turn', 'it', 'on', 'again', 'please']\n","Updated Tokens (Row 33): ['turn', 'please']\n","Stopwords Removed (Row 33): ['it', 'on', 'again']\n","Stopwords were removed for Row 33 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 34): ['very', 'well', 'if', 'you', 'have', 'to', 'be', 'boorish', 'and', 'idiotic']\n","Updated Tokens (Row 34): ['well', 'boorish', 'idiotic']\n","Stopwords Removed (Row 34): ['very', 'if', 'you', 'have', 'to', 'be', 'and']\n","Stopwords were removed for Row 34 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 35): ['you', 'are', 'far', 'too', 'temperamental', 'try', 'to', 'control', 'yourself']\n","Updated Tokens (Row 35): ['far', 'temperamental', 'try', 'control']\n","Stopwords Removed (Row 35): ['you', 'are', 'too', 'to', 'yourself']\n","Stopwords were removed for Row 35 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 36): ['go', 'away', 'go', 'away', 'i', 'hate', 'you']\n","Updated Tokens (Row 36): ['go', 'away', 'go', 'away', 'hate']\n","Stopwords Removed (Row 36): ['i', 'you']\n","Stopwords were removed for Row 36 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 37): ['you', 'know', 'what', 'i', 'sick', 'and', 'tire', 'of', 'listening', 'to', 'you', 'you', 'a', 'you', 'a', 'total', 'sadistic', 'bully']\n","Updated Tokens (Row 37): ['know', 'sick', 'tire', 'listening', 'total', 'sadistic', 'bully']\n","Stopwords Removed (Row 37): ['you', 'what', 'i', 'and', 'of', 'to', 'you', 'you', 'a', 'you', 'a']\n","Stopwords were removed for Row 37 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 38): ['stop', 'would', 'you', 'just', 'go', 'away', 'i', 'mean', 'you', 'conceited', 'and', 'overbearing', 'and', 'utterly', 'impossible']\n","Updated Tokens (Row 38): ['stop', 'would', 'go', 'away', 'mean', 'conceited', 'overbearing', 'utterly', 'impossible']\n","Stopwords Removed (Row 38): ['you', 'just', 'i', 'you', 'and', 'and']\n","Stopwords were removed for Row 38 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 39): ['this', 'is', 'the', 'end', 'do', 'you', 'understand', 'me', 'this', 'is', 'the', 'end']\n","Updated Tokens (Row 39): ['end', 'understand', 'end']\n","Stopwords Removed (Row 39): ['this', 'is', 'the', 'do', 'you', 'me', 'this', 'is', 'the']\n","Stopwords were removed for Row 39 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 40): ['yes', 'i', 'am', 'let', 'go', 'with', 'me']\n","Updated Tokens (Row 40): ['yes', 'let', 'go']\n","Stopwords Removed (Row 40): ['i', 'am', 'with', 'me']\n","Stopwords were removed for Row 40 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 41): ['you', 'are', 'a', 'cruel', 'fiend', 'and', 'i-i', 'loath', 'you', 'i', 'thank', 'god', 'i', 'realized', 'who', 'you', 'are', 'before', 'i', 'decided', 'to', 'marry', 'you', 'again', 'oh', 'my', 'god', 'never']\n","Updated Tokens (Row 41): ['cruel', 'fiend', 'i-i', 'loath', 'thank', 'god', 'realized', 'decided', 'marry', 'oh', 'god', 'never']\n","Stopwords Removed (Row 41): ['you', 'are', 'a', 'and', 'you', 'i', 'i', 'who', 'you', 'are', 'before', 'i', 'to', 'you', 'again', 'my']\n","Stopwords were removed for Row 41 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 42): ['beast']\n","Updated Tokens (Row 42): ['beast']\n","Stopwords Removed (Row 42): []\n","No stopwords removed for Row 42 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 43): ['brute']\n","Updated Tokens (Row 43): ['brute']\n","Stopwords Removed (Row 43): []\n","No stopwords removed for Row 43 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 44): ['pig']\n","Updated Tokens (Row 44): ['pig']\n","Stopwords Removed (Row 44): []\n","No stopwords removed for Row 44 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 45): ['come', 'to', 'think', 'of', 'it', 'the', 'real', 'cause', 'of', 'that', 'roue', 'was', 'peter', 'burden']\n","Updated Tokens (Row 45): ['come', 'think', 'real', 'cause', 'roue', 'peter', 'burden']\n","Stopwords Removed (Row 45): ['to', 'of', 'it', 'the', 'of', 'that', 'was']\n","Stopwords were removed for Row 45 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 46): ['i', 'knew', 'nothing', 'of', 'the', 'sort', 'you', 'accepted', 'presents', 'from', 'him']\n","Updated Tokens (Row 46): ['knew', 'nothing', 'sort', 'accepted', 'presents']\n","Stopwords Removed (Row 46): ['i', 'of', 'the', 'you', 'from', 'him']\n","Stopwords were removed for Row 46 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 47): ['i', 'remember', 'it', 'well', 'covered', 'in', 'diamonds', 'and', 'the', 'worst', 'possible', 'taste']\n","Updated Tokens (Row 47): ['remember', 'well', 'covered', 'diamonds', 'worst', 'possible', 'taste']\n","Stopwords Removed (Row 47): ['i', 'it', 'in', 'and', 'the']\n","Stopwords were removed for Row 47 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 48): ['you', 'went', 'out', 'of', 'your', 'way', 'to', 'torture', 'me', 'over', 'peter', 'burden']\n","Updated Tokens (Row 48): ['went', 'way', 'torture', 'peter', 'burden']\n","Stopwords Removed (Row 48): ['you', 'out', 'of', 'your', 'to', 'me', 'over']\n","Stopwords were removed for Row 48 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 49): ['you', 'must', 'admit', 'that', 'he', 'was', 'in', 'love', 'with', 'you', 'was', 'not', 'he']\n","Updated Tokens (Row 49): ['must', 'admit', 'love']\n","Stopwords Removed (Row 49): ['you', 'that', 'he', 'was', 'in', 'with', 'you', 'was', 'not', 'he']\n","Stopwords were removed for Row 49 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 50): ['he', 'let', 'him', 'kiss', 'you', 'you', 'said', 'you', 'did']\n","Updated Tokens (Row 50): ['let', 'kiss', 'said']\n","Stopwords Removed (Row 50): ['he', 'him', 'you', 'you', 'you', 'did']\n","Stopwords were removed for Row 50 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 51): ['what', 'of', 'it']\n","Updated Tokens (Row 51): []\n","Stopwords Removed (Row 51): ['what', 'of', 'it']\n","Stopwords were removed for Row 51 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 52): ['what', 'about', 'me']\n","Updated Tokens (Row 52): []\n","Stopwords Removed (Row 52): ['what', 'about', 'me']\n","Stopwords were removed for Row 52 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 53): ['well', 'that', 'is', 'a', 'nice', 'point', 'of', 'view', 'i', 'must', 'say']\n","Updated Tokens (Row 53): ['well', 'nice', 'point', 'view', 'must', 'say']\n","Stopwords Removed (Row 53): ['that', 'is', 'a', 'of', 'i']\n","Stopwords were removed for Row 53 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 54): ['me', 'too', 'bored', 'stiff']\n","Updated Tokens (Row 54): ['bored', 'stiff']\n","Stopwords Removed (Row 54): ['me', 'too']\n","Stopwords were removed for Row 54 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 55): ['do', 'you', 'want', 'some', 'brandy']\n","Updated Tokens (Row 55): ['want', 'brandy']\n","Stopwords Removed (Row 55): ['do', 'you', 'some']\n","Stopwords were removed for Row 55 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 56): ['i', 'think', 'i', 'have', 'a', 'little']\n","Updated Tokens (Row 56): ['think', 'little']\n","Stopwords Removed (Row 56): ['i', 'i', 'have', 'a']\n","Stopwords were removed for Row 56 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 57): ['no', 'particular', 'reason', 'besides', 'they', 'were', 'little', 'ones']\n","Updated Tokens (Row 57): ['particular', 'reason', 'besides', 'little', 'ones']\n","Stopwords Removed (Row 57): ['no', 'they', 'were']\n","Stopwords were removed for Row 57 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 58): ['you', 'can', 'hardly', 'say', 'you', 'can', 'hardly', 'call', 'three', 'little', 'liquor', 'glasses', 'of', 'brandy', 'for', 'the', 'entire', 'evening', 'going', 'on', 'and', 'on']\n","Updated Tokens (Row 58): ['hardly', 'say', 'hardly', 'call', 'three', 'little', 'liquor', 'glasses', 'brandy', 'entire', 'evening', 'going']\n","Stopwords Removed (Row 58): ['you', 'can', 'you', 'can', 'of', 'for', 'the', 'on', 'and', 'on']\n","Stopwords were removed for Row 58 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 59): ['you', 'need', 'not', 'be', 'so', 'grand', 'simply', 'because', 'you', 'do', 'not', 'happen', 'to', 'want', 'me', 'at', 'the', 'moment']\n","Updated Tokens (Row 59): ['need', 'grand', 'simply', 'happen', 'want', 'moment']\n","Stopwords Removed (Row 59): ['you', 'not', 'be', 'so', 'because', 'you', 'do', 'not', 'to', 'me', 'at', 'the']\n","Stopwords were removed for Row 59 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 60): ['amanda', 'really']\n","Updated Tokens (Row 60): ['amanda', 'really']\n","Stopwords Removed (Row 60): []\n","No stopwords removed for Row 60 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 61): ['nothing', 'are', 'you', 'going', 'out', 'somewhere', 'darling']\n","Updated Tokens (Row 61): ['nothing', 'going', 'somewhere', 'darling']\n","Stopwords Removed (Row 61): ['are', 'you', 'out']\n","Stopwords were removed for Row 61 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 62): ['um', 'well', 'that', 'reply', 'has', 'just', 'broken', 'my', 'heart']\n","Updated Tokens (Row 62): ['um', 'well', 'reply', 'broken', 'heart']\n","Stopwords Removed (Row 62): ['that', 'has', 'just', 'my']\n","Stopwords were removed for Row 62 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 63): ['oh', 'as', 'a', 'matter', 'of', 'fact', 'that', 'is', 'perfectly', 'true']\n","Updated Tokens (Row 63): ['oh', 'matter', 'fact', 'perfectly', 'true']\n","Stopwords Removed (Row 63): ['as', 'a', 'of', 'that', 'is']\n","Stopwords were removed for Row 63 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 64): ['yes', 'it', 'is']\n","Updated Tokens (Row 64): ['yes']\n","Stopwords Removed (Row 64): ['it', 'is']\n","Stopwords were removed for Row 64 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 65): ['it', 'is', 'a', 'pity', 'you', 'did', 'not', 'have', 'a', 'little', 'bit', 'more', 'brandy', 'it', 'might', 'have', 'made', 'you', 'a', 'little', 'less', 'disagreeable']\n","Updated Tokens (Row 65): ['pity', 'little', 'bit', 'brandy', 'might', 'made', 'little', 'less', 'disagreeable']\n","Stopwords Removed (Row 65): ['it', 'is', 'a', 'you', 'did', 'not', 'have', 'a', 'more', 'it', 'have', 'you', 'a']\n","Stopwords were removed for Row 65 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 66): ['oh', 'snap', 'snap', 'snap', 'like', 'a', 'little', 'adder']\n","Updated Tokens (Row 66): ['oh', 'snap', 'snap', 'snap', 'like', 'little', 'adder']\n","Stopwords Removed (Row 66): ['a']\n","Stopwords were removed for Row 66 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 67): ['nonsense', 'they', 'have', 'got', 'a', 'little', 'bag', 'of', 'venom', 'behind', 'their', 'fangs', 'and', 'they', 'snap']\n","Updated Tokens (Row 67): ['nonsense', 'got', 'little', 'bag', 'venom', 'behind', 'fangs', 'snap']\n","Stopwords Removed (Row 67): ['they', 'have', 'a', 'of', 'their', 'and', 'they']\n","Stopwords were removed for Row 67 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 68): ['they', 'snap']\n","Updated Tokens (Row 68): ['snap']\n","Stopwords Removed (Row 68): ['they']\n","Stopwords were removed for Row 68 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 69): ['so', 'did', 'you', 'see', 'much', 'of', 'peter', 'burden', 'after', 'the', 'divorce']\n","Updated Tokens (Row 69): ['see', 'much', 'peter', 'burden', 'divorce']\n","Stopwords Removed (Row 69): ['so', 'did', 'you', 'of', 'after', 'the']\n","Stopwords were removed for Row 69 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 70): ['you', 'must', 'have', 'let', 'him', 'kiss', 'you', 'quite', 'a', 'good', 'deal', 'more', 'then', 'huh']\n","Updated Tokens (Row 70): ['must', 'let', 'kiss', 'quite', 'good', 'deal', 'huh']\n","Stopwords Removed (Row 70): ['you', 'have', 'him', 'you', 'a', 'more', 'then']\n","Stopwords were removed for Row 70 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 71): ['i', 'sure', 'you', 'had', 'a', 'riotous', 'time', 'no', 'restrain', 'at', 'all', 'very', 'enjoyable', 'you', 'never', 'had', 'much', 'anyway']\n","Updated Tokens (Row 71): ['sure', 'riotous', 'time', 'restrain', 'enjoyable', 'never', 'much', 'anyway']\n","Stopwords Removed (Row 71): ['i', 'you', 'had', 'a', 'no', 'at', 'all', 'very', 'you', 'had']\n","Stopwords were removed for Row 71 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 72): ['i', 'am', 'not', 'the', 'slightest', 'bit', 'drunk']\n","Updated Tokens (Row 72): ['slightest', 'bit', 'drunk']\n","Stopwords Removed (Row 72): ['i', 'am', 'not', 'the']\n","Stopwords were removed for Row 72 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 73): ['i', 'do', 'believe', 'that', 'i', 'have', 'said', 'already', 'that', 'i', 'had', 'three', 'minuet', 'liquor', 'glasses', 'of', 'brandy', 'in', 'the', 'entire', 'evening', 'a', 'child', 'of', 'two', 'could', 'get', 'drunk', 'of', 'that']\n","Updated Tokens (Row 73): ['believe', 'said', 'already', 'three', 'minuet', 'liquor', 'glasses', 'brandy', 'entire', 'evening', 'child', 'two', 'could', 'get', 'drunk']\n","Stopwords Removed (Row 73): ['i', 'do', 'that', 'i', 'have', 'that', 'i', 'had', 'of', 'in', 'the', 'a', 'of', 'of', 'that']\n","Stopwords were removed for Row 73 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 74): ['oh', 'really', 'how', 'about', 'a', 'child', 'of', 'three', 'or', 'child', 'of', 'six', 'what', 'about', 'a', 'child', 'of', 'nine']\n","Updated Tokens (Row 74): ['oh', 'really', 'child', 'three', 'child', 'six', 'child', 'nine']\n","Stopwords Removed (Row 74): ['how', 'about', 'a', 'of', 'or', 'of', 'what', 'about', 'a', 'of']\n","Stopwords were removed for Row 74 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 75): ['you', 'know', 'we', 'could', 'get', 'a', 'really', 'good', 'debate', 'going', 'on', 'about', 'this', 'you', 'know', 'intemperate', 'tots']\n","Updated Tokens (Row 75): ['know', 'could', 'get', 'really', 'good', 'debate', 'going', 'know', 'intemperate', 'tots']\n","Stopwords Removed (Row 75): ['you', 'we', 'a', 'on', 'about', 'this', 'you']\n","Stopwords were removed for Row 75 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 76): ['you', 'know', 'what', 'that', 'is', 'a', 'very', 'good', 'idea', 'i', 'think', 'i', 'will']\n","Updated Tokens (Row 76): ['know', 'good', 'idea', 'think']\n","Stopwords Removed (Row 76): ['you', 'what', 'that', 'is', 'a', 'very', 'i', 'i', 'will']\n","Stopwords were removed for Row 76 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 77): ['you', 'better', 'turn', 'that', 'off', 'i', 'think']\n","Updated Tokens (Row 77): ['better', 'turn', 'think']\n","Stopwords Removed (Row 77): ['you', 'that', 'off', 'i']\n","Stopwords were removed for Row 77 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 78): ['because', 'it', 'is', 'very', 'late', 'and', 'you', 'disturb', 'the', 'people', 'upstairs']\n","Updated Tokens (Row 78): ['late', 'disturb', 'people', 'upstairs']\n","Stopwords Removed (Row 78): ['because', 'it', 'is', 'very', 'and', 'you', 'the']\n","Stopwords were removed for Row 78 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 79): ['well', 'there', 'are', 'people', 'downstairs', 'i', 'suppose']\n","Updated Tokens (Row 79): ['well', 'people', 'downstairs', 'suppose']\n","Stopwords Removed (Row 79): ['there', 'are', 'i']\n","Stopwords were removed for Row 79 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 80): ['this', 'is', 'no', 'time', 'of', 'the', 'year', 'for', 'tunis']\n","Updated Tokens (Row 80): ['time', 'year', 'tunis']\n","Stopwords Removed (Row 80): ['this', 'is', 'no', 'of', 'the', 'for']\n","Stopwords were removed for Row 80 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 81): ['i', 'do', 'i', 'shall', 'do', 'no', 'such', 'thing']\n","Updated Tokens (Row 81): ['shall', 'thing']\n","Stopwords Removed (Row 81): ['i', 'do', 'i', 'do', 'no', 'such']\n","Stopwords were removed for Row 81 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 82): ['turn', 'it', 'off', 'it', 'is', 'driving', 'me', 'mad']\n","Updated Tokens (Row 82): ['turn', 'driving', 'mad']\n","Stopwords Removed (Row 82): ['it', 'off', 'it', 'is', 'me']\n","Stopwords were removed for Row 82 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 83): ['turn', 'it', 'off']\n","Updated Tokens (Row 83): ['turn']\n","Stopwords Removed (Row 83): ['it', 'off']\n","Stopwords were removed for Row 83 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 84): ['very', 'amusing', 'indeed']\n","Updated Tokens (Row 84): ['amusing', 'indeed']\n","Stopwords Removed (Row 84): ['very']\n","Stopwords were removed for Row 84 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 85): ['ja', 'very', 'funny']\n","Updated Tokens (Row 85): ['ja', 'funny']\n","Stopwords Removed (Row 85): ['very']\n","Stopwords were removed for Row 85 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 86): ['you', 'are', 'a', 'vile', 'tempered', 'wicked', 'living', 'evil', 'little', 'beast', 'and', 'i', 'hope', 'i', 'never', 'set', 'eyes', 'on', 'you', 'ever', 'again']\n","Updated Tokens (Row 86): ['vile', 'tempered', 'wicked', 'living', 'evil', 'little', 'beast', 'hope', 'never', 'set', 'eyes', 'ever']\n","Stopwords Removed (Row 86): ['you', 'are', 'a', 'and', 'i', 'i', 'on', 'you', 'again']\n","Stopwords were removed for Row 86 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 87): ['oh', 'you', 'not', 'going', 'like', 'this']\n","Updated Tokens (Row 87): ['oh', 'going', 'like']\n","Stopwords Removed (Row 87): ['you', 'not', 'this']\n","Stopwords were removed for Row 87 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 88): ['garbage', 'no', 'you', 'not']\n","Updated Tokens (Row 88): ['garbage']\n","Stopwords Removed (Row 88): ['no', 'you', 'not']\n","Stopwords were removed for Row 88 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 89): ['oh', 'marry', 'you', 'again', 'i', 'would', 'not', 'marry', 'you', 'again', 'if', 'you', 'came', 'crawling', 'to', 'me', 'on', 'bended', 'knee']\n","Updated Tokens (Row 89): ['oh', 'marry', 'would', 'marry', 'came', 'crawling', 'bended', 'knee']\n","Stopwords Removed (Row 89): ['you', 'again', 'i', 'not', 'you', 'again', 'if', 'you', 'to', 'me', 'on']\n","Stopwords were removed for Row 89 in file Ses05M_script03_2.csv.\n","Original Tokens (Row 90): ['you', 'a', 'wicked', 'little', 'vampire', 'and', 'i', 'pray', 'to', 'god', 'i', 'never', 'set', 'eyes', 'on', 'you', 'again', 'as', 'long', 'as', 'i', 'live']\n","Updated Tokens (Row 90): ['wicked', 'little', 'vampire', 'pray', 'god', 'never', 'set', 'eyes', 'long', 'live']\n","Stopwords Removed (Row 90): ['you', 'a', 'and', 'i', 'to', 'i', 'on', 'you', 'again', 'as', 'as', 'i']\n","Stopwords were removed for Row 90 in file Ses05M_script03_2.csv.\n","Stopwords were removed in at least one row in the file: Ses05M_script03_2.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05M_script03_2.csv\n","\n","Processing File: Ses05F_impro02.csv\n","Original Tokens (Row 0): ['baby', 'i', 'need', 'you', 'to', 'sit', 'down']\n","Updated Tokens (Row 0): ['baby', 'need', 'sit']\n","Stopwords Removed (Row 0): ['i', 'you', 'to', 'down']\n","Stopwords were removed for Row 0 in file Ses05F_impro02.csv.\n","Original Tokens (Row 1): ['um']\n","Updated Tokens (Row 1): ['um']\n","Stopwords Removed (Row 1): []\n","No stopwords removed for Row 1 in file Ses05F_impro02.csv.\n","Original Tokens (Row 2): ['i', 'sorry', 'it', 'is', 'just', 'a', 'lot', 'ahh', 'to', 'explain', 'ahh', 'i', 'got', 'a', 'call']\n","Updated Tokens (Row 2): ['sorry', 'lot', 'ahh', 'explain', 'ahh', 'got', 'call']\n","Stopwords Removed (Row 2): ['i', 'it', 'is', 'just', 'a', 'to', 'i', 'a']\n","Stopwords were removed for Row 2 in file Ses05F_impro02.csv.\n","Original Tokens (Row 3): ['yeah', 'um', 'everything', 'fine', 'so', 'far', 'um']\n","Updated Tokens (Row 3): ['yeah', 'um', 'everything', 'fine', 'far', 'um']\n","Stopwords Removed (Row 3): ['so']\n","Stopwords were removed for Row 3 in file Ses05F_impro02.csv.\n","Original Tokens (Row 4): ['i', 'got', 'a', 'call', 'today']\n","Updated Tokens (Row 4): ['got', 'call', 'today']\n","Stopwords Removed (Row 4): ['i', 'a']\n","Stopwords were removed for Row 4 in file Ses05F_impro02.csv.\n","Original Tokens (Row 5): ['i', 'going', 'to', 'need', 'to', 'go', 'overseas', 'for', 'a', 'while']\n","Updated Tokens (Row 5): ['going', 'need', 'go', 'overseas']\n","Stopwords Removed (Row 5): ['i', 'to', 'to', 'for', 'a', 'while']\n","Stopwords were removed for Row 5 in file Ses05F_impro02.csv.\n","Original Tokens (Row 6): ['iraq']\n","Updated Tokens (Row 6): ['iraq']\n","Stopwords Removed (Row 6): []\n","No stopwords removed for Row 6 in file Ses05F_impro02.csv.\n","Original Tokens (Row 7): ['i', 'sorry', 'i', 'thought', 'so', 'sigh']\n","Updated Tokens (Row 7): ['sorry', 'thought', 'sigh']\n","Stopwords Removed (Row 7): ['i', 'i', 'so']\n","Stopwords were removed for Row 7 in file Ses05F_impro02.csv.\n","Original Tokens (Row 8): ['i', 'do', 'not', 'know', 'sigh']\n","Updated Tokens (Row 8): ['know', 'sigh']\n","Stopwords Removed (Row 8): ['i', 'do', 'not']\n","Stopwords were removed for Row 8 in file Ses05F_impro02.csv.\n","Original Tokens (Row 9): ['i', 'know', 'i', 'know']\n","Updated Tokens (Row 9): ['know', 'know']\n","Stopwords Removed (Row 9): ['i', 'i']\n","Stopwords were removed for Row 9 in file Ses05F_impro02.csv.\n","Original Tokens (Row 10): ['i', 'know', 'well', 'we', 'have', 'to', 'figure', 'all', 'that', 'out', 'i', 'mean', 'i', 'think', 'the', 'army', 'going', 'to', 'provide', 'childcare', 'and', 'help', 'us', 'out', 'with', 'that', 'um']\n","Updated Tokens (Row 10): ['know', 'well', 'figure', 'mean', 'think', 'army', 'going', 'provide', 'childcare', 'help', 'us', 'um']\n","Stopwords Removed (Row 10): ['i', 'we', 'have', 'to', 'all', 'that', 'out', 'i', 'i', 'the', 'to', 'and', 'out', 'with', 'that']\n","Stopwords were removed for Row 10 in file Ses05F_impro02.csv.\n","Original Tokens (Row 11): ['iraq']\n","Updated Tokens (Row 11): ['iraq']\n","Stopwords Removed (Row 11): []\n","No stopwords removed for Row 11 in file Ses05F_impro02.csv.\n","Original Tokens (Row 12): ['i', 'think', 'infantry', 'i', 'not', 'sure']\n","Updated Tokens (Row 12): ['think', 'infantry', 'sure']\n","Stopwords Removed (Row 12): ['i', 'i', 'not']\n","Stopwords were removed for Row 12 in file Ses05F_impro02.csv.\n","Original Tokens (Row 13): ['it', 'is', 'going', 'to', 'be', 'at', 'least', 'six', 'months', 'probably', 'a', 'year', 'i', 'tried']\n","Updated Tokens (Row 13): ['going', 'least', 'six', 'months', 'probably', 'year', 'tried']\n","Stopwords Removed (Row 13): ['it', 'is', 'to', 'be', 'at', 'a', 'i']\n","Stopwords were removed for Row 13 in file Ses05F_impro02.csv.\n","Original Tokens (Row 14): ['i', 'know', 'i', 'know', 'it', 'is', 'really', 'really', 'messed', 'up']\n","Updated Tokens (Row 14): ['know', 'know', 'really', 'really', 'messed']\n","Stopwords Removed (Row 14): ['i', 'i', 'it', 'is', 'up']\n","Stopwords were removed for Row 14 in file Ses05F_impro02.csv.\n","Original Tokens (Row 15): ['believe', 'me', 'if', 'i', 'had', 'a', 'choice', 'i', 'would', 'not', 'have', 'chosen', 'this']\n","Updated Tokens (Row 15): ['believe', 'choice', 'would', 'chosen']\n","Stopwords Removed (Row 15): ['me', 'if', 'i', 'had', 'a', 'i', 'not', 'have', 'this']\n","Stopwords were removed for Row 15 in file Ses05F_impro02.csv.\n","Original Tokens (Row 16): ['you', 'do', 'not', 'know', 'how', 'to', 'what', 'you', 'be', 'fine', 'i', 'mean', 'you', 'a', 'great', 'parent', 'i', 'know']\n","Updated Tokens (Row 16): ['know', 'fine', 'mean', 'great', 'parent', 'know']\n","Stopwords Removed (Row 16): ['you', 'do', 'not', 'how', 'to', 'what', 'you', 'be', 'i', 'you', 'a', 'i']\n","Stopwords were removed for Row 16 in file Ses05F_impro02.csv.\n","Original Tokens (Row 17): ['well', 'maybe', 'you', 'should', 'move', 'in', 'with', 'my', 'mom', 'and', 'she', 'can', 'help']\n","Updated Tokens (Row 17): ['well', 'maybe', 'move', 'mom', 'help']\n","Stopwords Removed (Row 17): ['you', 'should', 'in', 'with', 'my', 'and', 'she', 'can']\n","Stopwords were removed for Row 17 in file Ses05F_impro02.csv.\n","Original Tokens (Row 18): ['i', 'do', 'not', 'know', 'i', 'just', 'i', 'trying', 'to', 'think', 'of', 'something']\n","Updated Tokens (Row 18): ['know', 'trying', 'think', 'something']\n","Stopwords Removed (Row 18): ['i', 'do', 'not', 'i', 'just', 'i', 'to', 'of']\n","Stopwords were removed for Row 18 in file Ses05F_impro02.csv.\n","Original Tokens (Row 19): ['she', 'likes', 'you', 'of', 'course', 'she', 'likes', 'you']\n","Updated Tokens (Row 19): ['likes', 'course', 'likes']\n","Stopwords Removed (Row 19): ['she', 'you', 'of', 'she', 'you']\n","Stopwords were removed for Row 19 in file Ses05F_impro02.csv.\n","Original Tokens (Row 20): ['you', 'can', 'not', 'what']\n","Updated Tokens (Row 20): []\n","Stopwords Removed (Row 20): ['you', 'can', 'not', 'what']\n","Stopwords were removed for Row 20 in file Ses05F_impro02.csv.\n","Original Tokens (Row 21): ['i', 'do', 'not', 'think', 'there', 'anything', 'we', 'can', 'do']\n","Updated Tokens (Row 21): ['think', 'anything']\n","Stopwords Removed (Row 21): ['i', 'do', 'not', 'there', 'we', 'can', 'do']\n","Stopwords were removed for Row 21 in file Ses05F_impro02.csv.\n","Original Tokens (Row 22): ['well', 'we', 'can', 'try', 'it', 'baby', 'do', 'not', 'beg', 'me', 'i', 'mean', 'if', 'there', 'were', 'anything', 'that', 'i', 'could', 'do', 'i', 'would', 'do', 'it', 'believe', 'me', 'this', 'is', 'not', 'what', 'i', 'want']\n","Updated Tokens (Row 22): ['well', 'try', 'baby', 'beg', 'mean', 'anything', 'could', 'would', 'believe', 'want']\n","Stopwords Removed (Row 22): ['we', 'can', 'it', 'do', 'not', 'me', 'i', 'if', 'there', 'were', 'that', 'i', 'do', 'i', 'do', 'it', 'me', 'this', 'is', 'not', 'what', 'i']\n","Stopwords were removed for Row 22 in file Ses05F_impro02.csv.\n","Original Tokens (Row 23): ['i', 'know', 'i', 'know', 'it', 'is', 'not', 'fair']\n","Updated Tokens (Row 23): ['know', 'know', 'fair']\n","Stopwords Removed (Row 23): ['i', 'i', 'it', 'is', 'not']\n","Stopwords were removed for Row 23 in file Ses05F_impro02.csv.\n","Original Tokens (Row 24): ['well', 'apparently', 'nobody', 'else', 'can', 'go']\n","Updated Tokens (Row 24): ['well', 'apparently', 'nobody', 'else', 'go']\n","Stopwords Removed (Row 24): ['can']\n","Stopwords were removed for Row 24 in file Ses05F_impro02.csv.\n","Original Tokens (Row 25): ['i', 'do', 'not', 'know', 'baby', 'why', 'are', 'you', 'asking', 'me', 'this', 'it', 'is', 'just', 'as', 'hard', 'for', 'me', 'please', 'try', 'to', 'understand', 'that']\n","Updated Tokens (Row 25): ['know', 'baby', 'asking', 'hard', 'please', 'try', 'understand']\n","Stopwords Removed (Row 25): ['i', 'do', 'not', 'why', 'are', 'you', 'me', 'this', 'it', 'is', 'just', 'as', 'for', 'me', 'to', 'that']\n","Stopwords were removed for Row 25 in file Ses05F_impro02.csv.\n","Original Tokens (Row 26): ['i', 'understand', 'baby', 'i', 'sorry', 'i', 'mean', 'try', 'to', 'understand', 'i', 'i', 'scared', 'myself']\n","Updated Tokens (Row 26): ['understand', 'baby', 'sorry', 'mean', 'try', 'understand', 'scared']\n","Stopwords Removed (Row 26): ['i', 'i', 'i', 'to', 'i', 'i', 'myself']\n","Stopwords were removed for Row 26 in file Ses05F_impro02.csv.\n","Original Tokens (Row 27): ['i', 'know']\n","Updated Tokens (Row 27): ['know']\n","Stopwords Removed (Row 27): ['i']\n","Stopwords were removed for Row 27 in file Ses05F_impro02.csv.\n","Original Tokens (Row 28): ['i', 'know']\n","Updated Tokens (Row 28): ['know']\n","Stopwords Removed (Row 28): ['i']\n","Stopwords were removed for Row 28 in file Ses05F_impro02.csv.\n","Original Tokens (Row 29): ['we', 'figure', 'something', 'out', 'we', 'just', 'have', 'to', 'we', 'just', 'have', 'to', 'think', 'about', 'this', 'could', 'any', 'of', 'your', 'family', 'help', 'us']\n","Updated Tokens (Row 29): ['figure', 'something', 'think', 'could', 'family', 'help', 'us']\n","Stopwords Removed (Row 29): ['we', 'out', 'we', 'just', 'have', 'to', 'we', 'just', 'have', 'to', 'about', 'this', 'any', 'of', 'your']\n","Stopwords were removed for Row 29 in file Ses05F_impro02.csv.\n","Original Tokens (Row 30): ['maybe', 'we', 'should', 'call', 'your', 'parents']\n","Updated Tokens (Row 30): ['maybe', 'call', 'parents']\n","Stopwords Removed (Row 30): ['we', 'should', 'your']\n","Stopwords were removed for Row 30 in file Ses05F_impro02.csv.\n","Original Tokens (Row 31): ['i', 'going', 'to', 'miss', 'their', 'first', 'words']\n","Updated Tokens (Row 31): ['going', 'miss', 'first', 'words']\n","Stopwords Removed (Row 31): ['i', 'to', 'their']\n","Stopwords were removed for Row 31 in file Ses05F_impro02.csv.\n","Original Tokens (Row 32): ['you', 'have', 'to', 'send', 'me', 'pictures', 'and', 'letters', 'everyday']\n","Updated Tokens (Row 32): ['send', 'pictures', 'letters', 'everyday']\n","Stopwords Removed (Row 32): ['you', 'have', 'to', 'me', 'and']\n","Stopwords were removed for Row 32 in file Ses05F_impro02.csv.\n","Original Tokens (Row 33): ['i', 'do', 'not', 'know', 'i', 'hope', 'so']\n","Updated Tokens (Row 33): ['know', 'hope']\n","Stopwords Removed (Row 33): ['i', 'do', 'not', 'i', 'so']\n","Stopwords were removed for Row 33 in file Ses05F_impro02.csv.\n","Original Tokens (Row 34): ['yeah', 'as', 'much', 'as', 'i', 'can']\n","Updated Tokens (Row 34): ['yeah', 'much']\n","Stopwords Removed (Row 34): ['as', 'as', 'i', 'can']\n","Stopwords were removed for Row 34 in file Ses05F_impro02.csv.\n","Original Tokens (Row 35): ['sigh', 'three', 'weeks']\n","Updated Tokens (Row 35): ['sigh', 'three', 'weeks']\n","Stopwords Removed (Row 35): []\n","No stopwords removed for Row 35 in file Ses05F_impro02.csv.\n","Original Tokens (Row 36): ['yeah']\n","Updated Tokens (Row 36): ['yeah']\n","Stopwords Removed (Row 36): []\n","No stopwords removed for Row 36 in file Ses05F_impro02.csv.\n","Original Tokens (Row 37): ['yeah']\n","Updated Tokens (Row 37): ['yeah']\n","Stopwords Removed (Row 37): []\n","No stopwords removed for Row 37 in file Ses05F_impro02.csv.\n","Original Tokens (Row 38): ['i', 'love', 'you', 'i', 'going', 'to', 'miss', 'you', 'so', 'much', 'sigh']\n","Updated Tokens (Row 38): ['love', 'going', 'miss', 'much', 'sigh']\n","Stopwords Removed (Row 38): ['i', 'you', 'i', 'to', 'you', 'so']\n","Stopwords were removed for Row 38 in file Ses05F_impro02.csv.\n","Original Tokens (Row 39): ['what', 'is', 'it']\n","Updated Tokens (Row 39): []\n","Stopwords Removed (Row 39): ['what', 'is', 'it']\n","Stopwords were removed for Row 39 in file Ses05F_impro02.csv.\n","Original Tokens (Row 40): ['you', 'can', 'say', 'it']\n","Updated Tokens (Row 40): ['say']\n","Stopwords Removed (Row 40): ['you', 'can', 'it']\n","Stopwords were removed for Row 40 in file Ses05F_impro02.csv.\n","Original Tokens (Row 41): ['are', 'you', 'all', 'right']\n","Updated Tokens (Row 41): ['right']\n","Stopwords Removed (Row 41): ['are', 'you', 'all']\n","Stopwords were removed for Row 41 in file Ses05F_impro02.csv.\n","Original Tokens (Row 42): ['okay']\n","Updated Tokens (Row 42): ['okay']\n","Stopwords Removed (Row 42): []\n","No stopwords removed for Row 42 in file Ses05F_impro02.csv.\n","Original Tokens (Row 43): ['you', 'got', 'called', 'up']\n","Updated Tokens (Row 43): ['got', 'called']\n","Stopwords Removed (Row 43): ['you', 'up']\n","Stopwords were removed for Row 43 in file Ses05F_impro02.csv.\n","Original Tokens (Row 44): ['i', 'thought', 'you', 'said', 'this', 'was', 'not', 'going', 'to', 'happen', 'for', 'at', 'least', 'a', 'year']\n","Updated Tokens (Row 44): ['thought', 'said', 'going', 'happen', 'least', 'year']\n","Stopwords Removed (Row 44): ['i', 'you', 'this', 'was', 'not', 'to', 'for', 'at', 'a']\n","Stopwords were removed for Row 44 in file Ses05F_impro02.csv.\n","Original Tokens (Row 45): ['what', 'am', 'i', 'going', 'to', 'do']\n","Updated Tokens (Row 45): ['going']\n","Stopwords Removed (Row 45): ['what', 'am', 'i', 'to', 'do']\n","Stopwords were removed for Row 45 in file Ses05F_impro02.csv.\n","Original Tokens (Row 46): ['i', 'can', 'not', 'do', 'this', 'by', 'myself', 'i', 'i', 'do', 'not', 'know', 'how', 'to', 'do', 'this', 'you', 'know', 'how', 'to', 'do', 'this']\n","Updated Tokens (Row 46): ['know', 'know']\n","Stopwords Removed (Row 46): ['i', 'can', 'not', 'do', 'this', 'by', 'myself', 'i', 'i', 'do', 'not', 'how', 'to', 'do', 'this', 'you', 'how', 'to', 'do', 'this']\n","Stopwords were removed for Row 46 in file Ses05F_impro02.csv.\n","Original Tokens (Row 47): ['the', 'kids']\n","Updated Tokens (Row 47): ['kids']\n","Stopwords Removed (Row 47): ['the']\n","Stopwords were removed for Row 47 in file Ses05F_impro02.csv.\n","Original Tokens (Row 48): ['nobody', 'even', 'here', 'your', 'parents', 'live', 'on', 'the', 'other', 'side', 'of', 'the', 'country']\n","Updated Tokens (Row 48): ['nobody', 'even', 'parents', 'live', 'side', 'country']\n","Stopwords Removed (Row 48): ['here', 'your', 'on', 'the', 'other', 'of', 'the']\n","Stopwords were removed for Row 48 in file Ses05F_impro02.csv.\n","Original Tokens (Row 49): ['where', 'do', 'you', 'have', 'to', 'go', 'where', 'are', 'you', 'going']\n","Updated Tokens (Row 49): ['go', 'going']\n","Stopwords Removed (Row 49): ['where', 'do', 'you', 'have', 'to', 'where', 'are', 'you']\n","Stopwords were removed for Row 49 in file Ses05F_impro02.csv.\n","Original Tokens (Row 50): ['what', 'are', 'you', 'going', 'to', 'do', 'there', 'is', 'it', 'going', 'to', 'be', 'dangerous', 'what', 'are', 'you']\n","Updated Tokens (Row 50): ['going', 'going', 'dangerous']\n","Stopwords Removed (Row 50): ['what', 'are', 'you', 'to', 'do', 'there', 'is', 'it', 'to', 'be', 'what', 'are', 'you']\n","Stopwords were removed for Row 50 in file Ses05F_impro02.csv.\n","Original Tokens (Row 51): ['it', 'is']\n","Updated Tokens (Row 51): []\n","Stopwords Removed (Row 51): ['it', 'is']\n","Stopwords were removed for Row 51 in file Ses05F_impro02.csv.\n","Original Tokens (Row 52): ['can', 'we', 'do', 'something', 'else', 'can', 'you', 'tell', 'them', 'that', 'you', 'just', 'had', 'two', 'kids']\n","Updated Tokens (Row 52): ['something', 'else', 'tell', 'two', 'kids']\n","Stopwords Removed (Row 52): ['can', 'we', 'do', 'can', 'you', 'them', 'that', 'you', 'just', 'had']\n","Stopwords were removed for Row 52 in file Ses05F_impro02.csv.\n","Original Tokens (Row 53): ['i', 'do', 'not', 'understand', 'why', 'they', 'would', 'just', 'do', 'something', 'like', 'this']\n","Updated Tokens (Row 53): ['understand', 'would', 'something', 'like']\n","Stopwords Removed (Row 53): ['i', 'do', 'not', 'why', 'they', 'just', 'do', 'this']\n","Stopwords were removed for Row 53 in file Ses05F_impro02.csv.\n","Original Tokens (Row 54): ['it', 'does', 'not', 'make', 'any', 'sense', 'it', 'is', 'stupid', 'i', 'told', 'you', 'you', 'should', 'not', 'go', 'in', 'the', 'army']\n","Updated Tokens (Row 54): ['make', 'sense', 'stupid', 'told', 'go', 'army']\n","Stopwords Removed (Row 54): ['it', 'does', 'not', 'any', 'it', 'is', 'i', 'you', 'you', 'should', 'not', 'in', 'the']\n","Stopwords were removed for Row 54 in file Ses05F_impro02.csv.\n","Original Tokens (Row 55): ['i', 'do', 'not', 'know', 'i', 'do', 'not', 'know', 'what', 'i', 'going', 'to', 'do', 'i', 'do', 'not', 'know', 'how', 'to']\n","Updated Tokens (Row 55): ['know', 'know', 'going', 'know']\n","Stopwords Removed (Row 55): ['i', 'do', 'not', 'i', 'do', 'not', 'what', 'i', 'to', 'do', 'i', 'do', 'not', 'how', 'to']\n","Stopwords were removed for Row 55 in file Ses05F_impro02.csv.\n","Original Tokens (Row 56): ['they', 'are', 'six', 'months', 'old', 'six', 'months', 'old', 'they', 'are', 'tiny']\n","Updated Tokens (Row 56): ['six', 'months', 'old', 'six', 'months', 'old', 'tiny']\n","Stopwords Removed (Row 56): ['they', 'are', 'they', 'are']\n","Stopwords were removed for Row 56 in file Ses05F_impro02.csv.\n","Original Tokens (Row 57): ['i', 'can', 'not', 'do', 'this', 'i', 'never', 'done', 'this', 'before', 'i', 'do', 'not', 'know', 'anything', 'about', 'this']\n","Updated Tokens (Row 57): ['never', 'done', 'know', 'anything']\n","Stopwords Removed (Row 57): ['i', 'can', 'not', 'do', 'this', 'i', 'this', 'before', 'i', 'do', 'not', 'about', 'this']\n","Stopwords were removed for Row 57 in file Ses05F_impro02.csv.\n","Original Tokens (Row 58): ['your', 'your', 'mom', 'you', 'want', 'me', 'to', 'move', 'in', 'with', 'your', 'mom']\n","Updated Tokens (Row 58): ['mom', 'want', 'move', 'mom']\n","Stopwords Removed (Row 58): ['your', 'your', 'you', 'me', 'to', 'in', 'with', 'your']\n","Stopwords were removed for Row 58 in file Ses05F_impro02.csv.\n","Original Tokens (Row 59): ['she', 'does', 'not', 'even', 'like', 'me', 'she', 'is', 'never', 'liked', 'me', 'no']\n","Updated Tokens (Row 59): ['even', 'like', 'never', 'liked']\n","Stopwords Removed (Row 59): ['she', 'does', 'not', 'me', 'she', 'is', 'me', 'no']\n","Stopwords were removed for Row 59 in file Ses05F_impro02.csv.\n","Original Tokens (Row 60): ['she', 'likes', 'you', 'she', 'likes', 'the', 'kids']\n","Updated Tokens (Row 60): ['likes', 'likes', 'kids']\n","Stopwords Removed (Row 60): ['she', 'you', 'she', 'the']\n","Stopwords were removed for Row 60 in file Ses05F_impro02.csv.\n","Original Tokens (Row 61): ['i', 'no', 'i', 'can', 'not', 'sigh']\n","Updated Tokens (Row 61): ['sigh']\n","Stopwords Removed (Row 61): ['i', 'no', 'i', 'can', 'not']\n","Stopwords were removed for Row 61 in file Ses05F_impro02.csv.\n","Original Tokens (Row 62): ['i', 'can', 'not', 'let', 'you', 'go', 'i', 'can', 'not', 'let', 'you', 'go', 'i', 'call', 'them', 'i', 'say', 'something', 'i', 'do', 'anything', 'i', 'tell', 'them', 'something', 'different']\n","Updated Tokens (Row 62): ['let', 'go', 'let', 'go', 'call', 'say', 'something', 'anything', 'tell', 'something', 'different']\n","Stopwords Removed (Row 62): ['i', 'can', 'not', 'you', 'i', 'can', 'not', 'you', 'i', 'them', 'i', 'i', 'do', 'i', 'them']\n","Stopwords were removed for Row 62 in file Ses05F_impro02.csv.\n","Original Tokens (Row 63): ['i', 'tell', 'them', 'i', 'sick', 'and', 'that', 'you', 'can', 'not', 'leave', 'something']\n","Updated Tokens (Row 63): ['tell', 'sick', 'leave', 'something']\n","Stopwords Removed (Row 63): ['i', 'them', 'i', 'and', 'that', 'you', 'can', 'not']\n","Stopwords were removed for Row 63 in file Ses05F_impro02.csv.\n","Original Tokens (Row 64): ['it', 'is', 'not', 'fair']\n","Updated Tokens (Row 64): ['fair']\n","Stopwords Removed (Row 64): ['it', 'is', 'not']\n","Stopwords were removed for Row 64 in file Ses05F_impro02.csv.\n","Original Tokens (Row 65): ['why', 'has', 'to', 'be', 'you', 'there', 'all', 'those', 'other', 'people', 'somebody', 'else', 'can', 'go', 'instead', 'it', 'is', 'not', 'right']\n","Updated Tokens (Row 65): ['people', 'somebody', 'else', 'go', 'instead', 'right']\n","Stopwords Removed (Row 65): ['why', 'has', 'to', 'be', 'you', 'there', 'all', 'those', 'other', 'can', 'it', 'is', 'not']\n","Stopwords were removed for Row 65 in file Ses05F_impro02.csv.\n","Original Tokens (Row 66): ['what', 'are', 'you', 'going', 'to', 'do', 'that', 'is', 'any', 'different', 'than', 'anybody', 'else']\n","Updated Tokens (Row 66): ['going', 'different', 'anybody', 'else']\n","Stopwords Removed (Row 66): ['what', 'are', 'you', 'to', 'do', 'that', 'is', 'any', 'than']\n","Stopwords were removed for Row 66 in file Ses05F_impro02.csv.\n","Original Tokens (Row 67): ['i', 'do', 'not', 'know', 'it', 'is', 'not', 'me', 'so', 'i', 'the', 'one', 'who', 'has', 'to', 'stay', 'here', 'i', 'the', 'one', 'who', 'has', 'to', 'take', 'care', 'of', 'them', 'and', 'i', 'do', 'not', 'have-i', 'do', 'not', 'have', 'anybody', 'else', 'you', 'all', 'i', 'have']\n","Updated Tokens (Row 67): ['know', 'one', 'stay', 'one', 'take', 'care', 'have-i', 'anybody', 'else']\n","Stopwords Removed (Row 67): ['i', 'do', 'not', 'it', 'is', 'not', 'me', 'so', 'i', 'the', 'who', 'has', 'to', 'here', 'i', 'the', 'who', 'has', 'to', 'of', 'them', 'and', 'i', 'do', 'not', 'do', 'not', 'have', 'you', 'all', 'i', 'have']\n","Stopwords were removed for Row 67 in file Ses05F_impro02.csv.\n","Original Tokens (Row 68): ['i', 'understand', 'i', 'worried', 'about', 'you', 'i', 'do', 'not', 'know', 'what', 'is', 'going', 'to', 'happen', 'to', 'you']\n","Updated Tokens (Row 68): ['understand', 'worried', 'know', 'going', 'happen']\n","Stopwords Removed (Row 68): ['i', 'i', 'about', 'you', 'i', 'do', 'not', 'what', 'is', 'to', 'to', 'you']\n","Stopwords were removed for Row 68 in file Ses05F_impro02.csv.\n","Original Tokens (Row 69): ['iraq', 'of', 'all-come', 'on', 'people', 'die', 'every', 'day']\n","Updated Tokens (Row 69): ['iraq', 'all-come', 'people', 'die', 'every', 'day']\n","Stopwords Removed (Row 69): ['of', 'on']\n","Stopwords were removed for Row 69 in file Ses05F_impro02.csv.\n","Original Tokens (Row 70): ['i', 'jus']\n","Updated Tokens (Row 70): ['jus']\n","Stopwords Removed (Row 70): ['i']\n","Stopwords were removed for Row 70 in file Ses05F_impro02.csv.\n","Original Tokens (Row 71): ['i', 'do', 'not', 'know']\n","Updated Tokens (Row 71): ['know']\n","Stopwords Removed (Row 71): ['i', 'do', 'not']\n","Stopwords were removed for Row 71 in file Ses05F_impro02.csv.\n","Original Tokens (Row 72): ['yeah', 'i', 'guess', 'i', 'do', 'not', 'know', 'what', 'they', 'are', 'going', 'to', 'say']\n","Updated Tokens (Row 72): ['yeah', 'guess', 'know', 'going', 'say']\n","Stopwords Removed (Row 72): ['i', 'i', 'do', 'not', 'what', 'they', 'are', 'to']\n","Stopwords were removed for Row 72 in file Ses05F_impro02.csv.\n","Original Tokens (Row 73): ['yeah', 'we', 'call', 'them', 'we', 'figure', 'something', 'out', 'i', 'sorry', 'i', 'sorry', 'i', 'sorry', 'you', 'right']\n","Updated Tokens (Row 73): ['yeah', 'call', 'figure', 'something', 'sorry', 'sorry', 'sorry', 'right']\n","Stopwords Removed (Row 73): ['we', 'them', 'we', 'out', 'i', 'i', 'i', 'you']\n","Stopwords were removed for Row 73 in file Ses05F_impro02.csv.\n","Original Tokens (Row 74): ['i', 'know']\n","Updated Tokens (Row 74): ['know']\n","Stopwords Removed (Row 74): ['i']\n","Stopwords were removed for Row 74 in file Ses05F_impro02.csv.\n","Original Tokens (Row 75): ['all', 'the', 'time', 'every', 'day', 'every', 'day', 'they', 'have', 'e-mail', 'over', 'there', 'and', 'stuff', 'like', 'that', 'right', 'i', 'can', 'send', 'you', 'pictures']\n","Updated Tokens (Row 75): ['time', 'every', 'day', 'every', 'day', 'e-mail', 'stuff', 'like', 'right', 'send', 'pictures']\n","Stopwords Removed (Row 75): ['all', 'the', 'they', 'have', 'over', 'there', 'and', 'that', 'i', 'can', 'you']\n","Stopwords were removed for Row 75 in file Ses05F_impro02.csv.\n","Original Tokens (Row 76): ['you', 'have', 'to', 'call', 'me', 'all', 'the', 'time', 'whenever', 'you', 'can', 'you', 'have', 'to', 'tell', 'me', 'what', 'you', 'doing', 'and', 'how', 'you', 'doing', 'okay']\n","Updated Tokens (Row 76): ['call', 'time', 'whenever', 'tell', 'okay']\n","Stopwords Removed (Row 76): ['you', 'have', 'to', 'me', 'all', 'the', 'you', 'can', 'you', 'have', 'to', 'me', 'what', 'you', 'doing', 'and', 'how', 'you', 'doing']\n","Stopwords were removed for Row 76 in file Ses05F_impro02.csv.\n","Original Tokens (Row 77): ['how', 'long', 'do', 'we', 'have', 'when', 'do', 'you', 'leave']\n","Updated Tokens (Row 77): ['long', 'leave']\n","Stopwords Removed (Row 77): ['how', 'do', 'we', 'have', 'when', 'do', 'you']\n","Stopwords were removed for Row 77 in file Ses05F_impro02.csv.\n","Original Tokens (Row 78): ['three', 'weeks']\n","Updated Tokens (Row 78): ['three', 'weeks']\n","Stopwords Removed (Row 78): []\n","No stopwords removed for Row 78 in file Ses05F_impro02.csv.\n","Original Tokens (Row 79): ['i', 'do', 'not', 'okay', 'okay', 'we', 'can', 'do', 'this', 'we', 'can', 'do', 'this', 'it', 'is', 'okay', 'we', 'make', 'it', 'work']\n","Updated Tokens (Row 79): ['okay', 'okay', 'okay', 'make', 'work']\n","Stopwords Removed (Row 79): ['i', 'do', 'not', 'we', 'can', 'do', 'this', 'we', 'can', 'do', 'this', 'it', 'is', 'we', 'it']\n","Stopwords were removed for Row 79 in file Ses05F_impro02.csv.\n","Original Tokens (Row 80): ['i', 'love', 'you']\n","Updated Tokens (Row 80): ['love']\n","Stopwords Removed (Row 80): ['i', 'you']\n","Stopwords were removed for Row 80 in file Ses05F_impro02.csv.\n","Stopwords were removed in at least one row in the file: Ses05F_impro02.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05F_impro02.csv\n","\n","Processing File: Ses05F_impro04.csv\n","Original Tokens (Row 0): ['brian', 'i', 'need', 'help']\n","Updated Tokens (Row 0): ['brian', 'need', 'help']\n","Stopwords Removed (Row 0): ['i']\n","Stopwords were removed for Row 0 in file Ses05F_impro04.csv.\n","Original Tokens (Row 1): ['i', 'do', 'not', 'i', 'just', 'i', 'thinking', 'maybe', 'i', 'should', 'move', 'back', 'home', 'or', 'something', 'i', 'do', 'not', 'i', 'do', 'not', 'know', 'what', 'to', 'do', 'i', 'can', 'not', 'i', 'cant', 'keep', 'living', 'the', 'way', 'i', 'living']\n","Updated Tokens (Row 1): ['thinking', 'maybe', 'move', 'back', 'home', 'something', 'know', 'cant', 'keep', 'living', 'way', 'living']\n","Stopwords Removed (Row 1): ['i', 'do', 'not', 'i', 'just', 'i', 'i', 'should', 'or', 'i', 'do', 'not', 'i', 'do', 'not', 'what', 'to', 'do', 'i', 'can', 'not', 'i', 'the', 'i']\n","Stopwords were removed for Row 1 in file Ses05F_impro04.csv.\n","Original Tokens (Row 2): ['i', 'do', 'not', 'know', 'i', 'mean', 'what', 'am', 'i', 'supposed', 'to', 'do', 'i', 'it', 'is', 'not', 'for', 'lack', 'of', 'effort', 'i', 'been', 'trying']\n","Updated Tokens (Row 2): ['know', 'mean', 'supposed', 'lack', 'effort', 'trying']\n","Stopwords Removed (Row 2): ['i', 'do', 'not', 'i', 'what', 'am', 'i', 'to', 'do', 'i', 'it', 'is', 'not', 'for', 'of', 'i', 'been']\n","Stopwords were removed for Row 2 in file Ses05F_impro04.csv.\n","Original Tokens (Row 3): ['how', 'did', 'you', 'get', 'a', 'job', 'what', 'am', 'i', 'what', 'am', 'i', 'supposed', 'to', 'do']\n","Updated Tokens (Row 3): ['get', 'job', 'supposed']\n","Stopwords Removed (Row 3): ['how', 'did', 'you', 'a', 'what', 'am', 'i', 'what', 'am', 'i', 'to', 'do']\n","Stopwords were removed for Row 3 in file Ses05F_impro04.csv.\n","Original Tokens (Row 4): ['i', 'mean', 'i', 'just', 'do', 'not', 'i', 'do', 'not', 'know', 'if', 'you', 'do', 'not', 'have', 'a', 'lot', 'of', 'qualification', 'where', 'do', 'you', 'where', 'do', 'you', 'find', 'work', 'it', 'is', 'like', 'l.a.', 'is', 'so', 'frustrating', 'because', 'if', 'you', 'do', 'not', 'know', 'somebody', 'you', 'can', 'not', '-you', 'can', 'not', 'get', 'a', 'job', 'it', 'is', 'impossible', 'it', 'is', 'totally', 'discriminatory', 'you', 'have', 'to', 'know', 'somebody']\n","Updated Tokens (Row 4): ['mean', 'know', 'lot', 'qualification', 'find', 'work', 'like', 'l.a.', 'frustrating', 'know', 'somebody', '-you', 'get', 'job', 'impossible', 'totally', 'discriminatory', 'know', 'somebody']\n","Stopwords Removed (Row 4): ['i', 'i', 'just', 'do', 'not', 'i', 'do', 'not', 'if', 'you', 'do', 'not', 'have', 'a', 'of', 'where', 'do', 'you', 'where', 'do', 'you', 'it', 'is', 'is', 'so', 'because', 'if', 'you', 'do', 'not', 'you', 'can', 'not', 'can', 'not', 'a', 'it', 'is', 'it', 'is', 'you', 'have', 'to']\n","Stopwords were removed for Row 4 in file Ses05F_impro04.csv.\n","Original Tokens (Row 5): ['it', 'is', 'not', 'fair']\n","Updated Tokens (Row 5): ['fair']\n","Stopwords Removed (Row 5): ['it', 'is', 'not']\n","Stopwords were removed for Row 5 in file Ses05F_impro04.csv.\n","Original Tokens (Row 6): ['that', 'is', 'fine', 'i', 'be', 'willing', 'to', 'start', 'anywhere', 'i', 'can', 'not', 'get', 'a', 'job']\n","Updated Tokens (Row 6): ['fine', 'willing', 'start', 'anywhere', 'get', 'job']\n","Stopwords Removed (Row 6): ['that', 'is', 'i', 'be', 'to', 'i', 'can', 'not', 'a']\n","Stopwords were removed for Row 6 in file Ses05F_impro04.csv.\n","Original Tokens (Row 7): ['i', 'mean', 'on', 'six', 'seven', 'and', 'five', 'an', 'hour', 'does', 'not', 'does', 'not', 'pay', 'the', 'bills', 'i', 'mean']\n","Updated Tokens (Row 7): ['mean', 'six', 'seven', 'five', 'hour', 'pay', 'bills', 'mean']\n","Stopwords Removed (Row 7): ['i', 'on', 'and', 'an', 'does', 'not', 'does', 'not', 'the', 'i']\n","Stopwords were removed for Row 7 in file Ses05F_impro04.csv.\n","Original Tokens (Row 8): ['i', 'still', 'can', 'not', 'live', 'on', 'in', 'six', 'seven', 'and', 'five', 'it', 'is', 'not', 'possible', 'in', 'los', 'angeles', 'housing', 'is', 'too', 'expensive']\n","Updated Tokens (Row 8): ['still', 'live', 'six', 'seven', 'five', 'possible', 'los', 'angeles', 'housing', 'expensive']\n","Stopwords Removed (Row 8): ['i', 'can', 'not', 'on', 'in', 'and', 'it', 'is', 'not', 'in', 'is', 'too']\n","Stopwords were removed for Row 8 in file Ses05F_impro04.csv.\n","Original Tokens (Row 9): ['i', 'mean', 'i', 'can', 'do', 'the', 'mcdonald', 'thing', 'for', 'a', 'while', 'as', 'humiliating', 'as', 'that', 'is', 'but', 'i', 'mean', 'then', 'what', 'i', 'mean', 'you', 'can', 'not', 'exactly', 'move', 'up', 'in', 'that', 'kind', 'of', 'industry']\n","Updated Tokens (Row 9): ['mean', 'mcdonald', 'thing', 'humiliating', 'mean', 'mean', 'exactly', 'move', 'kind', 'industry']\n","Stopwords Removed (Row 9): ['i', 'i', 'can', 'do', 'the', 'for', 'a', 'while', 'as', 'as', 'that', 'is', 'but', 'i', 'then', 'what', 'i', 'you', 'can', 'not', 'up', 'in', 'that', 'of']\n","Stopwords were removed for Row 9 in file Ses05F_impro04.csv.\n","Original Tokens (Row 10): ['oh', 'come', 'on', 'that', 'is', 'not', 'what', 'i', 'envisioned', 'for', 'myself', 'honestly', 'would', 'you', 'settle', 'for', 'being', 'a', 'manager', 'at', 'mcdonalds']\n","Updated Tokens (Row 10): ['oh', 'come', 'envisioned', 'honestly', 'would', 'settle', 'manager', 'mcdonalds']\n","Stopwords Removed (Row 10): ['on', 'that', 'is', 'not', 'what', 'i', 'for', 'myself', 'you', 'for', 'being', 'a', 'at']\n","Stopwords were removed for Row 10 in file Ses05F_impro04.csv.\n","Original Tokens (Row 11): ['this', 'is', 'humiliating']\n","Updated Tokens (Row 11): ['humiliating']\n","Stopwords Removed (Row 11): ['this', 'is']\n","Stopwords were removed for Row 11 in file Ses05F_impro04.csv.\n","Original Tokens (Row 12): ['no', 'i', 'do', 'not', 'i', 'do', 'not', 'want', 'to', 'accept', 'that', 'i', 'think', 'that', 'is', 'bullshit']\n","Updated Tokens (Row 12): ['want', 'accept', 'think', 'bullshit']\n","Stopwords Removed (Row 12): ['no', 'i', 'do', 'not', 'i', 'do', 'not', 'to', 'that', 'i', 'that', 'is']\n","Stopwords were removed for Row 12 in file Ses05F_impro04.csv.\n","Original Tokens (Row 13): ['i', 'do', 'not', 'know', 'i', 'feel', 'like', 'i', 'tried', 'everything']\n","Updated Tokens (Row 13): ['know', 'feel', 'like', 'tried', 'everything']\n","Stopwords Removed (Row 13): ['i', 'do', 'not', 'i', 'i']\n","Stopwords were removed for Row 13 in file Ses05F_impro04.csv.\n","Original Tokens (Row 14): ['three', 'years', 'of', 'going', 'out', 'every', 'day', 'every', 'day', 'and', 'looking', 'for', 'a', 'job', 'and', 'being', 'constantly', 'denied', 'everywhere', 'i', 'go']\n","Updated Tokens (Row 14): ['three', 'years', 'going', 'every', 'day', 'every', 'day', 'looking', 'job', 'constantly', 'denied', 'everywhere', 'go']\n","Stopwords Removed (Row 14): ['of', 'out', 'and', 'for', 'a', 'and', 'being', 'i']\n","Stopwords were removed for Row 14 in file Ses05F_impro04.csv.\n","Original Tokens (Row 15): ['i', 'just', 'so', 'scared', 'to', 'start', 'over', 'i', 'mean', 'i', 'put', 'so', 'much', 'time', 'and', 'energy', 'into', 'being', 'here']\n","Updated Tokens (Row 15): ['scared', 'start', 'mean', 'put', 'much', 'time', 'energy']\n","Stopwords Removed (Row 15): ['i', 'just', 'so', 'to', 'over', 'i', 'i', 'so', 'and', 'into', 'being', 'here']\n","Stopwords were removed for Row 15 in file Ses05F_impro04.csv.\n","Original Tokens (Row 16): ['where', 'am', 'i', 'supposed', 'to', 'go', 'i', 'mean', 'like', 'what']\n","Updated Tokens (Row 16): ['supposed', 'go', 'mean', 'like']\n","Stopwords Removed (Row 16): ['where', 'am', 'i', 'to', 'i', 'what']\n","Stopwords were removed for Row 16 in file Ses05F_impro04.csv.\n","Original Tokens (Row 17): ['i', 'do', 'not', 'know', 'maybe', 'i', 'can', 'take', 'out', 'a', 'loan', 'i', 'just', 'i', 'need', 'prospects', 'and', 'i', 'do', 'not', 'feel', 'like', 'i', 'have', 'any']\n","Updated Tokens (Row 17): ['know', 'maybe', 'take', 'loan', 'need', 'prospects', 'feel', 'like']\n","Stopwords Removed (Row 17): ['i', 'do', 'not', 'i', 'can', 'out', 'a', 'i', 'just', 'i', 'and', 'i', 'do', 'not', 'i', 'have', 'any']\n","Stopwords were removed for Row 17 in file Ses05F_impro04.csv.\n","Original Tokens (Row 18): ['but', 'that', 'does', 'not', 'help', 'me', 'when', 'i', 'hungry', 'now']\n","Updated Tokens (Row 18): ['help', 'hungry']\n","Stopwords Removed (Row 18): ['but', 'that', 'does', 'not', 'me', 'when', 'i', 'now']\n","Stopwords were removed for Row 18 in file Ses05F_impro04.csv.\n","Original Tokens (Row 19): ['i', 'just', 'worried']\n","Updated Tokens (Row 19): ['worried']\n","Stopwords Removed (Row 19): ['i', 'just']\n","Stopwords were removed for Row 19 in file Ses05F_impro04.csv.\n","Original Tokens (Row 20): ['it', 'is', 'three', 'years']\n","Updated Tokens (Row 20): ['three', 'years']\n","Stopwords Removed (Row 20): ['it', 'is']\n","Stopwords were removed for Row 20 in file Ses05F_impro04.csv.\n","Original Tokens (Row 21): ['is', 'that', 'honestly', 'what', 'you', 'think']\n","Updated Tokens (Row 21): ['honestly', 'think']\n","Stopwords Removed (Row 21): ['is', 'that', 'what', 'you']\n","Stopwords were removed for Row 21 in file Ses05F_impro04.csv.\n","Original Tokens (Row 22): ['that', 'is', 'really', 'hard', 'to', 'hear']\n","Updated Tokens (Row 22): ['really', 'hard', 'hear']\n","Stopwords Removed (Row 22): ['that', 'is', 'to']\n","Stopwords were removed for Row 22 in file Ses05F_impro04.csv.\n","Original Tokens (Row 23): ['i', 'feel', 'like', 'i', 'have', 'faith', 'and', 'now', 'faith', 'is', 'running', 'thin', 'because', 'there', 'is', 'no', 'money']\n","Updated Tokens (Row 23): ['feel', 'like', 'faith', 'faith', 'running', 'thin', 'money']\n","Stopwords Removed (Row 23): ['i', 'i', 'have', 'and', 'now', 'is', 'because', 'there', 'is', 'no']\n","Stopwords were removed for Row 23 in file Ses05F_impro04.csv.\n","Original Tokens (Row 24): ['brian', 'i', 'do', 'not', 'think', 'you', 'have', 'a', 'concept', 'of', 'what', 'i', 'mean', 'by', 'by', 'money', 'i', 'do', 'not', 'mean', 'money', 'like', 'oh', 'i', 'can', 'not', 'go', 'get', 'my', 'hair', 'and', 'my', 'nails', 'done', 'today', 'i', 'mean', 'like', 'i', 'can', 'not', 'eat']\n","Updated Tokens (Row 24): ['brian', 'think', 'concept', 'mean', 'money', 'mean', 'money', 'like', 'oh', 'go', 'get', 'hair', 'nails', 'done', 'today', 'mean', 'like', 'eat']\n","Stopwords Removed (Row 24): ['i', 'do', 'not', 'you', 'have', 'a', 'of', 'what', 'i', 'by', 'by', 'i', 'do', 'not', 'i', 'can', 'not', 'my', 'and', 'my', 'i', 'i', 'can', 'not']\n","Stopwords were removed for Row 24 in file Ses05F_impro04.csv.\n","Original Tokens (Row 25): ['no', 'no', 'really', 'if', 'i', 'can', 'not', 'pay', 'to', 'live', 'somewhere', 'i', 'going', 'to', 'end', 'up', 'living', 'in', 'my', 'car']\n","Updated Tokens (Row 25): ['really', 'pay', 'live', 'somewhere', 'going', 'end', 'living', 'car']\n","Stopwords Removed (Row 25): ['no', 'no', 'if', 'i', 'can', 'not', 'to', 'i', 'to', 'up', 'in', 'my']\n","Stopwords were removed for Row 25 in file Ses05F_impro04.csv.\n","Original Tokens (Row 26): ['i', 'just', 'i']\n","Updated Tokens (Row 26): []\n","Stopwords Removed (Row 26): ['i', 'just', 'i']\n","Stopwords were removed for Row 26 in file Ses05F_impro04.csv.\n","Original Tokens (Row 27): ['well', 'thank', 'you']\n","Updated Tokens (Row 27): ['well', 'thank']\n","Stopwords Removed (Row 27): ['you']\n","Stopwords were removed for Row 27 in file Ses05F_impro04.csv.\n","Original Tokens (Row 28): ['yeah', 'i', 'do', 'not', 'intend', 'to', 'stop', 'trying', 'i', 'just', 'i', 'do', 'not', 'when', 'is', 'when', 'enough', 'is', 'enough']\n","Updated Tokens (Row 28): ['yeah', 'intend', 'stop', 'trying', 'enough', 'enough']\n","Stopwords Removed (Row 28): ['i', 'do', 'not', 'to', 'i', 'just', 'i', 'do', 'not', 'when', 'is', 'when', 'is']\n","Stopwords were removed for Row 28 in file Ses05F_impro04.csv.\n","Original Tokens (Row 29): ['i', 'do', 'not', 'know']\n","Updated Tokens (Row 29): ['know']\n","Stopwords Removed (Row 29): ['i', 'do', 'not']\n","Stopwords were removed for Row 29 in file Ses05F_impro04.csv.\n","Original Tokens (Row 30): ['yeah', 'and', 'i', 'look', 'nice', 'and', 'i', 'you', 'know']\n","Updated Tokens (Row 30): ['yeah', 'look', 'nice', 'know']\n","Stopwords Removed (Row 30): ['and', 'i', 'and', 'i', 'you']\n","Stopwords were removed for Row 30 in file Ses05F_impro04.csv.\n","Original Tokens (Row 31): ['charismatic']\n","Updated Tokens (Row 31): ['charismatic']\n","Stopwords Removed (Row 31): []\n","No stopwords removed for Row 31 in file Ses05F_impro04.csv.\n","Original Tokens (Row 32): ['yah', 'to-totally', 'and', 'i', 'not']\n","Updated Tokens (Row 32): ['yah', 'to-totally']\n","Stopwords Removed (Row 32): ['and', 'i', 'not']\n","Stopwords were removed for Row 32 in file Ses05F_impro04.csv.\n","Original Tokens (Row 33): ['yeah', 'i', 'always', 'think', 'so', 'but', 'i', 'just', 'feel', 'like', 'it', 'is', 'a', 'lot', 'of', 'lip', 'service', 'everywhere', 'i', 'go']\n","Updated Tokens (Row 33): ['yeah', 'always', 'think', 'feel', 'like', 'lot', 'lip', 'service', 'everywhere', 'go']\n","Stopwords Removed (Row 33): ['i', 'so', 'but', 'i', 'just', 'it', 'is', 'a', 'of', 'i']\n","Stopwords were removed for Row 33 in file Ses05F_impro04.csv.\n","Original Tokens (Row 34): ['yeah', 'i', 'follow', 'up']\n","Updated Tokens (Row 34): ['yeah', 'follow']\n","Stopwords Removed (Row 34): ['i', 'up']\n","Stopwords were removed for Row 34 in file Ses05F_impro04.csv.\n","Original Tokens (Row 35): ['it', 'is', 'just', 'like', 'it', 'is', 'a', 'matter', 'of']\n","Updated Tokens (Row 35): ['like', 'matter']\n","Stopwords Removed (Row 35): ['it', 'is', 'just', 'it', 'is', 'a', 'of']\n","Stopwords were removed for Row 35 in file Ses05F_impro04.csv.\n","Original Tokens (Row 36): ['not', 'tall', 'enough', 'not', 'pretty', 'enough', 'not', 'you', 'know', 'how', 'this', 'place', 'is']\n","Updated Tokens (Row 36): ['tall', 'enough', 'pretty', 'enough', 'know', 'place']\n","Stopwords Removed (Row 36): ['not', 'not', 'not', 'you', 'how', 'this', 'is']\n","Stopwords were removed for Row 36 in file Ses05F_impro04.csv.\n","Original Tokens (Row 37): ['i', 'mean', 'anything']\n","Updated Tokens (Row 37): ['mean', 'anything']\n","Stopwords Removed (Row 37): ['i']\n","Stopwords were removed for Row 37 in file Ses05F_impro04.csv.\n","Original Tokens (Row 38): ['well', 'i', 'like', 'to', 'be', 'a', 'working', 'actor']\n","Updated Tokens (Row 38): ['well', 'like', 'working', 'actor']\n","Stopwords Removed (Row 38): ['i', 'to', 'be', 'a']\n","Stopwords were removed for Row 38 in file Ses05F_impro04.csv.\n","Original Tokens (Row 39): ['but', 'um']\n","Updated Tokens (Row 39): ['um']\n","Stopwords Removed (Row 39): ['but']\n","Stopwords were removed for Row 39 in file Ses05F_impro04.csv.\n","Original Tokens (Row 40): ['yeah']\n","Updated Tokens (Row 40): ['yeah']\n","Stopwords Removed (Row 40): []\n","No stopwords removed for Row 40 in file Ses05F_impro04.csv.\n","Original Tokens (Row 41): ['bartending', 'catering']\n","Updated Tokens (Row 41): ['bartending', 'catering']\n","Stopwords Removed (Row 41): []\n","No stopwords removed for Row 41 in file Ses05F_impro04.csv.\n","Original Tokens (Row 42): ['would', 'you', 'be', 'willing', 'to', 'make', 'some', 'more', 'calls', 'on', 'my', 'behalf', 'i', 'will', 'not', 'i', 'will', 'not', 'make', 'you', 'look', 'bad']\n","Updated Tokens (Row 42): ['would', 'willing', 'make', 'calls', 'behalf', 'make', 'look', 'bad']\n","Stopwords Removed (Row 42): ['you', 'be', 'to', 'some', 'more', 'on', 'my', 'i', 'will', 'not', 'i', 'will', 'not', 'you']\n","Stopwords were removed for Row 42 in file Ses05F_impro04.csv.\n","Original Tokens (Row 43): ['yeah']\n","Updated Tokens (Row 43): ['yeah']\n","Stopwords Removed (Row 43): []\n","No stopwords removed for Row 43 in file Ses05F_impro04.csv.\n","Original Tokens (Row 44): ['thank', 'you']\n","Updated Tokens (Row 44): ['thank']\n","Stopwords Removed (Row 44): ['you']\n","Stopwords were removed for Row 44 in file Ses05F_impro04.csv.\n","Original Tokens (Row 45): ['i', 'will', 'i', 'will']\n","Updated Tokens (Row 45): []\n","Stopwords Removed (Row 45): ['i', 'will', 'i', 'will']\n","Stopwords were removed for Row 45 in file Ses05F_impro04.csv.\n","Original Tokens (Row 46): ['yeah', 'thank', 'you']\n","Updated Tokens (Row 46): ['yeah', 'thank']\n","Stopwords Removed (Row 46): ['you']\n","Stopwords were removed for Row 46 in file Ses05F_impro04.csv.\n","Original Tokens (Row 47): ['babe', 'i', 'do', 'not', 'know', 'what', 'to', 'tell', 'you', 'do', 'not', 'give', 'up']\n","Updated Tokens (Row 47): ['babe', 'know', 'tell', 'give']\n","Stopwords Removed (Row 47): ['i', 'do', 'not', 'what', 'to', 'you', 'do', 'not', 'up']\n","Stopwords were removed for Row 47 in file Ses05F_impro04.csv.\n","Original Tokens (Row 48): ['well', 'of', 'course', 'not', 'but', 'what', 'are', 'you', 'going', 'to', 'do', 'if', 'you', 'move', 'back', 'home', 'are', 'you', 'going', 'to', 'be', 'able', 'to', 'find', 'a', 'job', 'there']\n","Updated Tokens (Row 48): ['well', 'course', 'going', 'move', 'back', 'home', 'going', 'able', 'find', 'job']\n","Stopwords Removed (Row 48): ['of', 'not', 'but', 'what', 'are', 'you', 'to', 'do', 'if', 'you', 'are', 'you', 'to', 'be', 'to', 'a', 'there']\n","Stopwords were removed for Row 48 in file Ses05F_impro04.csv.\n","Original Tokens (Row 49): ['i', 'wish', 'i', 'had', 'some', 'answers', 'for', 'you', 'babe', 'i', 'mean-i', 'do', 'not', 'know', 'what', 'to', 'tell', 'you']\n","Updated Tokens (Row 49): ['wish', 'answers', 'babe', 'mean-i', 'know', 'tell']\n","Stopwords Removed (Row 49): ['i', 'i', 'had', 'some', 'for', 'you', 'i', 'do', 'not', 'what', 'to', 'you']\n","Stopwords were removed for Row 49 in file Ses05F_impro04.csv.\n","Original Tokens (Row 50): ['i', 'went', 'to', 'school', 'and', 'i', 'got', 'my', 'degree', 'and', 'i', 'got', 'a', 'job']\n","Updated Tokens (Row 50): ['went', 'school', 'got', 'degree', 'got', 'job']\n","Stopwords Removed (Row 50): ['i', 'to', 'and', 'i', 'my', 'and', 'i', 'a']\n","Stopwords were removed for Row 50 in file Ses05F_impro04.csv.\n","Original Tokens (Row 51): ['nothing', 'impossible']\n","Updated Tokens (Row 51): ['nothing', 'impossible']\n","Stopwords Removed (Row 51): []\n","No stopwords removed for Row 51 in file Ses05F_impro04.csv.\n","Original Tokens (Row 52): ['you', 'have', 'to', 'be', 'willing', 'you', 'have', 'to', 'be', 'willing', 'to', 'start', 'you', 'know', 'at', 'the', 'bottom', 'and', 'work', 'your', 'way', 'up', 'and']\n","Updated Tokens (Row 52): ['willing', 'willing', 'start', 'know', 'bottom', 'work', 'way']\n","Stopwords Removed (Row 52): ['you', 'have', 'to', 'be', 'you', 'have', 'to', 'be', 'to', 'you', 'at', 'the', 'and', 'your', 'up', 'and']\n","Stopwords were removed for Row 52 in file Ses05F_impro04.csv.\n","Original Tokens (Row 53): ['i']\n","Updated Tokens (Row 53): []\n","Stopwords Removed (Row 53): ['i']\n","Stopwords were removed for Row 53 in file Ses05F_impro04.csv.\n","Original Tokens (Row 54): ['no', 'it', 'does', 'not', 'pay', 'the', 'bills', 'but', 'it', 'would', 'pay', 'something', 'and', 'it', 'would', 'help', 'you', 'get', 'somewhere', 'else']\n","Updated Tokens (Row 54): ['pay', 'bills', 'would', 'pay', 'something', 'would', 'help', 'get', 'somewhere', 'else']\n","Stopwords Removed (Row 54): ['no', 'it', 'does', 'not', 'the', 'but', 'it', 'and', 'it', 'you']\n","Stopwords were removed for Row 54 in file Ses05F_impro04.csv.\n","Original Tokens (Row 55): ['and', 'no', 'i', 'understand', 'but', 'you', 'have', 'got', 'to', 'start', 'somewhere', 'it', 'is', 'better', 'than', 'nothing', 'and', 'that', 'is', 'all', 'you', 'have', 'you', 'have', 'nothing', 'right', 'now']\n","Updated Tokens (Row 55): ['understand', 'got', 'start', 'somewhere', 'better', 'nothing', 'nothing', 'right']\n","Stopwords Removed (Row 55): ['and', 'no', 'i', 'but', 'you', 'have', 'to', 'it', 'is', 'than', 'and', 'that', 'is', 'all', 'you', 'have', 'you', 'have', 'now']\n","Stopwords were removed for Row 55 in file Ses05F_impro04.csv.\n","Original Tokens (Row 56): ['wait', 'you', 'can', 'move', 'up', 'there', 'management', 'programs', 'in', 'mcdonalds', 'and', 'things', 'like', 'that']\n","Updated Tokens (Row 56): ['wait', 'move', 'management', 'programs', 'mcdonalds', 'things', 'like']\n","Stopwords Removed (Row 56): ['you', 'can', 'up', 'there', 'in', 'and', 'that']\n","Stopwords were removed for Row 56 in file Ses05F_impro04.csv.\n","Original Tokens (Row 57): ['garbage', 'no', 'i', 'would', 'not', 'but', 'i']\n","Updated Tokens (Row 57): ['garbage', 'would']\n","Stopwords Removed (Row 57): ['no', 'i', 'not', 'but', 'i']\n","Stopwords were removed for Row 57 in file Ses05F_impro04.csv.\n","Original Tokens (Row 58): ['well', 'you', 'know', 'what', 'life', 'gets', 'humili', 'humiliating', 'at', 'times']\n","Updated Tokens (Row 58): ['well', 'know', 'life', 'gets', 'humili', 'humiliating', 'times']\n","Stopwords Removed (Row 58): ['you', 'what', 'at']\n","Stopwords were removed for Row 58 in file Ses05F_impro04.csv.\n","Original Tokens (Row 59): ['well', 'what', 'are', 'you', 'going', 'to', 'do', 'about', 'it', 'to', 'make', 'it', 'different']\n","Updated Tokens (Row 59): ['well', 'going', 'make', 'different']\n","Stopwords Removed (Row 59): ['what', 'are', 'you', 'to', 'do', 'about', 'it', 'to', 'it']\n","Stopwords were removed for Row 59 in file Ses05F_impro04.csv.\n","Original Tokens (Row 60): ['have', 'you', 'there', 'got', 'to', 'be', 'something', 'else']\n","Updated Tokens (Row 60): ['got', 'something', 'else']\n","Stopwords Removed (Row 60): ['have', 'you', 'there', 'to', 'be']\n","Stopwords were removed for Row 60 in file Ses05F_impro04.csv.\n","Original Tokens (Row 61): ['i', 'do', 'not', 'know', 'what', 'to', 'tell', 'you', 'babe', 'maybe', 'maybe', 'you', 'right', 'maybe', 'you', 'do', 'have', 'to', 'go', 'someplace', 'else', 'i', 'do', 'not', 'know', 'maybe', 'it', 'is', 'just', 'not', 'meant', 'to', 'be', 'here', 'i', 'mean', 'i', 'want', 'you', 'to-i', 'do', 'not', 'want', 'you', 'to', 'give', 'up', 'but', 'i', 'mean', 'i', 'do', 'not', 'want', 'you', 'to', 'move', 'away', 'but', 'at', 'the', 'same', 'time', 'i', 'do', 'not', 'like', 'seeing', 'you', 'like', 'this']\n","Updated Tokens (Row 61): ['know', 'tell', 'babe', 'maybe', 'maybe', 'right', 'maybe', 'go', 'someplace', 'else', 'know', 'maybe', 'meant', 'mean', 'want', 'to-i', 'want', 'give', 'mean', 'want', 'move', 'away', 'time', 'like', 'seeing', 'like']\n","Stopwords Removed (Row 61): ['i', 'do', 'not', 'what', 'to', 'you', 'you', 'you', 'do', 'have', 'to', 'i', 'do', 'not', 'it', 'is', 'just', 'not', 'to', 'be', 'here', 'i', 'i', 'you', 'do', 'not', 'you', 'to', 'up', 'but', 'i', 'i', 'do', 'not', 'you', 'to', 'but', 'at', 'the', 'same', 'i', 'do', 'not', 'you', 'this']\n","Stopwords were removed for Row 61 in file Ses05F_impro04.csv.\n","Original Tokens (Row 62): ['if', 'it', 'is', 'rent', 'or', 'something', 'like', 'that', 'i', 'mean', 'i', 'can', 'help', 'you', 'out', 'a', 'little', 'bit', 'if', 'if', 'that', 'will', 'help', 'you', 'you', 'know', 'stick', 'with', 'it']\n","Updated Tokens (Row 62): ['rent', 'something', 'like', 'mean', 'help', 'little', 'bit', 'help', 'know', 'stick']\n","Stopwords Removed (Row 62): ['if', 'it', 'is', 'or', 'that', 'i', 'i', 'can', 'you', 'out', 'a', 'if', 'if', 'that', 'will', 'you', 'you', 'with', 'it']\n","Stopwords were removed for Row 62 in file Ses05F_impro04.csv.\n","Original Tokens (Row 63): ['well', 'just', 'do', 'not', 'give', 'up', 'and', \"there's\", 'you', 'know', 'you', 'never', 'know', 'something', 'might', 'be', 'around', 'the', 'corner', 'tomorrow']\n","Updated Tokens (Row 63): ['well', 'give', \"there's\", 'know', 'never', 'know', 'something', 'might', 'around', 'corner', 'tomorrow']\n","Stopwords Removed (Row 63): ['just', 'do', 'not', 'up', 'and', 'you', 'you', 'be', 'the']\n","Stopwords were removed for Row 63 in file Ses05F_impro04.csv.\n","Original Tokens (Row 64): ['well', 'you', 'know', 'i', 'not', 'going', 'to', 'let', 'you', 'starve']\n","Updated Tokens (Row 64): ['well', 'know', 'going', 'let', 'starve']\n","Stopwords Removed (Row 64): ['you', 'i', 'not', 'to', 'you']\n","Stopwords were removed for Row 64 in file Ses05F_impro04.csv.\n","Original Tokens (Row 65): ['of', 'course', 'you', 'worried', 'we', 'all', 'worried', 'i', 'worried', 'for', 'you', 'everyone', 'always', 'worried', 'you', 'know', 'i', 'do', 'not-maybe', 'i', 'have', 'a', 'job', 'and', 'yeah', 'it', 'is', 'a', 'good', 'job', 'whatever', 'and', 'i', 'happy', 'but', 'it', 'does', 'not', 'mean', 'i', 'going', 'to', 'have', 'it', 'tomorrow', 'or', 'the', 'next', 'day', 'you', 'never', 'know', 'what', 'is', 'going', 'to', 'happen', 'something', 'crazy', 'could', 'happen', 'tomorrow', 'something', 'crazy', 'can', 'happen', 'for', 'you', 'tomorrow', 'and', 'you', 'get', 'a', 'job', 'you', 'never', 'know', 'you', 'can', 'walk', 'up', 'to', 'somebody', 'on', 'the', 'street', 'and', 'it', 'be', 'something', 'great', 'you', 'have', 'just', 'got', 'to', 'be', 'positive', 'you', 'so', 'negative', 'all', 'the', 'time']\n","Updated Tokens (Row 65): ['course', 'worried', 'worried', 'worried', 'everyone', 'always', 'worried', 'know', 'not-maybe', 'job', 'yeah', 'good', 'job', 'whatever', 'happy', 'mean', 'going', 'tomorrow', 'next', 'day', 'never', 'know', 'going', 'happen', 'something', 'crazy', 'could', 'happen', 'tomorrow', 'something', 'crazy', 'happen', 'tomorrow', 'get', 'job', 'never', 'know', 'walk', 'somebody', 'street', 'something', 'great', 'got', 'positive', 'negative', 'time']\n","Stopwords Removed (Row 65): ['of', 'you', 'we', 'all', 'i', 'for', 'you', 'you', 'i', 'do', 'i', 'have', 'a', 'and', 'it', 'is', 'a', 'and', 'i', 'but', 'it', 'does', 'not', 'i', 'to', 'have', 'it', 'or', 'the', 'you', 'what', 'is', 'to', 'can', 'for', 'you', 'and', 'you', 'a', 'you', 'you', 'can', 'up', 'to', 'on', 'the', 'and', 'it', 'be', 'you', 'have', 'just', 'to', 'be', 'you', 'so', 'all', 'the']\n","Stopwords were removed for Row 65 in file Ses05F_impro04.csv.\n","Original Tokens (Row 66): ['i', 'understand', 'but', 'you', 'know', 'what', 'you', 'have', 'been', 'negative', 'for', 'three', 'years']\n","Updated Tokens (Row 66): ['understand', 'know', 'negative', 'three', 'years']\n","Stopwords Removed (Row 66): ['i', 'but', 'you', 'what', 'you', 'have', 'been', 'for']\n","Stopwords were removed for Row 66 in file Ses05F_impro04.csv.\n","Original Tokens (Row 67): ['it', 'is', 'the', 'way', 'it', 'seems', 'to', 'me', 'you', 'started', 'complaining', 'about', 'not', 'being', 'able', 'to', 'find', 'a', 'job', 'the', 'first', 'day', 'you', 'went', 'out', 'and', 'did', 'not', 'find', 'a', 'job', 'and', 'i', 'not', 'saying', 'like', 'and', 'not', 'trying', 'to', 'you', 'know', 'put', 'you', 'down', 'or', 'anything', 'it', 'is', 'just', 'that']\n","Updated Tokens (Row 67): ['way', 'seems', 'started', 'complaining', 'able', 'find', 'job', 'first', 'day', 'went', 'find', 'job', 'saying', 'like', 'trying', 'know', 'put', 'anything']\n","Stopwords Removed (Row 67): ['it', 'is', 'the', 'it', 'to', 'me', 'you', 'about', 'not', 'being', 'to', 'a', 'the', 'you', 'out', 'and', 'did', 'not', 'a', 'and', 'i', 'not', 'and', 'not', 'to', 'you', 'you', 'down', 'or', 'it', 'is', 'just', 'that']\n","Stopwords were removed for Row 67 in file Ses05F_impro04.csv.\n","Original Tokens (Row 68): ['but', 'it', 'is', 'true', 'babe', 'you', 'have', 'got', 'to', 'be', 'more', 'positive', 'about', 'things', 'like', 'have', 'some', 'faith', 'in', 'yourself']\n","Updated Tokens (Row 68): ['true', 'babe', 'got', 'positive', 'things', 'like', 'faith']\n","Stopwords Removed (Row 68): ['but', 'it', 'is', 'you', 'have', 'to', 'be', 'more', 'about', 'have', 'some', 'in', 'yourself']\n","Stopwords were removed for Row 68 in file Ses05F_impro04.csv.\n","Original Tokens (Row 69): ['well', 'exactly', 'money', 'is', 'not', 'everything']\n","Updated Tokens (Row 69): ['well', 'exactly', 'money', 'everything']\n","Stopwords Removed (Row 69): ['is', 'not']\n","Stopwords were removed for Row 69 in file Ses05F_impro04.csv.\n","Original Tokens (Row 70): ['you', 'can']\n","Updated Tokens (Row 70): []\n","Stopwords Removed (Row 70): ['you', 'can']\n","Stopwords were removed for Row 70 in file Ses05F_impro04.csv.\n","Original Tokens (Row 71): ['you', 'know', 'i', 'would', 'never', 'let', 'that', 'happen', 'i', 'would', 'not', 'let', 'that', 'happen']\n","Updated Tokens (Row 71): ['know', 'would', 'never', 'let', 'happen', 'would', 'let', 'happen']\n","Stopwords Removed (Row 71): ['you', 'i', 'that', 'i', 'not', 'that']\n","Stopwords were removed for Row 71 in file Ses05F_impro04.csv.\n","Original Tokens (Row 72): ['you', 'can', 'always', 'stay', 'with', 'me', 'if', 'you', 'if', 'you', 'have', 'to', 'stay', 'with', 'me', 'for', 'a', 'while', 'and', 'get', 'yourself', 'back', 'up', 'on', 'your', 'feet', 'again', 'you', 'know', 'i', 'not', 'just', 'going', 'to', 'you', 'know', 'just', 'throw', 'you', 'to', 'the', 'wolves', 'or', 'something', 'like', 'that', 'if', 'there', 'any', 'way', 'i', 'can', 'help', 'you', 'i', 'will']\n","Updated Tokens (Row 72): ['always', 'stay', 'stay', 'get', 'back', 'feet', 'know', 'going', 'know', 'throw', 'wolves', 'something', 'like', 'way', 'help']\n","Stopwords Removed (Row 72): ['you', 'can', 'with', 'me', 'if', 'you', 'if', 'you', 'have', 'to', 'with', 'me', 'for', 'a', 'while', 'and', 'yourself', 'up', 'on', 'your', 'again', 'you', 'i', 'not', 'just', 'to', 'you', 'just', 'you', 'to', 'the', 'or', 'that', 'if', 'there', 'any', 'i', 'can', 'you', 'i', 'will']\n","Stopwords were removed for Row 72 in file Ses05F_impro04.csv.\n","Original Tokens (Row 73): ['but', 'you', 'have', 'to', 'keep', 'trying', 'you', 'can', 'not', 'give', 'up']\n","Updated Tokens (Row 73): ['keep', 'trying', 'give']\n","Stopwords Removed (Row 73): ['but', 'you', 'have', 'to', 'you', 'can', 'not', 'up']\n","Stopwords were removed for Row 73 in file Ses05F_impro04.csv.\n","Original Tokens (Row 74): ['and', 'you', 'have', 'got', 'to', 'think', 'well', 'ask', 'yourself', 'why', 'are', 'they', 'not', 'hiring', 'you']\n","Updated Tokens (Row 74): ['got', 'think', 'well', 'ask', 'hiring']\n","Stopwords Removed (Row 74): ['and', 'you', 'have', 'to', 'yourself', 'why', 'are', 'they', 'not', 'you']\n","Stopwords were removed for Row 74 in file Ses05F_impro04.csv.\n","Original Tokens (Row 75): ['i', 'mean', 'are', 'you', 'going', 'in', 'for', 'interviews']\n","Updated Tokens (Row 75): ['mean', 'going', 'interviews']\n","Stopwords Removed (Row 75): ['i', 'are', 'you', 'in', 'for']\n","Stopwords were removed for Row 75 in file Ses05F_impro04.csv.\n","Original Tokens (Row 76): ['are', 'you', 'presenting']\n","Updated Tokens (Row 76): ['presenting']\n","Stopwords Removed (Row 76): ['are', 'you']\n","Stopwords were removed for Row 76 in file Ses05F_impro04.csv.\n","Original Tokens (Row 77): ['putting', 'your', 'best', 'foot', 'forward', 'or', 'you']\n","Updated Tokens (Row 77): ['putting', 'best', 'foot', 'forward']\n","Stopwords Removed (Row 77): ['your', 'or', 'you']\n","Stopwords were removed for Row 77 in file Ses05F_impro04.csv.\n","Original Tokens (Row 78): ['do', 'they', 'seem', 'to', 'like', 'you', 'i', 'mean', 'can', 'you', 'get', 'any', 'read', 'from', 'them']\n","Updated Tokens (Row 78): ['seem', 'like', 'mean', 'get', 'read']\n","Stopwords Removed (Row 78): ['do', 'they', 'to', 'you', 'i', 'can', 'you', 'any', 'from', 'them']\n","Stopwords were removed for Row 78 in file Ses05F_impro04.csv.\n","Original Tokens (Row 79): ['have', 'you', 'ever', 'called', 'them', 'back', 'and', 'asked', 'why', 'you', 'did', 'not', 'get', 'the', 'job']\n","Updated Tokens (Row 79): ['ever', 'called', 'back', 'asked', 'get', 'job']\n","Stopwords Removed (Row 79): ['have', 'you', 'them', 'and', 'why', 'you', 'did', 'not', 'the']\n","Stopwords were removed for Row 79 in file Ses05F_impro04.csv.\n","Original Tokens (Row 80): ['do', 'they', 'give', 'you', 'any', 'specifics', 'as', 'to', 'why', 'they', 'did', 'not', 'go', 'with', 'you']\n","Updated Tokens (Row 80): ['give', 'specifics', 'go']\n","Stopwords Removed (Row 80): ['do', 'they', 'you', 'any', 'as', 'to', 'why', 'they', 'did', 'not', 'with', 'you']\n","Stopwords were removed for Row 80 in file Ses05F_impro04.csv.\n","Original Tokens (Row 81): ['yeah', 'i', 'understand', 'maybe', 'what', 'jobs', 'are', 'we', 'talking', 'about']\n","Updated Tokens (Row 81): ['yeah', 'understand', 'maybe', 'jobs', 'talking']\n","Stopwords Removed (Row 81): ['i', 'what', 'are', 'we', 'about']\n","Stopwords were removed for Row 81 in file Ses05F_impro04.csv.\n","Original Tokens (Row 82): ['like', 'what', 'is', 'your', 'ideal', 'job', 'what', 'do', 'you', 'want', 'to', 'do']\n","Updated Tokens (Row 82): ['like', 'ideal', 'job', 'want']\n","Stopwords Removed (Row 82): ['what', 'is', 'your', 'what', 'do', 'you', 'to', 'do']\n","Stopwords were removed for Row 82 in file Ses05F_impro04.csv.\n","Original Tokens (Row 83): ['of', 'course']\n","Updated Tokens (Row 83): ['course']\n","Stopwords Removed (Row 83): ['of']\n","Stopwords were removed for Row 83 in file Ses05F_impro04.csv.\n","Original Tokens (Row 84): ['everyone', 'wants', 'to', 'be', 'a', 'working', 'actor', 'but', 'they', 'all', 'work', 'at', 'something', 'else']\n","Updated Tokens (Row 84): ['everyone', 'wants', 'working', 'actor', 'work', 'something', 'else']\n","Stopwords Removed (Row 84): ['to', 'be', 'a', 'but', 'they', 'all', 'at']\n","Stopwords were removed for Row 84 in file Ses05F_impro04.csv.\n","Original Tokens (Row 85): ['so', 'what', 'is', 'the', 'something', 'else']\n","Updated Tokens (Row 85): ['something', 'else']\n","Stopwords Removed (Row 85): ['so', 'what', 'is', 'the']\n","Stopwords were removed for Row 85 in file Ses05F_impro04.csv.\n","Original Tokens (Row 86): ['you', 'can', 'not', 'get', 'a', 'catering', 'gig', 'well', 'i', 'can', 'call', 'some', 'friends', 'well', 'i', 'did', 'call', 'some', 'friends', 'before', 'but', 'you', 'went', 'in', 'once', 'and', 'then', 'never', 'went', 'back']\n","Updated Tokens (Row 86): ['get', 'catering', 'gig', 'well', 'call', 'friends', 'well', 'call', 'friends', 'went', 'never', 'went', 'back']\n","Stopwords Removed (Row 86): ['you', 'can', 'not', 'a', 'i', 'can', 'some', 'i', 'did', 'some', 'before', 'but', 'you', 'in', 'once', 'and', 'then']\n","Stopwords were removed for Row 86 in file Ses05F_impro04.csv.\n","Original Tokens (Row 87): ['if', 'if', 'you', 'will', 'you', 'stick', 'with', 'it']\n","Updated Tokens (Row 87): ['stick']\n","Stopwords Removed (Row 87): ['if', 'if', 'you', 'will', 'you', 'with', 'it']\n","Stopwords were removed for Row 87 in file Ses05F_impro04.csv.\n","Original Tokens (Row 88): ['okay', 'okay', 'i', 'call', 'some', 'people']\n","Updated Tokens (Row 88): ['okay', 'okay', 'call', 'people']\n","Stopwords Removed (Row 88): ['i', 'some']\n","Stopwords were removed for Row 88 in file Ses05F_impro04.csv.\n","Original Tokens (Row 89): ['but', 'you', 'have', 'got', 'to', 'keep', 'looking', 'for', 'other', 'stuff', 'you', 'have', 'got', 'to', 'do', 'it', 'on', 'your', 'own', 'too', 'okay']\n","Updated Tokens (Row 89): ['got', 'keep', 'looking', 'stuff', 'got', 'okay']\n","Stopwords Removed (Row 89): ['but', 'you', 'have', 'to', 'for', 'other', 'you', 'have', 'to', 'do', 'it', 'on', 'your', 'own', 'too']\n","Stopwords were removed for Row 89 in file Ses05F_impro04.csv.\n","Original Tokens (Row 90): ['you', 'know', 'i', 'always', 'help', 'you']\n","Updated Tokens (Row 90): ['know', 'always', 'help']\n","Stopwords Removed (Row 90): ['you', 'i', 'you']\n","Stopwords were removed for Row 90 in file Ses05F_impro04.csv.\n","Stopwords were removed in at least one row in the file: Ses05F_impro04.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords/Ses05F_impro04.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import ast  # Safer alternative to eval\n","\n","def remove_empty_rows_in_folder(input_folder_path, output_folder_path):\n","    # Ensure the output folder exists\n","    os.makedirs(output_folder_path, exist_ok=True)\n","\n","    # Loop over files in the input folder\n","    for filename in os.listdir(input_folder_path):\n","        if filename.endswith('.csv'):  # Adjust if files are in another format (e.g., .json, .xlsx)\n","            file_path = os.path.join(input_folder_path, filename)\n","            df = pd.read_csv(file_path)  # Read the CSV file\n","\n","            # Check if the 'TEXT' column exists\n","            if 'TEXT' in df.columns:\n","                print(f\"\\nProcessing File: {filename}\")\n","\n","                # Define a function to check if a string is an empty list\n","                def is_empty_list(text):\n","                    try:\n","                        # If text is a string representation of a list (e.g., '[]'), convert it to an actual list\n","                        evaluated_text = ast.literal_eval(text)\n","                        return evaluated_text == []  # True if the evaluated text is an empty list\n","                    except (ValueError, SyntaxError):\n","                        # If text cannot be evaluated to a list, it's not an empty list\n","                        return text == \"\"  # Check if the text is an empty string\n","\n","                # Identify rows where TEXT is empty or an empty list\n","                rows_to_delete = df[df['TEXT'].apply(is_empty_list)].index.tolist()\n","\n","                # If there are rows to delete, display them and remove them\n","                if rows_to_delete:\n","                    print(f\"\\nDeleted Rows in file {filename}:\")\n","                    for row in rows_to_delete:\n","                        print(f\"Row {row} deleted: {df.iloc[row]}\")  # Display the deleted row\n","                    # Drop the rows\n","                    df.drop(rows_to_delete, inplace=True)\n","\n","                # Define the path for saving the updated file to the output folder\n","                output_file_path = os.path.join(output_folder_path, filename)\n","\n","                # Save the cleaned dataframe back to the output file\n","                df.to_csv(output_file_path, index=False)  # Save to the new folder\n","\n","                print(f\"Updated file saved: {output_file_path}\")\n","            else:\n","                print(f\"No 'TEXT' column found in {filename}\")\n","\n","# Usage\n","input_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/RemovedStopWords\"\n","output_folder_path = \"/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText\"\n","remove_empty_rows_in_folder(input_folder_path, output_folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"862TFHuP5A46","executionInfo":{"status":"ok","timestamp":1739717111027,"user_tz":-480,"elapsed":1189,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"3772777a-3fae-498d-d6ef-93c8cd847667"},"id":"862TFHuP5A46","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing File: Ses05F_impro01.csv\n","\n","Deleted Rows in file Ses05F_impro01.csv:\n","Row 10 deleted: % [START_TIME - END_TIME]         [86.8900 - 88.5000]\n","TURN_NAME                         Ses05F_impro01_F010\n","EMOTION                                           fru\n","[V, A, D]                    [1.5000, 3.5000, 3.5000]\n","TEXT                                               []\n","Name: 10, dtype: object\n","Row 15 deleted: % [START_TIME - END_TIME]       [135.3800 - 136.7300]\n","TURN_NAME                         Ses05F_impro01_F015\n","EMOTION                                           fru\n","[V, A, D]                    [2.5000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 15, dtype: object\n","Row 18 deleted: % [START_TIME - END_TIME]       [150.9500 - 152.5100]\n","TURN_NAME                         Ses05F_impro01_F018\n","EMOTION                                           ang\n","[V, A, D]                    [1.5000, 4.0000, 4.0000]\n","TEXT                                               []\n","Name: 18, dtype: object\n","Row 31 deleted: % [START_TIME - END_TIME]         [67.6900 - 69.3400]\n","TURN_NAME                         Ses05F_impro01_M007\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 31, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro01.csv\n","\n","Processing File: Ses05F_impro05.csv\n","\n","Deleted Rows in file Ses05F_impro05.csv:\n","Row 25 deleted: % [START_TIME - END_TIME]       [228.3200 - 230.1800]\n","TURN_NAME                         Ses05F_impro05_F025\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 25, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro05.csv\n","\n","Processing File: Ses05F_impro07.csv\n","\n","Deleted Rows in file Ses05F_impro07.csv:\n","Row 4 deleted: % [START_TIME - END_TIME]         [13.6500 - 14.7900]\n","TURN_NAME                         Ses05F_impro07_F004\n","EMOTION                                           exc\n","[V, A, D]                    [4.5000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 4, dtype: object\n","Row 40 deleted: % [START_TIME - END_TIME]           [4.2400 - 5.2953]\n","TURN_NAME                         Ses05F_impro07_M000\n","EMOTION                                           exc\n","[V, A, D]                    [4.0000, 3.0000, 3.5000]\n","TEXT                                               []\n","Name: 40, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro07.csv\n","\n","Processing File: Ses05F_script01_2.csv\n","\n","Deleted Rows in file Ses05F_script01_2.csv:\n","Row 33 deleted: % [START_TIME - END_TIME]       [135.2500 - 138.2600]\n","TURN_NAME                      Ses05F_script01_2_M015\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.0000, 3.5000]\n","TEXT                                               []\n","Name: 33, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script01_2.csv\n","\n","Processing File: Ses05F_impro08.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro08.csv\n","\n","Processing File: Ses05F_impro04.csv\n","\n","Deleted Rows in file Ses05F_impro04.csv:\n","Row 26 deleted: % [START_TIME - END_TIME]       [285.7500 - 287.4300]\n","TURN_NAME                         Ses05F_impro04_F026\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 26, dtype: object\n","Row 45 deleted: % [START_TIME - END_TIME]       [398.6800 - 400.7100]\n","TURN_NAME                         Ses05F_impro04_F045\n","EMOTION                                           neu\n","[V, A, D]                    [3.0000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 45, dtype: object\n","Row 53 deleted: % [START_TIME - END_TIME]         [75.0100 - 76.2800]\n","TURN_NAME                         Ses05F_impro04_M006\n","EMOTION                                           fru\n","[V, A, D]                    [3.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 53, dtype: object\n","Row 70 deleted: % [START_TIME - END_TIME]       [274.6900 - 276.6000]\n","TURN_NAME                         Ses05F_impro04_M023\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 3.5000, 3.0000]\n","TEXT                                               []\n","Name: 70, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro04.csv\n","\n","Processing File: Ses05F_script01_1.csv\n","\n","Deleted Rows in file Ses05F_script01_1.csv:\n","Row 2 deleted: % [START_TIME - END_TIME]         [20.5700 - 22.1000]\n","TURN_NAME                      Ses05F_script01_1_F002\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 9 deleted: % [START_TIME - END_TIME]         [69.6000 - 71.3200]\n","TURN_NAME                      Ses05F_script01_1_F009\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 9, dtype: object\n","Row 16 deleted: % [START_TIME - END_TIME]       [156.1600 - 157.9000]\n","TURN_NAME                      Ses05F_script01_1_F016\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 16, dtype: object\n","Row 71 deleted: % [START_TIME - END_TIME]       [267.4100 - 269.0700]\n","TURN_NAME                      Ses05F_script01_1_M029\n","EMOTION                                           fru\n","[V, A, D]                    [2.5000, 3.5000, 4.5000]\n","TEXT                                               []\n","Name: 71, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script01_1.csv\n","\n","Processing File: Ses05F_script01_3.csv\n","\n","Deleted Rows in file Ses05F_script01_3.csv:\n","Row 29 deleted: % [START_TIME - END_TIME]         [27.1111 - 28.6434]\n","TURN_NAME                      Ses05F_script01_3_M002\n","EMOTION                                           sur\n","[V, A, D]                    [3.0000, 2.5000, 2.0000]\n","TEXT                                               []\n","Name: 29, dtype: object\n","Row 31 deleted: % [START_TIME - END_TIME]         [39.0692 - 40.6300]\n","TURN_NAME                      Ses05F_script01_3_M004\n","EMOTION                                           neu\n","[V, A, D]                    [3.0000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 31, dtype: object\n","Row 39 deleted: % [START_TIME - END_TIME]       [132.8012 - 135.4151]\n","TURN_NAME                      Ses05F_script01_3_M012\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 39, dtype: object\n","Row 53 deleted: % [START_TIME - END_TIME]       [249.9286 - 252.0118]\n","TURN_NAME                      Ses05F_script01_3_M026\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 53, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script01_3.csv\n","\n","Processing File: Ses05F_impro02.csv\n","\n","Deleted Rows in file Ses05F_impro02.csv:\n","Row 20 deleted: % [START_TIME - END_TIME]       [156.4300 - 158.2300]\n","TURN_NAME                         Ses05F_impro02_F020\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 1.5000, 1.0000]\n","TEXT                                               []\n","Name: 20, dtype: object\n","Row 39 deleted: % [START_TIME - END_TIME]          [7.6018 - 10.4300]\n","TURN_NAME                         Ses05F_impro02_M000\n","EMOTION                                           neu\n","[V, A, D]                    [3.0000, 2.5000, 1.5000]\n","TEXT                                               []\n","Name: 39, dtype: object\n","Row 51 deleted: % [START_TIME - END_TIME]         [94.9700 - 97.4600]\n","TURN_NAME                         Ses05F_impro02_M012\n","EMOTION                                           xxx\n","[V, A, D]                    [1.5000, 3.0000, 2.0000]\n","TEXT                                               []\n","Name: 51, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro02.csv\n","\n","Processing File: Ses05F_impro06.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro06.csv\n","\n","Processing File: Ses05F_impro03.csv\n","\n","Deleted Rows in file Ses05F_impro03.csv:\n","Row 61 deleted: % [START_TIME - END_TIME]           [4.2300 - 5.4300]\n","TURN_NAME                         Ses05F_impro03_M000\n","EMOTION                                           exc\n","[V, A, D]                    [4.0000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 61, dtype: object\n","Row 81 deleted: % [START_TIME - END_TIME]         [88.8400 - 90.3800]\n","TURN_NAME                         Ses05F_impro03_M020\n","EMOTION                                           exc\n","[V, A, D]                    [3.5000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 81, dtype: object\n","Row 113 deleted: % [START_TIME - END_TIME]       [226.4700 - 227.3700]\n","TURN_NAME                         Ses05F_impro03_M052\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 113, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_impro03.csv\n","\n","Processing File: Ses05F_script02_1.csv\n","\n","Deleted Rows in file Ses05F_script02_1.csv:\n","Row 12 deleted: % [START_TIME - END_TIME]       [137.5700 - 139.6329]\n","TURN_NAME                      Ses05F_script02_1_F012\n","EMOTION                                           neu\n","[V, A, D]                    [2.0000, 1.5000, 2.0000]\n","TEXT                                               []\n","Name: 12, dtype: object\n","Row 15 deleted: % [START_TIME - END_TIME]       [205.7400 - 207.6622]\n","TURN_NAME                      Ses05F_script02_1_F015\n","EMOTION                                           neu\n","[V, A, D]                    [2.0000, 2.0000, 2.0000]\n","TEXT                                               []\n","Name: 15, dtype: object\n","Row 37 deleted: % [START_TIME - END_TIME]       [135.6100 - 137.6075]\n","TURN_NAME                      Ses05F_script02_1_M017\n","EMOTION                                           fru\n","[V, A, D]                    [3.5000, 3.5000, 2.5000]\n","TEXT                                               []\n","Name: 37, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script02_1.csv\n","\n","Processing File: Ses05F_script03_1.csv\n","\n","Deleted Rows in file Ses05F_script03_1.csv:\n","Row 2 deleted: % [START_TIME - END_TIME]         [14.4500 - 16.5800]\n","TURN_NAME                      Ses05F_script03_1_F002\n","EMOTION                                           xxx\n","[V, A, D]                    [3.5000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 13 deleted: % [START_TIME - END_TIME]         [77.7200 - 79.2100]\n","TURN_NAME                      Ses05F_script03_1_F013\n","EMOTION                                           neu\n","[V, A, D]                    [3.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 13, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script03_1.csv\n","\n","Processing File: Ses05F_script02_2.csv\n","\n","Deleted Rows in file Ses05F_script02_2.csv:\n","Row 0 deleted: % [START_TIME - END_TIME]          [9.5800 - 11.9629]\n","TURN_NAME                      Ses05F_script02_2_F000\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 0, dtype: object\n","Row 18 deleted: % [START_TIME - END_TIME]       [225.3896 - 227.2275]\n","TURN_NAME                      Ses05F_script02_2_F018\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 18, dtype: object\n","Row 19 deleted: % [START_TIME - END_TIME]       [228.8315 - 230.6025]\n","TURN_NAME                      Ses05F_script02_2_F019\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 19, dtype: object\n","Row 20 deleted: % [START_TIME - END_TIME]       [231.3376 - 232.8079]\n","TURN_NAME                      Ses05F_script02_2_F020\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 2.5000, 3.5000]\n","TEXT                                               []\n","Name: 20, dtype: object\n","Row 21 deleted: % [START_TIME - END_TIME]       [235.0468 - 236.6842]\n","TURN_NAME                      Ses05F_script02_2_F021\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 21, dtype: object\n","Row 22 deleted: % [START_TIME - END_TIME]       [238.5600 - 240.0800]\n","TURN_NAME                      Ses05F_script02_2_F022\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 1.5000, 2.5000]\n","TEXT                                               []\n","Name: 22, dtype: object\n","Row 23 deleted: % [START_TIME - END_TIME]       [242.1644 - 243.7400]\n","TURN_NAME                      Ses05F_script02_2_F023\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 3.5000, 3.5000]\n","TEXT                                               []\n","Name: 23, dtype: object\n","Row 38 deleted: % [START_TIME - END_TIME]       [434.0379 - 435.9426]\n","TURN_NAME                      Ses05F_script02_2_F038\n","EMOTION                                           xxx\n","[V, A, D]                    [4.0000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 38, dtype: object\n","Row 47 deleted: % [START_TIME - END_TIME]         [78.8200 - 80.4319]\n","TURN_NAME                      Ses05F_script02_2_M008\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 47, dtype: object\n","Row 80 deleted: % [START_TIME - END_TIME]       [436.5441 - 438.3820]\n","TURN_NAME                      Ses05F_script02_2_M041\n","EMOTION                                           hap\n","[V, A, D]                    [3.5000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 80, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script02_2.csv\n","\n","Processing File: Ses05M_impro01.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro01.csv\n","\n","Processing File: Ses05F_script03_2.csv\n","\n","Deleted Rows in file Ses05F_script03_2.csv:\n","Row 5 deleted: % [START_TIME - END_TIME]         [36.6100 - 38.2200]\n","TURN_NAME                      Ses05F_script03_2_F005\n","EMOTION                                           neu\n","[V, A, D]                    [2.5000, 4.0000, 3.0000]\n","TEXT                                               []\n","Name: 5, dtype: object\n","Row 9 deleted: % [START_TIME - END_TIME]         [57.9400 - 59.6100]\n","TURN_NAME                      Ses05F_script03_2_F009\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 9, dtype: object\n","Row 16 deleted: % [START_TIME - END_TIME]       [113.0800 - 114.9000]\n","TURN_NAME                      Ses05F_script03_2_F016\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 16, dtype: object\n","Row 29 deleted: % [START_TIME - END_TIME]       [189.1200 - 190.5400]\n","TURN_NAME                      Ses05F_script03_2_F029\n","EMOTION                                           ang\n","[V, A, D]                    [1.5000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 29, dtype: object\n","Row 48 deleted: % [START_TIME - END_TIME]         [37.9500 - 39.0500]\n","TURN_NAME                      Ses05F_script03_2_M006\n","EMOTION                                           fru\n","[V, A, D]                    [1.5000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 48, dtype: object\n","Row 49 deleted: % [START_TIME - END_TIME]         [41.7400 - 43.6700]\n","TURN_NAME                      Ses05F_script03_2_M007\n","EMOTION                                           xxx\n","[V, A, D]                    [1.5000, 4.0000, 4.0000]\n","TEXT                                               []\n","Name: 49, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05F_script03_2.csv\n","\n","Processing File: Ses05M_impro02.csv\n","\n","Deleted Rows in file Ses05M_impro02.csv:\n","Row 0 deleted: % [START_TIME - END_TIME]           [3.0334 - 5.3000]\n","TURN_NAME                         Ses05M_impro02_F000\n","EMOTION                                           xxx\n","[V, A, D]                    [2.3333, 1.6667, 1.6667]\n","TEXT                                               []\n","Name: 0, dtype: object\n","Row 1 deleted: % [START_TIME - END_TIME]         [16.3100 - 18.1100]\n","TURN_NAME                         Ses05M_impro02_F001\n","EMOTION                                           sur\n","[V, A, D]                    [2.0000, 2.6667, 2.0000]\n","TEXT                                               []\n","Name: 1, dtype: object\n","Row 2 deleted: % [START_TIME - END_TIME]         [22.2500 - 24.1900]\n","TURN_NAME                         Ses05M_impro02_F002\n","EMOTION                                           fea\n","[V, A, D]                    [2.0000, 3.3333, 3.0000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 5 deleted: % [START_TIME - END_TIME]         [40.0700 - 42.4000]\n","TURN_NAME                         Ses05M_impro02_F005\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.3333, 2.6667]\n","TEXT                                               []\n","Name: 5, dtype: object\n","Row 8 deleted: % [START_TIME - END_TIME]         [59.8200 - 60.8100]\n","TURN_NAME                         Ses05M_impro02_F008\n","EMOTION                                           sur\n","[V, A, D]                    [1.3333, 3.3333, 1.6667]\n","TEXT                                               []\n","Name: 8, dtype: object\n","Row 29 deleted: % [START_TIME - END_TIME]         [35.2500 - 37.4400]\n","TURN_NAME                         Ses05M_impro02_M004\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.6667, 2.0000]\n","TEXT                                               []\n","Name: 29, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro02.csv\n","\n","Processing File: Ses05M_impro03.csv\n","\n","Deleted Rows in file Ses05M_impro03.csv:\n","Row 0 deleted: % [START_TIME - END_TIME]           [6.6500 - 8.0900]\n","TURN_NAME                         Ses05M_impro03_F000\n","EMOTION                                           neu\n","[V, A, D]                    [4.0000, 2.6667, 2.0000]\n","TEXT                                               []\n","Name: 0, dtype: object\n","Row 1 deleted: % [START_TIME - END_TIME]         [10.6700 - 12.8900]\n","TURN_NAME                         Ses05M_impro03_F001\n","EMOTION                                           sur\n","[V, A, D]                    [4.3333, 3.3333, 2.3333]\n","TEXT                                               []\n","Name: 1, dtype: object\n","Row 2 deleted: % [START_TIME - END_TIME]         [12.9400 - 13.9600]\n","TURN_NAME                         Ses05M_impro03_F002\n","EMOTION                                           exc\n","[V, A, D]                    [4.3333, 3.0000, 2.6667]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro03.csv\n","\n","Processing File: Ses05M_impro05.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro05.csv\n","\n","Processing File: Ses05M_impro06.csv\n","\n","Deleted Rows in file Ses05M_impro06.csv:\n","Row 1 deleted: % [START_TIME - END_TIME]         [15.2600 - 17.1900]\n","TURN_NAME                         Ses05M_impro06_F001\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.0000, 1.5000]\n","TEXT                                               []\n","Name: 1, dtype: object\n","Row 4 deleted: % [START_TIME - END_TIME]         [64.2500 - 65.9400]\n","TURN_NAME                         Ses05M_impro06_F004\n","EMOTION                                           sad\n","[V, A, D]                    [2.5000, 2.0000, 2.0000]\n","TEXT                                               []\n","Name: 4, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro06.csv\n","\n","Processing File: Ses05M_impro04.csv\n","\n","Deleted Rows in file Ses05M_impro04.csv:\n","Row 46 deleted: % [START_TIME - END_TIME]         [59.4900 - 61.5400]\n","TURN_NAME                         Ses05M_impro04_M007\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 46, dtype: object\n","Row 74 deleted: % [START_TIME - END_TIME]       [236.6900 - 238.9100]\n","TURN_NAME                         Ses05M_impro04_M035\n","EMOTION                                           fru\n","[V, A, D]                    [2.5000, 3.0000, 3.5000]\n","TEXT                                               []\n","Name: 74, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro04.csv\n","\n","Processing File: Ses05M_impro07.csv\n","\n","Deleted Rows in file Ses05M_impro07.csv:\n","Row 0 deleted: % [START_TIME - END_TIME]           [5.4800 - 6.7000]\n","TURN_NAME                         Ses05M_impro07_F000\n","EMOTION                                           exc\n","[V, A, D]                    [4.0000, 3.0000, 2.0000]\n","TEXT                                               []\n","Name: 0, dtype: object\n","Row 10 deleted: % [START_TIME - END_TIME]         [32.1000 - 33.3300]\n","TURN_NAME                         Ses05M_impro07_F010\n","EMOTION                                           neu\n","[V, A, D]                    [4.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 10, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro07.csv\n","\n","Processing File: Ses05M_impro08.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_impro08.csv\n","\n","Processing File: Ses05M_script01_1.csv\n","\n","Deleted Rows in file Ses05M_script01_1.csv:\n","Row 2 deleted: % [START_TIME - END_TIME]         [18.2800 - 19.8700]\n","TURN_NAME                      Ses05M_script01_1_F002\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 8 deleted: % [START_TIME - END_TIME]         [68.6900 - 70.1200]\n","TURN_NAME                      Ses05M_script01_1_F008\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.5000, 2.5000]\n","TEXT                                               []\n","Name: 8, dtype: object\n","Row 15 deleted: % [START_TIME - END_TIME]       [139.5700 - 141.3300]\n","TURN_NAME                      Ses05M_script01_1_F015\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 15, dtype: object\n","Row 68 deleted: % [START_TIME - END_TIME]       [248.5400 - 250.4800]\n","TURN_NAME                      Ses05M_script01_1_M029\n","EMOTION                                           fru\n","[V, A, D]                    [2.5000, 3.0000, 4.0000]\n","TEXT                                               []\n","Name: 68, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script01_1.csv\n","\n","Processing File: Ses05M_script01_1b.csv\n","\n","Deleted Rows in file Ses05M_script01_1b.csv:\n","Row 2 deleted: % [START_TIME - END_TIME]         [15.1200 - 17.0200]\n","TURN_NAME                     Ses05M_script01_1b_F002\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 6 deleted: % [START_TIME - END_TIME]         [62.4100 - 64.0300]\n","TURN_NAME                     Ses05M_script01_1b_F006\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 6, dtype: object\n","Row 10 deleted: % [START_TIME - END_TIME]       [105.6000 - 110.7000]\n","TURN_NAME                     Ses05M_script01_1b_F010\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 10, dtype: object\n","Row 13 deleted: % [START_TIME - END_TIME]       [141.4600 - 143.2700]\n","TURN_NAME                     Ses05M_script01_1b_F013\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 2.0000, 3.0000]\n","TEXT                                               []\n","Name: 13, dtype: object\n","Row 66 deleted: % [START_TIME - END_TIME]       [244.7500 - 246.8800]\n","TURN_NAME                     Ses05M_script01_1b_M027\n","EMOTION                                           fru\n","[V, A, D]                    [2.0000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 66, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script01_1b.csv\n","\n","Processing File: Ses05M_script01_2.csv\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script01_2.csv\n","\n","Processing File: Ses05M_script01_3.csv\n","\n","Deleted Rows in file Ses05M_script01_3.csv:\n","Row 30 deleted: % [START_TIME - END_TIME]         [25.2200 - 26.9300]\n","TURN_NAME                      Ses05M_script01_3_M002\n","EMOTION                                           sur\n","[V, A, D]                    [2.0000, 2.0000, 2.0000]\n","TEXT                                               []\n","Name: 30, dtype: object\n","Row 32 deleted: % [START_TIME - END_TIME]         [37.4600 - 38.6700]\n","TURN_NAME                      Ses05M_script01_3_M004\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 32, dtype: object\n","Row 40 deleted: % [START_TIME - END_TIME]       [135.0800 - 137.0700]\n","TURN_NAME                      Ses05M_script01_3_M012\n","EMOTION                                           sur\n","[V, A, D]                    [3.0000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 40, dtype: object\n","Row 54 deleted: % [START_TIME - END_TIME]       [236.3100 - 238.4200]\n","TURN_NAME                      Ses05M_script01_3_M026\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 2.0000, 3.0000]\n","TEXT                                               []\n","Name: 54, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script01_3.csv\n","\n","Processing File: Ses05M_script02_1.csv\n","\n","Deleted Rows in file Ses05M_script02_1.csv:\n","Row 11 deleted: % [START_TIME - END_TIME]       [146.8900 - 148.7700]\n","TURN_NAME                      Ses05M_script02_1_F011\n","EMOTION                                           xxx\n","[V, A, D]                    [2.5000, 2.0000, 3.0000]\n","TEXT                                               []\n","Name: 11, dtype: object\n","Row 16 deleted: % [START_TIME - END_TIME]       [227.0200 - 228.7500]\n","TURN_NAME                      Ses05M_script02_1_F016\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 2.5000, 3.0000]\n","TEXT                                               []\n","Name: 16, dtype: object\n","Row 36 deleted: % [START_TIME - END_TIME]       [145.0200 - 146.8500]\n","TURN_NAME                      Ses05M_script02_1_M015\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.5000, 3.5000]\n","TEXT                                               []\n","Name: 36, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script02_1.csv\n","\n","Processing File: Ses05M_script02_2.csv\n","\n","Deleted Rows in file Ses05M_script02_2.csv:\n","Row 0 deleted: % [START_TIME - END_TIME]           [7.8200 - 9.4300]\n","TURN_NAME                      Ses05M_script02_2_F000\n","EMOTION                                           neu\n","[V, A, D]                    [3.0000, 2.0000, 2.0000]\n","TEXT                                               []\n","Name: 0, dtype: object\n","Row 17 deleted: % [START_TIME - END_TIME]       [230.0000 - 231.3200]\n","TURN_NAME                      Ses05M_script02_2_F017\n","EMOTION                                           sad\n","[V, A, D]                    [2.3333, 1.3333, 1.6667]\n","TEXT                                               []\n","Name: 17, dtype: object\n","Row 18 deleted: % [START_TIME - END_TIME]       [233.4900 - 234.9800]\n","TURN_NAME                      Ses05M_script02_2_F018\n","EMOTION                                           sad\n","[V, A, D]                    [2.3333, 2.3333, 1.6667]\n","TEXT                                               []\n","Name: 18, dtype: object\n","Row 19 deleted: % [START_TIME - END_TIME]       [235.4200 - 236.5400]\n","TURN_NAME                      Ses05M_script02_2_F019\n","EMOTION                                           sad\n","[V, A, D]                    [2.0000, 2.0000, 1.6667]\n","TEXT                                               []\n","Name: 19, dtype: object\n","Row 21 deleted: % [START_TIME - END_TIME]       [246.0500 - 247.2800]\n","TURN_NAME                      Ses05M_script02_2_F021\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 2.6667, 2.6667]\n","TEXT                                               []\n","Name: 21, dtype: object\n","Row 22 deleted: % [START_TIME - END_TIME]       [247.8400 - 248.7400]\n","TURN_NAME                      Ses05M_script02_2_F022\n","EMOTION                                           sad\n","[V, A, D]                    [2.3333, 2.0000, 2.0000]\n","TEXT                                               []\n","Name: 22, dtype: object\n","Row 38 deleted: % [START_TIME - END_TIME]       [448.6800 - 450.6900]\n","TURN_NAME                      Ses05M_script02_2_F038\n","EMOTION                                           hap\n","[V, A, D]                    [3.6667, 2.6667, 2.3333]\n","TEXT                                               []\n","Name: 38, dtype: object\n","Row 47 deleted: % [START_TIME - END_TIME]         [75.7300 - 77.2100]\n","TURN_NAME                      Ses05M_script02_2_M008\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 3.3333, 2.3333]\n","TEXT                                               []\n","Name: 47, dtype: object\n","Row 79 deleted: % [START_TIME - END_TIME]       [450.9519 - 453.2597]\n","TURN_NAME                      Ses05M_script02_2_M040\n","EMOTION                                           hap\n","[V, A, D]                    [4.0000, 2.3333, 2.0000]\n","TEXT                                               []\n","Name: 79, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script02_2.csv\n","\n","Processing File: Ses05M_script03_2.csv\n","\n","Deleted Rows in file Ses05M_script03_2.csv:\n","Row 14 deleted: % [START_TIME - END_TIME]         [85.0300 - 86.0700]\n","TURN_NAME                      Ses05M_script03_2_F014\n","EMOTION                                           xxx\n","[V, A, D]                    [1.5000, 3.5000, 3.5000]\n","TEXT                                               []\n","Name: 14, dtype: object\n","Row 17 deleted: % [START_TIME - END_TIME]       [103.3200 - 104.7400]\n","TURN_NAME                      Ses05M_script03_2_F017\n","EMOTION                                           ang\n","[V, A, D]                    [2.0000, 3.0000, 3.5000]\n","TEXT                                               []\n","Name: 17, dtype: object\n","Row 30 deleted: % [START_TIME - END_TIME]       [188.5200 - 190.4000]\n","TURN_NAME                      Ses05M_script03_2_F030\n","EMOTION                                           xxx\n","[V, A, D]                    [3.0000, 2.0000, 2.5000]\n","TEXT                                               []\n","Name: 30, dtype: object\n","Row 51 deleted: % [START_TIME - END_TIME]         [38.2400 - 39.8900]\n","TURN_NAME                      Ses05M_script03_2_M006\n","EMOTION                                           xxx\n","[V, A, D]                    [1.5000, 3.5000, 4.0000]\n","TEXT                                               []\n","Name: 51, dtype: object\n","Row 52 deleted: % [START_TIME - END_TIME]         [41.8900 - 43.7700]\n","TURN_NAME                      Ses05M_script03_2_M007\n","EMOTION                                           xxx\n","[V, A, D]                    [2.0000, 4.0000, 4.0000]\n","TEXT                                               []\n","Name: 52, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script03_2.csv\n","\n","Processing File: Ses05M_script03_1.csv\n","\n","Deleted Rows in file Ses05M_script03_1.csv:\n","Row 2 deleted: % [START_TIME - END_TIME]         [12.3000 - 14.6700]\n","TURN_NAME                      Ses05M_script03_1_F002\n","EMOTION                                           exc\n","[V, A, D]                    [2.5000, 3.0000, 2.5000]\n","TEXT                                               []\n","Name: 2, dtype: object\n","Row 12 deleted: % [START_TIME - END_TIME]         [77.2400 - 79.1900]\n","TURN_NAME                      Ses05M_script03_1_F012\n","EMOTION                                           neu\n","[V, A, D]                    [3.5000, 3.0000, 3.0000]\n","TEXT                                               []\n","Name: 12, dtype: object\n","Updated file saved: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText/Ses05M_script03_1.csv\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import spacy\n","\n","# Initialize the spaCy model for lemmatization\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Folder paths\n","source_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDeletingEmptyText'\n","destination_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization'\n","\n","# Function to lemmatize the text\n","def lemmatize_text(text):\n","    doc = nlp(text)\n","    return \" \".join([token.lemma_ for token in doc])\n","\n","# Loop through all files in the source folder\n","for filename in os.listdir(source_folder):\n","    file_path = os.path.join(source_folder, filename)\n","\n","    if file_path.endswith('.csv'):  # Check for CSV files, adjust for other formats as needed\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Ensure the column name is correct\n","        if 'TEXT' in df.columns:  # Replace 'TEXT' with the actual column name if needed\n","            # Apply lemmatization to the 'TEXT' column\n","            df['TEXT'] = df['TEXT'].apply(lemmatize_text)\n","\n","            # Create a new folder if it doesn't exist\n","            if not os.path.exists(destination_folder):\n","                os.makedirs(destination_folder)\n","\n","            # Save the DataFrame to a new CSV in the destination folder\n","            output_file_path = os.path.join(destination_folder, filename)\n","            df.to_csv(output_file_path, index=False)\n","            print(f\"Lemmatized file saved: {output_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KeNt7_bNr5Q4","executionInfo":{"status":"ok","timestamp":1739717142514,"user_tz":-480,"elapsed":23356,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"4279efbb-cd67-47a9-e534-058349105b6c"},"id":"KeNt7_bNr5Q4","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]},{"output_type":"stream","name":"stdout","text":["Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro01.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro05.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro08.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script01_3.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro03.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro06.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro07.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script01_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script01_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script02_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script02_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script03_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_script03_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro03.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro04.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro01.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro05.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro06.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro02.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro07.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_impro08.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script01_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script01_1b.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script01_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script01_3.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script02_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script02_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script03_1.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05M_script03_2.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro02.csv\n","Lemmatized file saved: /content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization/Ses05F_impro04.csv\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Set the folder path where your files are located\n","folder_path = '/content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization'\n","\n","# Get the list of all files in the folder\n","file_list = [f for f in os.listdir(folder_path) if f.endswith('.csv')]  # adjust file extension if needed\n","\n","# Initialize an empty list to store data from all files\n","all_data = []\n","\n","# Loop through each file in the folder\n","for file in file_list:\n","    file_path = os.path.join(folder_path, file)\n","\n","    # Read the current file into a DataFrame\n","    df = pd.read_csv(file_path)\n","\n","    # Append the data to the all_data list\n","    all_data.append(df)\n","\n","# Concatenate all dataframes into one\n","merged_df = pd.concat(all_data, ignore_index=True)\n","\n","# Save the merged dataframe to a new CSV file in Google Drive\n","output_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/Merged_Files/'\n","os.makedirs(output_folder, exist_ok=True)  # This creates the folder if it doesn't exist\n","merged_df.to_csv(os.path.join(output_folder, 'merged_output.csv'), index=False)\n","\n","print(\"All files merged successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tsWr1f0S0ln","executionInfo":{"status":"ok","timestamp":1740040636288,"user_tz":-480,"elapsed":256,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"75e781d4-17e0-4ddc-9eb4-ace85e267568"},"id":"1tsWr1f0S0ln","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All files merged successfully!\n"]}]},{"cell_type":"code","source":["# Count the number of rows (data points) in the merged DataFrame\n","num_rows = len(merged_df)  # or merged_df.shape[0]\n","print(f'Total number of rows merged: {num_rows}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KazEnHDvTu3Z","executionInfo":{"status":"ok","timestamp":1740040659385,"user_tz":-480,"elapsed":127,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"425cff96-f633-4487-d0b8-1e3fb83cda75"},"id":"KazEnHDvTu3Z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of rows merged: 2076\n"]}]},{"cell_type":"code","source":["_______#####"],"metadata":{"id":"_sAJGDHCjNCg"},"id":"_sAJGDHCjNCg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYhxnt_hjOZm","executionInfo":{"status":"ok","timestamp":1740796452037,"user_tz":-480,"elapsed":32317,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"973e1e5d-4a5a-49a8-910a-2878d07cee1b"},"id":"DYhxnt_hjOZm","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","folder = '/content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization'\n","\n","# Initialize a set to store unique emotion labels\n","unique_emotions = set()\n","\n","# Initialize counters\n","total_text_count = 0\n","xxx_count = 0  # Counter for rows with 'xxx' emotion label\n","\n","# Loop through all files in the folder\n","for file_name in os.listdir(folder):\n","    # Ensure the file is a CSV file\n","    if file_name.endswith('.csv'):\n","        file_path = os.path.join(folder, file_name)\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Check if the TEXT and EMOTION columns exist\n","        if 'TEXT' in df.columns and 'EMOTION' in df.columns:\n","            total_text_count += df['TEXT'].notna().sum()  # Counting non-null entries in TEXT column\n","\n","            # Count rows with 'xxx' emotion label\n","            xxx_count += df[df['EMOTION'] == 'xxx'].shape[0]  # Count rows where EMOTION is 'xxx'\n","\n","            # Add unique emotion labels from this file to the set\n","            unique_emotions.update(df['EMOTION'].dropna().unique())\n","\n","# Print the total count of texts\n","print(f'Total number of texts in all files: {total_text_count}')\n","\n","# Print the unique emotion labels across all files\n","print(f\"The unique emotion labels in the EMOTION column across all files are: {', '.join(sorted(unique_emotions))}\")\n","\n","# Print the count of 'xxx' emotion labels\n","print(f\"Total number of rows with 'xxx' emotion label: {xxx_count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAsWbuKVaWnD","executionInfo":{"status":"ok","timestamp":1740799064973,"user_tz":-480,"elapsed":199,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"94ad3944-137a-44ff-be3a-c522c81a2432","collapsed":true},"id":"UAsWbuKVaWnD","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of texts in all files: 2076\n","The unique emotion labels in the EMOTION column across all files are: ang, exc, fea, fru, hap, neu, sad, sur, xxx\n","Total number of rows with 'xxx' emotion label: 484\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Input folder with the original files\n","input_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/Lemmatization'\n","# Output folder to save the cleaned files\n","output_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel'\n","\n","# Create the output folder if it doesn't exist\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Initialize a counter to track the total number of texts before and after cleaning\n","total_before = 0\n","total_after = 0\n","\n","# Loop through all files in the folder\n","for file_name in os.listdir(input_folder):\n","    # Ensure the file is a CSV file\n","    if file_name.endswith('.csv'):\n","        file_path = os.path.join(input_folder, file_name)\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Check if the TEXT and EMOTION columns exist\n","        if 'TEXT' in df.columns and 'EMOTION' in df.columns:\n","            # Count the number of rows before dropping\n","            total_before_file = df['TEXT'].notna().sum()\n","            total_before += total_before_file\n","\n","            # Drop rows where the EMOTION column has the value 'xxx'\n","            df_cleaned = df[df['EMOTION'] != 'xxx']\n","\n","            # Count the number of rows after dropping\n","            total_after_file = df_cleaned['TEXT'].notna().sum()\n","            total_after += total_after_file\n","\n","            # Save the cleaned DataFrame to the output folder\n","            output_file_path = os.path.join(output_folder, file_name)\n","            df_cleaned.to_csv(output_file_path, index=False)\n","\n","            # Print the saved file path and the counts of rows before and after cleaning\n","            print(f\"Saved cleaned file: {output_file_path}\")\n","            print(f\"Rows before cleaning (TEXT column): {total_before_file}\")\n","            print(f\"Rows after cleaning (TEXT column): {total_after_file}\")\n","\n","# Print the total count of texts before and after cleaning\n","print(f\"Total rows in the TEXT column before cleaning: {total_before}\")\n","print(f\"Total rows in the TEXT column after cleaning: {total_after}\")\n","\n","print(\"Finished processing all files.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"BYWDbyXiogi3","executionInfo":{"status":"ok","timestamp":1740799861084,"user_tz":-480,"elapsed":892,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"c680bd64-01ef-488a-8ffa-3f0d318e5e96"},"id":"BYWDbyXiogi3","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro01.csv\n","Rows before cleaning (TEXT column): 45\n","Rows after cleaning (TEXT column): 40\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro08.csv\n","Rows before cleaning (TEXT column): 67\n","Rows after cleaning (TEXT column): 60\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro05.csv\n","Rows before cleaning (TEXT column): 99\n","Rows after cleaning (TEXT column): 91\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script01_3.csv\n","Rows before cleaning (TEXT column): 64\n","Rows after cleaning (TEXT column): 42\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro06.csv\n","Rows before cleaning (TEXT column): 56\n","Rows after cleaning (TEXT column): 52\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro07.csv\n","Rows before cleaning (TEXT column): 75\n","Rows after cleaning (TEXT column): 65\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro03.csv\n","Rows before cleaning (TEXT column): 127\n","Rows after cleaning (TEXT column): 82\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script01_1.csv\n","Rows before cleaning (TEXT column): 79\n","Rows after cleaning (TEXT column): 52\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script01_2.csv\n","Rows before cleaning (TEXT column): 35\n","Rows after cleaning (TEXT column): 28\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script02_2.csv\n","Rows before cleaning (TEXT column): 71\n","Rows after cleaning (TEXT column): 53\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script02_1.csv\n","Rows before cleaning (TEXT column): 52\n","Rows after cleaning (TEXT column): 41\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script03_2.csv\n","Rows before cleaning (TEXT column): 80\n","Rows after cleaning (TEXT column): 56\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_script03_1.csv\n","Rows before cleaning (TEXT column): 66\n","Rows after cleaning (TEXT column): 37\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro03.csv\n","Rows before cleaning (TEXT column): 63\n","Rows after cleaning (TEXT column): 56\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro05.csv\n","Rows before cleaning (TEXT column): 45\n","Rows after cleaning (TEXT column): 43\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro01.csv\n","Rows before cleaning (TEXT column): 47\n","Rows after cleaning (TEXT column): 40\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro06.csv\n","Rows before cleaning (TEXT column): 30\n","Rows after cleaning (TEXT column): 27\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro07.csv\n","Rows before cleaning (TEXT column): 93\n","Rows after cleaning (TEXT column): 81\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro02.csv\n","Rows before cleaning (TEXT column): 52\n","Rows after cleaning (TEXT column): 34\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro08.csv\n","Rows before cleaning (TEXT column): 58\n","Rows after cleaning (TEXT column): 55\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_impro04.csv\n","Rows before cleaning (TEXT column): 79\n","Rows after cleaning (TEXT column): 73\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script01_1.csv\n","Rows before cleaning (TEXT column): 76\n","Rows after cleaning (TEXT column): 52\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script01_1b.csv\n","Rows before cleaning (TEXT column): 76\n","Rows after cleaning (TEXT column): 45\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script01_3.csv\n","Rows before cleaning (TEXT column): 67\n","Rows after cleaning (TEXT column): 43\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script01_2.csv\n","Rows before cleaning (TEXT column): 35\n","Rows after cleaning (TEXT column): 23\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script02_2.csv\n","Rows before cleaning (TEXT column): 71\n","Rows after cleaning (TEXT column): 52\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script02_1.csv\n","Rows before cleaning (TEXT column): 52\n","Rows after cleaning (TEXT column): 33\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script03_1.csv\n","Rows before cleaning (TEXT column): 65\n","Rows after cleaning (TEXT column): 43\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05M_script03_2.csv\n","Rows before cleaning (TEXT column): 86\n","Rows after cleaning (TEXT column): 63\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro02.csv\n","Rows before cleaning (TEXT column): 78\n","Rows after cleaning (TEXT column): 50\n","Saved cleaned file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel/Ses05F_impro04.csv\n","Rows before cleaning (TEXT column): 87\n","Rows after cleaning (TEXT column): 80\n","Total rows in the TEXT column before cleaning: 2076\n","Total rows in the TEXT column after cleaning: 1592\n","Finished processing all files.\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Input folder with the original files\n","input_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterDroppingxxxEmotionLabel'\n","# Output folder to save the cleaned files with updated emotion labels\n","output_folder = '/content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels'\n","\n","# Create the output folder if it doesn't exist\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Initialize counters for the total number of rows for each emotion label\n","pos_count = 0\n","neg_count = 0\n","neu_count = 0\n","\n","# Loop through all files in the folder\n","for file_name in os.listdir(input_folder):\n","    # Ensure the file is a CSV file\n","    if file_name.endswith('.csv'):\n","        file_path = os.path.join(input_folder, file_name)\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Check if the TEXT and EMOTION columns exist\n","        if 'TEXT' in df.columns and 'EMOTION' in df.columns:\n","            # Update the EMOTION column based on the conditions\n","            df['EMOTION'] = df['EMOTION'].replace({\n","                'exc': 'pos',   # For excitement, assign 'pos'\n","                'hap': 'pos',   # For happiness, assign 'pos'\n","                'sur': 'pos',   # For surprise, assign 'pos'\n","                'ang': 'neg',   # For anger, assign 'neg'\n","                'fea': 'neg',   # For fear, assign 'neg'\n","                'fru': 'neg',   # For frustration, assign 'neg'\n","                'sad': 'neg',   # For sadness, assign 'neg'\n","                'neu': 'neu'    # Keep neutral as 'neu'\n","            })\n","\n","            # Count the occurrences of 'pos', 'neg', and 'neu' in the EMOTION column\n","            pos_count += df[df['EMOTION'] == 'pos'].shape[0]\n","            neg_count += df[df['EMOTION'] == 'neg'].shape[0]\n","            neu_count += df[df['EMOTION'] == 'neu'].shape[0]\n","\n","            # Save the updated DataFrame to the output folder\n","            output_file_path = os.path.join(output_folder, file_name)\n","            df.to_csv(output_file_path, index=False)\n","\n","            # Print the saved file path\n","            print(f\"Saved updated file: {output_file_path}\")\n","\n","# Print the total counts for each emotion label\n","print(f\"Total number of 'pos' emotion labels: {pos_count}\")\n","print(f\"Total number of 'neg' emotion labels: {neg_count}\")\n","print(f\"Total number of 'neu' emotion labels: {neu_count}\")\n","\n","print(\"Finished processing all files.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-UC7DjPCwgKx","executionInfo":{"status":"ok","timestamp":1740802859402,"user_tz":-480,"elapsed":880,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"d8274e24-3504-4db3-cd3e-020d5aae33dd"},"id":"-UC7DjPCwgKx","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro01.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro08.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro05.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script01_3.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro06.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro07.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro03.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script01_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script01_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script02_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script02_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script03_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_script03_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro03.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro05.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro01.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro06.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro07.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro02.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro08.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_impro04.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script01_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script01_1b.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script01_3.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script01_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script02_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script02_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script03_1.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05M_script03_2.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro02.csv\n","Saved updated file: /content/drive/MyDrive/TextClassification/Preproccessing/AfterAssigningTheThreeEmotionLabels/Ses05F_impro04.csv\n","Total number of 'pos' emotion labels: 444\n","Total number of 'neg' emotion labels: 775\n","Total number of 'neu' emotion labels: 373\n","Finished processing all files.\n"]}]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}